{
  "id": "/uta4-sm-vs-mm-sheets-nameless",
  "id_no": 49385,
  "datasetSlugNullable": "uta4-sm-vs-mm-sheets-nameless",
  "ownerUserNullable": null,
  "usabilityRatingNullable": 0.6470588235294118,
  "titleNullable": "[AVI 2020] UTA4: SM vs MM (Nameless)",
  "subtitleNullable": "A nameless comparison in Medical Imaging (MI) Diagnosis.",
  "descriptionNullable": "# UTA4: Single-Modality vs Multi-Modality (Nameless) Dataset\n\n<img src=\"https://github.com/MIMBCD-UI/meta/blob/master/banners/datasets_1280x640.png?raw=true\" width=\"100%\">\n\n\n### Context\n\nSeveral *datasets* are fostering innovation in higher-level functions for everyone, everywhere. By providing this repository, we hope to encourage the research community to focus on hard problems. In this repository, we present *usability* ([SUS](https://en.wikipedia.org/wiki/System_usability_scale)), *workload* ([NASA-TLX](https://en.wikipedia.org/wiki/NASA-TLX)), *time* and *rates* ([BIRADS](https://en.wikipedia.org/wiki/BI-RADS)) results of clinicians from our [User Tests and Analysis 4 (UTA4)](https://github.com/MIMBCD-UI/meta/wiki/User-Research#test-4-single-modality-vs-multi-modality-) study on an anonymized fashion. That said, we created [UTA4: SUS Dataset](https://mimbcd-ui.github.io/dataset-uta4-sus), [UTA4: NASA-TLX Dataset](https://mimbcd-ui.github.io/dataset-uta4-nasa-tlx), [UTA4: Time Dataset](https://mimbcd-ui.github.io/dataset-uta4-time) and [UTA4: Rates Dataset](https://mimbcd-ui.github.io/dataset-uta4-rates) pages to provide further information regarding these *datasets* and respective repositories. Please follow this last information. The present data is a mirror of the [`uta4-sm-vs-mm-sheets`](https://www.kaggle.com/MIMBCD-UI/uta4-sm-vs-mm-sheets) repository. Work and results are published on a top [Human-Computer Interaction (HCI)](https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction) conference named [AVI 2020](https://dl.acm.org/conference/avi) ([page](https://sites.google.com/unisa.it/avi2020))\n\n\n### Citing\n\nWe kindly ask **scientific works and studies** that make use of the repository to cite it in their associated publications. Similarly, we ask **open-source** and **closed-source** works that make use of the repository to warn us about this use.\n\nYou can cite our work using the following BibTeX entry:\n\n```\n@inproceedings{10.1145/3399715.3399744,\nauthor = {Calisto, Francisco Maria and Nunes, Nuno and Nascimento, Jacinto C.},\ntitle = {BreastScreening: On the Use of Multi-Modality in Medical Imaging Diagnosis},\nyear = {2020},\nisbn = {9781450375351},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3399715.3399744},\ndoi = {10.1145/3399715.3399744},\nabstract = {This paper describes the field research, design and comparative deployment of a multimodal medical imaging user interface for breast screening. The main contributions described here are threefold: 1) The design of an advanced visual interface for multimodal diagnosis of breast cancer (BreastScreening); 2) Insights from the field comparison of Single-Modality vs Multi-Modality screening of breast cancer diagnosis with 31 clinicians and 566 images; and 3) The visualization of the two main types of breast lesions in the following image modalities: (i) MammoGraphy (MG) in both Craniocaudal (CC) and Mediolateral oblique (MLO) views; (ii) UltraSound (US); and (iii) Magnetic Resonance Imaging (MRI). We summarize our work with recommendations from the radiologists for guiding the future design of medical imaging interfaces.},\nbooktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},\narticleno = {49},\nnumpages = {5},\nkeywords = {user-centered design, multimodality, medical imaging, human-computer interaction, healthcare systems, breast cancer, annotations},\nlocation = {Salerno, Italy},\nseries = {AVI '20}\n}\n```\n\n\n### Content\n\nResults were analyzed and interpreted from our [Statistical Analysis](https://mimbcd-ui.github.io/statistical-analysis/) charts. The user tests were made in clinical institutions, where clinicians diagnose several patients for a **Single-Modality** (SM) *vs* **Multi-Modality** (MM) comparison.\n\n\n### Related Repositories\n\nThe following list, represents the set of related repositories for the presented one:\n\n- [`dataset-uta4-sus`](https://github.com/MIMBCD-UI/dataset-uta4-sus)\n\n- [`dataset-uta4-nasa-tlx`](https://github.com/MIMBCD-UI/dataset-uta4-nasa-tlx)\n\n- [`dataset-uta4-time`](https://github.com/MIMBCD-UI/dataset-uta4-time)\n\n- [`dataset-uta4-rates`](https://github.com/MIMBCD-UI/dataset-uta4-rates)\n\n- [`dataset-uta4-dicom`](https://github.com/MIMBCD-UI/dataset-uta4-dicom)\n\n- [`dataset-uta7-sus`](https://github.com/MIMBCD-UI/dataset-uta7-sus)\n\n- [`dataset-uta7-nasa-tlx`](https://github.com/MIMBCD-UI/dataset-uta7-nasa-tlx)\n\n- [`dataset-uta7-time`](https://github.com/MIMBCD-UI/dataset-uta7-time)\n\n- [`dataset-uta7-rates`](https://github.com/MIMBCD-UI/dataset-uta7-rates)\n\n- [`statistical-analysis`](https://github.com/MIMBCD-UI/statistical-analysis)\n\n\n### Dataset Resources\n\nTo publish our [datasets](https://www.kaggle.com/MIMBCD-UI) we used a well known platform called [Kaggle](https://www.kaggle.com). To access our project's [Profile Page](https://www.kaggle.com/MIMBCD-UI) just follow the [link](https://www.kaggle.com/MIMBCD-UI). For the purpose, three main resources [`uta4-singlemodality-vs-multimodality-nasatlx`](https://www.kaggle.com/MIMBCD-UI/uta4-singlemodality-vs-multimodality-nasatlx), [`uta4-sm-vs-mm-sheets`](https://www.kaggle.com/MIMBCD-UI/uta4-sm-vs-mm-sheets) and [`uta4-sm-vs-mm-sheets-nameless`](https://www.kaggle.com/MIMBCD-UI/uta4-sm-vs-mm-sheets-nameless) are published in this platform. Moreover, the [**Single-Modality** *vs* **Multi-Modality**](https://data.world/mimbcdui-project/single-modality-vs-multi-modality) is available in our [MIMBCD-UI Project](https://data.world/mimbcdui-project) page on [data.world](https://data.world). Last but not least, *datasets* are also published at [figshare](https://figshare.com/projects/Single-Modality_vs_Multi-Modality/78372) and [OpenML](https://www.openml.org/d/42349) platforms.\n\n\n### License & Copyright\n\nCopyright \u00a9 2020 [Instituto Superior T\u00e9cnico](http://tecnico.ulisboa.pt/)\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n\nOur *datasets* are distributed under the terms of **GNU AGPLv3** license and **CC-BY-SA-4.0** copyright. Permissions of this license are conditioned on making available complete elements from this repository of licensed works and modifications, which include larger works using a licensed work, under the same license. Copyright and license notices must be preserved.\n\n\n### Acknowledgements\n\nThis work was partially supported by national funds through [FCT](http://fct.pt/) and [IST](http://tecnico.ulisboa.pt/) through the [UID/EEA/50009/2013](https://www.fct.pt/apoios/projectos/consulta/vglobal_projecto.phtml.en?idProjecto=147329&idElemConcurso=8999) project, [BL89/2017-IST-ID](http://ist-id.pt/en/) grant. We thank [Dr. Clara Aleluia](https://www.researchgate.net/profile/Clara_Aleluia) and her [radiology team](https://repositorio.hff.min-saude.pt/handle/10400.10/4?locale=en) of [HFF](https://hff.min-saude.pt/) for valuable insights and helping using the *Assistant* on their daily basis. From [IPO-Lisboa](http://www.ipolisboa.min-saude.pt/), we would like to thank the medical imaging teams of [Dr. Jos\u00e9 Carlos Marques](https://www.researchgate.net/profile/Jose_Marques42) and [Dr. Jos\u00e9 Ven\u00e2ncio](http://www.ipolisboa.min-saude.pt/servicosclinicos/radiologia/). From [IPO-Coimbra](https://ipocoimbra.com), we would like to thank the radiology department director and the all team of [Dr. Id\u00edlio Gomes](https://ipocoimbra.com/servico-de-imagiologia/). Also, we would like to provide our acknowledgments to Dr. Em\u00edlia Vieira and Dr. C\u00e1tia Pedro from [Hospital Santa Maria](http://www.chln.min-saude.pt/). Furthermore, we want to thank all teams from the radiology department of [HB](http://www.chbm.min-saude.pt/) for participation. Last but not least, a great thanks to [Dr. Cristina Ribeiro da Fonseca](http://imi.pt/pt/content/31-corpo-clnico/32-profissionais-imi?content=55), who among others is giving us crucial information for the [BreastScreening](https://github.com/BreastScreening) project.",
  "datasetId": 49385,
  "datasetSlug": "uta4-sm-vs-mm-sheets-nameless",
  "hasDatasetSlug": true,
  "ownerUser": "",
  "hasOwnerUser": false,
  "usabilityRating": 0.6470588235294118,
  "hasUsabilityRating": true,
  "totalViews": 3585,
  "totalVotes": 6,
  "totalDownloads": 86,
  "title": "[AVI 2020] UTA4: SM vs MM (Nameless)",
  "hasTitle": true,
  "subtitle": "A nameless comparison in Medical Imaging (MI) Diagnosis.",
  "hasSubtitle": true,
  "description": "# UTA4: Single-Modality vs Multi-Modality (Nameless) Dataset\n\n<img src=\"https://github.com/MIMBCD-UI/meta/blob/master/banners/datasets_1280x640.png?raw=true\" width=\"100%\">\n\n\n### Context\n\nSeveral *datasets* are fostering innovation in higher-level functions for everyone, everywhere. By providing this repository, we hope to encourage the research community to focus on hard problems. In this repository, we present *usability* ([SUS](https://en.wikipedia.org/wiki/System_usability_scale)), *workload* ([NASA-TLX](https://en.wikipedia.org/wiki/NASA-TLX)), *time* and *rates* ([BIRADS](https://en.wikipedia.org/wiki/BI-RADS)) results of clinicians from our [User Tests and Analysis 4 (UTA4)](https://github.com/MIMBCD-UI/meta/wiki/User-Research#test-4-single-modality-vs-multi-modality-) study on an anonymized fashion. That said, we created [UTA4: SUS Dataset](https://mimbcd-ui.github.io/dataset-uta4-sus), [UTA4: NASA-TLX Dataset](https://mimbcd-ui.github.io/dataset-uta4-nasa-tlx), [UTA4: Time Dataset](https://mimbcd-ui.github.io/dataset-uta4-time) and [UTA4: Rates Dataset](https://mimbcd-ui.github.io/dataset-uta4-rates) pages to provide further information regarding these *datasets* and respective repositories. Please follow this last information. The present data is a mirror of the [`uta4-sm-vs-mm-sheets`](https://www.kaggle.com/MIMBCD-UI/uta4-sm-vs-mm-sheets) repository. Work and results are published on a top [Human-Computer Interaction (HCI)](https://en.wikipedia.org/wiki/Human%E2%80%93computer_interaction) conference named [AVI 2020](https://dl.acm.org/conference/avi) ([page](https://sites.google.com/unisa.it/avi2020))\n\n\n### Citing\n\nWe kindly ask **scientific works and studies** that make use of the repository to cite it in their associated publications. Similarly, we ask **open-source** and **closed-source** works that make use of the repository to warn us about this use.\n\nYou can cite our work using the following BibTeX entry:\n\n```\n@inproceedings{10.1145/3399715.3399744,\nauthor = {Calisto, Francisco Maria and Nunes, Nuno and Nascimento, Jacinto C.},\ntitle = {BreastScreening: On the Use of Multi-Modality in Medical Imaging Diagnosis},\nyear = {2020},\nisbn = {9781450375351},\npublisher = {Association for Computing Machinery},\naddress = {New York, NY, USA},\nurl = {https://doi.org/10.1145/3399715.3399744},\ndoi = {10.1145/3399715.3399744},\nabstract = {This paper describes the field research, design and comparative deployment of a multimodal medical imaging user interface for breast screening. The main contributions described here are threefold: 1) The design of an advanced visual interface for multimodal diagnosis of breast cancer (BreastScreening); 2) Insights from the field comparison of Single-Modality vs Multi-Modality screening of breast cancer diagnosis with 31 clinicians and 566 images; and 3) The visualization of the two main types of breast lesions in the following image modalities: (i) MammoGraphy (MG) in both Craniocaudal (CC) and Mediolateral oblique (MLO) views; (ii) UltraSound (US); and (iii) Magnetic Resonance Imaging (MRI). We summarize our work with recommendations from the radiologists for guiding the future design of medical imaging interfaces.},\nbooktitle = {Proceedings of the International Conference on Advanced Visual Interfaces},\narticleno = {49},\nnumpages = {5},\nkeywords = {user-centered design, multimodality, medical imaging, human-computer interaction, healthcare systems, breast cancer, annotations},\nlocation = {Salerno, Italy},\nseries = {AVI '20}\n}\n```\n\n\n### Content\n\nResults were analyzed and interpreted from our [Statistical Analysis](https://mimbcd-ui.github.io/statistical-analysis/) charts. The user tests were made in clinical institutions, where clinicians diagnose several patients for a **Single-Modality** (SM) *vs* **Multi-Modality** (MM) comparison.\n\n\n### Related Repositories\n\nThe following list, represents the set of related repositories for the presented one:\n\n- [`dataset-uta4-sus`](https://github.com/MIMBCD-UI/dataset-uta4-sus)\n\n- [`dataset-uta4-nasa-tlx`](https://github.com/MIMBCD-UI/dataset-uta4-nasa-tlx)\n\n- [`dataset-uta4-time`](https://github.com/MIMBCD-UI/dataset-uta4-time)\n\n- [`dataset-uta4-rates`](https://github.com/MIMBCD-UI/dataset-uta4-rates)\n\n- [`dataset-uta4-dicom`](https://github.com/MIMBCD-UI/dataset-uta4-dicom)\n\n- [`dataset-uta7-sus`](https://github.com/MIMBCD-UI/dataset-uta7-sus)\n\n- [`dataset-uta7-nasa-tlx`](https://github.com/MIMBCD-UI/dataset-uta7-nasa-tlx)\n\n- [`dataset-uta7-time`](https://github.com/MIMBCD-UI/dataset-uta7-time)\n\n- [`dataset-uta7-rates`](https://github.com/MIMBCD-UI/dataset-uta7-rates)\n\n- [`statistical-analysis`](https://github.com/MIMBCD-UI/statistical-analysis)\n\n\n### Dataset Resources\n\nTo publish our [datasets](https://www.kaggle.com/MIMBCD-UI) we used a well known platform called [Kaggle](https://www.kaggle.com). To access our project's [Profile Page](https://www.kaggle.com/MIMBCD-UI) just follow the [link](https://www.kaggle.com/MIMBCD-UI). For the purpose, three main resources [`uta4-singlemodality-vs-multimodality-nasatlx`](https://www.kaggle.com/MIMBCD-UI/uta4-singlemodality-vs-multimodality-nasatlx), [`uta4-sm-vs-mm-sheets`](https://www.kaggle.com/MIMBCD-UI/uta4-sm-vs-mm-sheets) and [`uta4-sm-vs-mm-sheets-nameless`](https://www.kaggle.com/MIMBCD-UI/uta4-sm-vs-mm-sheets-nameless) are published in this platform. Moreover, the [**Single-Modality** *vs* **Multi-Modality**](https://data.world/mimbcdui-project/single-modality-vs-multi-modality) is available in our [MIMBCD-UI Project](https://data.world/mimbcdui-project) page on [data.world](https://data.world). Last but not least, *datasets* are also published at [figshare](https://figshare.com/projects/Single-Modality_vs_Multi-Modality/78372) and [OpenML](https://www.openml.org/d/42349) platforms.\n\n\n### License & Copyright\n\nCopyright \u00a9 2020 [Instituto Superior T\u00e9cnico](http://tecnico.ulisboa.pt/)\n\n[![Creative Commons License](https://i.creativecommons.org/l/by-sa/4.0/88x31.png)](http://creativecommons.org/licenses/by-sa/4.0/)\n\nOur *datasets* are distributed under the terms of **GNU AGPLv3** license and **CC-BY-SA-4.0** copyright. Permissions of this license are conditioned on making available complete elements from this repository of licensed works and modifications, which include larger works using a licensed work, under the same license. Copyright and license notices must be preserved.\n\n\n### Acknowledgements\n\nThis work was partially supported by national funds through [FCT](http://fct.pt/) and [IST](http://tecnico.ulisboa.pt/) through the [UID/EEA/50009/2013](https://www.fct.pt/apoios/projectos/consulta/vglobal_projecto.phtml.en?idProjecto=147329&idElemConcurso=8999) project, [BL89/2017-IST-ID](http://ist-id.pt/en/) grant. We thank [Dr. Clara Aleluia](https://www.researchgate.net/profile/Clara_Aleluia) and her [radiology team](https://repositorio.hff.min-saude.pt/handle/10400.10/4?locale=en) of [HFF](https://hff.min-saude.pt/) for valuable insights and helping using the *Assistant* on their daily basis. From [IPO-Lisboa](http://www.ipolisboa.min-saude.pt/), we would like to thank the medical imaging teams of [Dr. Jos\u00e9 Carlos Marques](https://www.researchgate.net/profile/Jose_Marques42) and [Dr. Jos\u00e9 Ven\u00e2ncio](http://www.ipolisboa.min-saude.pt/servicosclinicos/radiologia/). From [IPO-Coimbra](https://ipocoimbra.com), we would like to thank the radiology department director and the all team of [Dr. Id\u00edlio Gomes](https://ipocoimbra.com/servico-de-imagiologia/). Also, we would like to provide our acknowledgments to Dr. Em\u00edlia Vieira and Dr. C\u00e1tia Pedro from [Hospital Santa Maria](http://www.chln.min-saude.pt/). Furthermore, we want to thank all teams from the radiology department of [HB](http://www.chbm.min-saude.pt/) for participation. Last but not least, a great thanks to [Dr. Cristina Ribeiro da Fonseca](http://imi.pt/pt/content/31-corpo-clnico/32-profissionais-imi?content=55), who among others is giving us crucial information for the [BreastScreening](https://github.com/BreastScreening) project.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "earth and nature",
    "social science",
    "computer science"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-SA-4.0",
      "name": "CC-BY-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [
    {
      "username": "fmcalisto",
      "role": "writer"
    }
  ],
  "data": []
}