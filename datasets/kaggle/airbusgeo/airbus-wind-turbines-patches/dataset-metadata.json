{
  "id": "/airbus-wind-turbines-patches",
  "id_no": 941801,
  "datasetSlugNullable": "airbus-wind-turbines-patches",
  "ownerUserNullable": null,
  "usabilityRatingNullable": 0.875,
  "titleNullable": "Airbus Wind Turbines Patches",
  "subtitleNullable": "Airbus SPOT satellites images over wind turbines for classification.",
  "descriptionNullable": "### Context\n\nWind turbines make electricity from wind. Wind turns the propeller-like blades of a turbine around a rotor, which spins a generator, which creates electricity. Generating electricity from wind rather than from gas helps fight global warming. More and more states and private companies are investing in renewable energies and building huge wind turbines plants. Knowing where this wind turbines are located is essential and could help in energy production forecast. Deep Learning could help identify wind turbines on satellite image. \n\n### Content\n\nThis is very simple dataset which objective is to build a classifier of satellite images extract **with** or **without** wind turbines.  Extracts of 128 x 128 pixels with wind turbines are located in a folder called `targets` ; extracts without wind turbines are located in a folder called `background`. Images are extracted from satellite acquisitions from the Airbus [SPOT6 and SPOT7 satellites](https://www.intelligence-airbusds.com/en/8693-spot-67) which resolution is 1.5 meters per pixel. So extracts of 128 x 128 pixels represents roughly 192 meters on the ground which is compatible with the typical size of a wind turbine.\n\n### Acknowledgements\n\nThis dataset would not exists without the contribution of the Innovation team at Airbus DS GEO S.A. Thank you for all your hard work and the fun during the tagging and hacking sessions.\n\n### Inspiration\n\nBuilding a classifier is a very common task in Deep Learning. When dealing with imagery, it is also very common to use **convolutions** to create CNN. By replacing the last fully connected layers of the model by 1-d convolutions, it is possible to create what is called a **fully convolutional neural network** a.k.a. FCN. This model can then be used on imagery of any size to build a detector. The technical paper is available here https://arxiv.org/abs/1411.4038",
  "datasetId": 941801,
  "datasetSlug": "airbus-wind-turbines-patches",
  "hasDatasetSlug": true,
  "ownerUser": "",
  "hasOwnerUser": false,
  "usabilityRating": 0.875,
  "hasUsabilityRating": true,
  "totalViews": 16044,
  "totalVotes": 14,
  "totalDownloads": 488,
  "title": "Airbus Wind Turbines Patches",
  "hasTitle": true,
  "subtitle": "Airbus SPOT satellites images over wind turbines for classification.",
  "hasSubtitle": true,
  "description": "### Context\n\nWind turbines make electricity from wind. Wind turns the propeller-like blades of a turbine around a rotor, which spins a generator, which creates electricity. Generating electricity from wind rather than from gas helps fight global warming. More and more states and private companies are investing in renewable energies and building huge wind turbines plants. Knowing where this wind turbines are located is essential and could help in energy production forecast. Deep Learning could help identify wind turbines on satellite image. \n\n### Content\n\nThis is very simple dataset which objective is to build a classifier of satellite images extract **with** or **without** wind turbines.  Extracts of 128 x 128 pixels with wind turbines are located in a folder called `targets` ; extracts without wind turbines are located in a folder called `background`. Images are extracted from satellite acquisitions from the Airbus [SPOT6 and SPOT7 satellites](https://www.intelligence-airbusds.com/en/8693-spot-67) which resolution is 1.5 meters per pixel. So extracts of 128 x 128 pixels represents roughly 192 meters on the ground which is compatible with the typical size of a wind turbine.\n\n### Acknowledgements\n\nThis dataset would not exists without the contribution of the Innovation team at Airbus DS GEO S.A. Thank you for all your hard work and the fun during the tagging and hacking sessions.\n\n### Inspiration\n\nBuilding a classifier is a very common task in Deep Learning. When dealing with imagery, it is also very common to use **convolutions** to create CNN. By replacing the last fully connected layers of the model by 1-d convolutions, it is possible to create what is called a **fully convolutional neural network** a.k.a. FCN. This model can then be used on imagery of any size to build a detector. The technical paper is available here https://arxiv.org/abs/1411.4038",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "renewable energy",
    "computer science"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}