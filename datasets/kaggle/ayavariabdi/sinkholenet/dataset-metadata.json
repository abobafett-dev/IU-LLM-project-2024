{
  "id": "ayavariabdi/sinkholenet",
  "id_no": 2148439,
  "datasetSlugNullable": "sinkholenet",
  "ownerUserNullable": "ayavariabdi",
  "usabilityRatingNullable": 0.625,
  "titleNullable": "Sinkhole Dataset",
  "subtitleNullable": "",
  "descriptionNullable": "### SinkholeNet: A Multi-Head Deep Learning Model for Sinkhole Classification and Localization\n\n In this dataset, the high-resolution aerial image is collected from the region of Karapinar, located in Konya, Turkey. This sinkhole dataset, consisting of RGB orthomosaic image and ground slope map. To generate this datase, a DJI Phantom 4 Pro-V2.0 quadcopter UAV with an optical camera is used to acquire images of the ground. The image acquisition is carried out under clear sky conditions. Since optical cameras only acquire three wavelengths (red, green, and blue), the ground elevation information does not exist so that it is vital to estimate it via a 3D modeling strategy using RGB images. Therefore, a 3-step strategy is used to obtain both ground slope map and orthomosaic image. The aim of the first step is to generate georeferenced images. To achieve this, there are two possible approaches: 1) direct methods which use the geolocation data of the images or 2) indirect methods which use ground control points. Here, the second approach is used to generate georeferenced images. In this manner, geodetic studies are carried out before image acquisition to transfer the images obtained from the UAV into georeferenced images using Universal Transverse Mercator (UTM) WGS84 zone 36 projection. More specifically, we select ten different homogeneously distributed ground control points over the study area and these points are localized with the Global Navigation Satellite Systems (GNSS) technique. In the second step, the flight plan for automatic data acquisition is programmed with the DJI GroundStation Pro application. Here, a 800 x 750 meter grid is established covering the entire study area. In addition, the autonomous flight altitude is 90m above ground level with a camera angle of 90-degree. To create more detailed map, the front and side overlap rate is defined as 80. As a result, 467 high-resolution images are obtained. In the final step, visual Structure from Motion system (VisualSfM) algorithm is used to align 467 spatially overlapped images to generate orthomosaic image and DEM of the study region. To generate slope map, the changes in the DEM is measured and considered as ground slope. The constructed orthomosaic RGB image is with pixel and spatial resolutions of 14,770 x 15,979 and 5 cm/pixel, respectively.\n\n## Dataset Summery\nA new sinkhole dataset, consisting of RGB image samples with ground slope maps, is created and will be publicly available to the research community to further advance sinkhole classification and localization algorithms. To the best of our knowledge, this dataset is the first one to provide images in RGB color space and ground slope map. \n\n[RGB Orthomosaic Image](https://www.kaggle.com/datasets/ayavariabdi/sinkholenet?select=RGB.png)\n\n[Ground Slope Map](https://www.kaggle.com/datasets/ayavariabdi/sinkholenet?select=slope_2.tif)\n\n## Model\nModel will be shared shortly. \n\n## Read Image Dataset in Matlab\n[MATLAB Code for Visualization](https://github.com/sinkholenet/sinkholenet/blob/main/read_data.m)\n\n## If you use any of these datasets, please cite:\n\n#### Reference:\n\n* Amir Yavariabdi, Huseyin Kusetogullari, Osman Orhan, Esra Uray, Vahdettin Demir, and Turgay Celik, \"SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization\", The Egyptian Journal of Remote Sensing and Space Sciences, Submitted in 01/2023.\n* Amir Yavariabdi, Huseyin Kusetogullari, Osman Orhan, Esra Uray, Vahdettin Demir, and Turgay Celik, SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization, Jan. 2023. Accessed on: Jan. 25, 2023. Available: [https://github.com/sinkholenet/sinkholenet/](https://github.com/sinkholenet/sinkholenet/). \n\n#### BibTeX:\n* @article{YavariabdiSinkholeNet,  \n           title={SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization},  \n           author={Amir Yavariabdi and Huseyin Kusetogullari and Osman Orhan and Esra Uray and Vahdettin Demir and Turgay Celik},  \n           journal={The Egyptian Journal of Remote Sensing and Space Sciences},  \n           year={Submitted}  \n           }\n* @misc{YavariabdiSinkholeNetDataset,  \n       author = {Amir Yavariabdi and Huseyin Kusetogullari and Osman Orhan and Esra Uray and Vahdettin Demir and Turgay Celik},    \n       title = {SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization},    \n       howpublished = {\\url{https://github.com/sinkholenet/sinkholenet/}},  \n       note = {Accessed: 2023-25-01}  \n",
  "datasetId": 2148439,
  "datasetSlug": "sinkholenet",
  "hasDatasetSlug": true,
  "ownerUser": "ayavariabdi",
  "hasOwnerUser": true,
  "usabilityRating": 0.625,
  "hasUsabilityRating": true,
  "totalViews": 2747,
  "totalVotes": 12,
  "totalDownloads": 120,
  "title": "Sinkhole Dataset",
  "hasTitle": true,
  "subtitle": "",
  "hasSubtitle": true,
  "description": "### SinkholeNet: A Multi-Head Deep Learning Model for Sinkhole Classification and Localization\n\n In this dataset, the high-resolution aerial image is collected from the region of Karapinar, located in Konya, Turkey. This sinkhole dataset, consisting of RGB orthomosaic image and ground slope map. To generate this datase, a DJI Phantom 4 Pro-V2.0 quadcopter UAV with an optical camera is used to acquire images of the ground. The image acquisition is carried out under clear sky conditions. Since optical cameras only acquire three wavelengths (red, green, and blue), the ground elevation information does not exist so that it is vital to estimate it via a 3D modeling strategy using RGB images. Therefore, a 3-step strategy is used to obtain both ground slope map and orthomosaic image. The aim of the first step is to generate georeferenced images. To achieve this, there are two possible approaches: 1) direct methods which use the geolocation data of the images or 2) indirect methods which use ground control points. Here, the second approach is used to generate georeferenced images. In this manner, geodetic studies are carried out before image acquisition to transfer the images obtained from the UAV into georeferenced images using Universal Transverse Mercator (UTM) WGS84 zone 36 projection. More specifically, we select ten different homogeneously distributed ground control points over the study area and these points are localized with the Global Navigation Satellite Systems (GNSS) technique. In the second step, the flight plan for automatic data acquisition is programmed with the DJI GroundStation Pro application. Here, a 800 x 750 meter grid is established covering the entire study area. In addition, the autonomous flight altitude is 90m above ground level with a camera angle of 90-degree. To create more detailed map, the front and side overlap rate is defined as 80. As a result, 467 high-resolution images are obtained. In the final step, visual Structure from Motion system (VisualSfM) algorithm is used to align 467 spatially overlapped images to generate orthomosaic image and DEM of the study region. To generate slope map, the changes in the DEM is measured and considered as ground slope. The constructed orthomosaic RGB image is with pixel and spatial resolutions of 14,770 x 15,979 and 5 cm/pixel, respectively.\n\n## Dataset Summery\nA new sinkhole dataset, consisting of RGB image samples with ground slope maps, is created and will be publicly available to the research community to further advance sinkhole classification and localization algorithms. To the best of our knowledge, this dataset is the first one to provide images in RGB color space and ground slope map. \n\n[RGB Orthomosaic Image](https://www.kaggle.com/datasets/ayavariabdi/sinkholenet?select=RGB.png)\n\n[Ground Slope Map](https://www.kaggle.com/datasets/ayavariabdi/sinkholenet?select=slope_2.tif)\n\n## Model\nModel will be shared shortly. \n\n## Read Image Dataset in Matlab\n[MATLAB Code for Visualization](https://github.com/sinkholenet/sinkholenet/blob/main/read_data.m)\n\n## If you use any of these datasets, please cite:\n\n#### Reference:\n\n* Amir Yavariabdi, Huseyin Kusetogullari, Osman Orhan, Esra Uray, Vahdettin Demir, and Turgay Celik, \"SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization\", The Egyptian Journal of Remote Sensing and Space Sciences, Submitted in 01/2023.\n* Amir Yavariabdi, Huseyin Kusetogullari, Osman Orhan, Esra Uray, Vahdettin Demir, and Turgay Celik, SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization, Jan. 2023. Accessed on: Jan. 25, 2023. Available: [https://github.com/sinkholenet/sinkholenet/](https://github.com/sinkholenet/sinkholenet/). \n\n#### BibTeX:\n* @article{YavariabdiSinkholeNet,  \n           title={SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization},  \n           author={Amir Yavariabdi and Huseyin Kusetogullari and Osman Orhan and Esra Uray and Vahdettin Demir and Turgay Celik},  \n           journal={The Egyptian Journal of Remote Sensing and Space Sciences},  \n           year={Submitted}  \n           }\n* @misc{YavariabdiSinkholeNetDataset,  \n       author = {Amir Yavariabdi and Huseyin Kusetogullari and Osman Orhan and Esra Uray and Vahdettin Demir and Turgay Celik},    \n       title = {SinkholeNet: A Novel RGB-Slope Sinkhole Dataset and Deep Weakly-Supervised Learning Framework for Sinkhole Classification and Localization},    \n       howpublished = {\\url{https://github.com/sinkholenet/sinkholenet/}},  \n       note = {Accessed: 2023-25-01}  \n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "geography",
    "environment",
    "clothing and accessories",
    "science and technology",
    "computer science",
    "image"
  ],
  "licenses": [
    {
      "nameNullable": "ODbL-1.0",
      "name": "ODbL-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}