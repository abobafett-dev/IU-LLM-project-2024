{
  "id": "benjaminawd/new-york-times-articles-comments-2020",
  "id_no": 1131669,
  "datasetSlugNullable": "new-york-times-articles-comments-2020",
  "ownerUserNullable": "benjaminawd",
  "usabilityRatingNullable": 0.9117647058823529,
  "titleNullable": "New York Times Articles & Comments (2020)",
  "subtitleNullable": "16K articles and 5M comments from the New York Times",
  "descriptionNullable": "### Context\n\nThe New York Times is one of the most popular online news platforms in the world. What sets the Times apart from other publications is the ability to engage and connect with its readers. Readers who visit the site can provide their thoughts and reactions to published content in the form of comments, and have been doing so increasingly over the last few years.\n\n### Content\n\nThis dataset contains all comments and articles from January 1, 2020 - December 31, 2020. The articles .csv file contains **16K+ articles** with **11 features**, and the comments .csv file contains nearly **5M comments** with **23 features**.\n\n### Inspiration\n\nThere's a ton of things you can do with this dataset, including:\n1. Predict the number of comments that an article will receive -- you can use `n_comments` as a target variable or convert it to a binary classification variable. You can use this the train / test .csv files for this task.\n2. Predict how many recommendations a comment will receive using `recommendations` as a target variable.\n3. Predict whether a comment will be selected as a Times Pick using `editorsSelection` as a target variable.\n4. Identify the most popular topics based on article headlines -- you could try using something like KMeans clustering or Latent Dirichlet Allocation (LDA) clustering.\n5. Generate news headlines using a Long Short-Term Memory (LSTM) neural network.\n\n### Acknowledgements\n\nThis data was accessed through the New York Times API with [nytimes-scraper](https://github.com/ietz/nytimes-scraper). A detailed look at the data cleaning process can be found [here](https://nbviewer.jupyter.org/github/benjamin-awd/NYT-Article-Popularity/blob/main/1.%20Data%20Cleaning%20%26%20Preparation.ipynb). I'd like to acknowledge two invaluable sources of inspiration -- [Aashita Kersawani's]( https://www.kaggle.com/aashita/nyt-comments) 2018 dataset, and [The Analytics Edge](https://www.kaggle.com/c/15-071x-the-analytics-edge-competition-spring-2015) 2015 competition.",
  "datasetId": 1131669,
  "datasetSlug": "new-york-times-articles-comments-2020",
  "hasDatasetSlug": true,
  "ownerUser": "benjaminawd",
  "hasOwnerUser": true,
  "usabilityRating": 0.9117647058823529,
  "hasUsabilityRating": true,
  "totalViews": 19387,
  "totalVotes": 24,
  "totalDownloads": 2169,
  "title": "New York Times Articles & Comments (2020)",
  "hasTitle": true,
  "subtitle": "16K articles and 5M comments from the New York Times",
  "hasSubtitle": true,
  "description": "### Context\n\nThe New York Times is one of the most popular online news platforms in the world. What sets the Times apart from other publications is the ability to engage and connect with its readers. Readers who visit the site can provide their thoughts and reactions to published content in the form of comments, and have been doing so increasingly over the last few years.\n\n### Content\n\nThis dataset contains all comments and articles from January 1, 2020 - December 31, 2020. The articles .csv file contains **16K+ articles** with **11 features**, and the comments .csv file contains nearly **5M comments** with **23 features**.\n\n### Inspiration\n\nThere's a ton of things you can do with this dataset, including:\n1. Predict the number of comments that an article will receive -- you can use `n_comments` as a target variable or convert it to a binary classification variable. You can use this the train / test .csv files for this task.\n2. Predict how many recommendations a comment will receive using `recommendations` as a target variable.\n3. Predict whether a comment will be selected as a Times Pick using `editorsSelection` as a target variable.\n4. Identify the most popular topics based on article headlines -- you could try using something like KMeans clustering or Latent Dirichlet Allocation (LDA) clustering.\n5. Generate news headlines using a Long Short-Term Memory (LSTM) neural network.\n\n### Acknowledgements\n\nThis data was accessed through the New York Times API with [nytimes-scraper](https://github.com/ietz/nytimes-scraper). A detailed look at the data cleaning process can be found [here](https://nbviewer.jupyter.org/github/benjamin-awd/NYT-Article-Popularity/blob/main/1.%20Data%20Cleaning%20%26%20Preparation.ipynb). I'd like to acknowledge two invaluable sources of inspiration -- [Aashita Kersawani's]( https://www.kaggle.com/aashita/nyt-comments) 2018 dataset, and [The Analytics Edge](https://www.kaggle.com/c/15-071x-the-analytics-edge-competition-spring-2015) 2015 competition.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "nlp",
    "classification",
    "tabular",
    "regression",
    "news"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}