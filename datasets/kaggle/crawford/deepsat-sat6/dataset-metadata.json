{
  "id": "crawford/deepsat-sat6",
  "id_no": 9971,
  "datasetSlugNullable": "deepsat-sat6",
  "ownerUserNullable": "crawford",
  "usabilityRatingNullable": 0.7647058823529411,
  "titleNullable": "DeepSat (SAT-6) Airborne Dataset",
  "subtitleNullable": "405,000 image patches each of size 28x28 and covering 6 landcover classes ",
  "descriptionNullable": "### DeepSat SAT-6\n![Sample images][1]<br><br>\nOriginally, images were extracted from the National Agriculture Imagery Program (NAIP) dataset. The NAIP dataset consists of a total of 330,000 scenes spanning the whole of the Continental United States (CONUS). The authors used the uncompressed digital Ortho quarter quad tiles (DOQQs) which are GeoTIFF images and the area corresponds to the United States Geological Survey (USGS) topographic quadrangles. The average image tiles are ~6000 pixels in width and ~7000 pixels in height, measuring around 200 megabytes each. The entire NAIP dataset for CONUS is ~65 terabytes. The imagery is acquired at a 1-m ground sample distance (GSD) with a horizontal accuracy that lies within six meters of photo-identifiable ground control points.\n\nThe images consist of 4 bands - red, green, blue and Near Infrared (NIR). In order to maintain the high variance inherent in the entire NAIP dataset, we sample image patches from a multitude of scenes (a total of 1500 image tiles) covering different landscapes like rural areas, urban areas, densely forested, mountainous terrain, small to large water bodies, agricultural areas, etc. covering the whole state of California. An image labeling tool developed as part of this study was used to manually label uniform image patches belonging to a particular landcover class. \n\nOnce labeled, 28x28 non-overlapping sliding window blocks were extracted from the uniform image patch and saved to the dataset with the corresponding label. We chose 28x28 as the window size to maintain a significantly bigger context, and at the same time not to make it as big as to drop the relative statistical properties of the target class conditional distributions within the contextual window. Care was taken to avoid interclass overlaps within a selected and labeled image patch.\n\n### Content\n\n- Each sample image is 28x28 pixels and consists of 4 bands - red, green, blue and near infrared. \n\n- The training and test labels are one-hot encoded 1x6 vectors\n\n- The six classes represent the six broad land covers which include barren land, trees, grassland, roads, buildings and water bodies. \n\n- Training and test datasets belong to disjoint set of image tiles. \n\n- Each image patch is size normalized to 28x28 pixels.\n\n- Once generated, both the training and testing datasets were randomized using a pseudo-random number generator. \n\n### CSV files<br>\n- X_train_sat6.csv: 324,000 training images, 28x28 images each with 4 channels <br>\n- y_train_sat6.csv: 324,000 training labels, 1x6 one-hot encoded vectors <br>\n- X_test_sat6.csv: 81,000 training images, 28x28 images each with 4 channels <br>\n- y_test_sat6.csv: 81,000 training labels, 1x6 one-hot encoded vectors <br>\n\n### The original MAT file <br>\n- train_x:\t28x28x6x324000 uint8 (containing 400000 training samples of 28x28 images each with 4 channels)<br>\n- train_y:\t324,000x6 uint8 (containing 6x1 vectors having labels for the 400000 training samples)<br>\n- test_x:\t28x28x6x18000 uint8 (containing 100000 test samples of 28x28 images each with 4 channels)<br>\n- test_y:\t81,000x6 uint8 (containing 6x1 vectors having labels for the 100000 test samples)<br>\n\n### Acknowledgements\n\nThe original MATLAB file was converted to multiple CSV files \n\nThe original SAT-4 and SAT-6 airborne datasets can be found here:<br>\n[http://csc.lsu.edu/~saikat/deepsat/][2]<br>\n\nThanks to:<br>\nSaikat Basu, Robert DiBiano, Manohar Karki and Supratik Mukhopadhyay, Louisiana State University\nSangram Ganguly, Bay Area Environmental Research Institute/NASA Ames Research Center\nRamakrishna R. Nemani, NASA Advanced Supercomputing Division, NASA Ames Research Center\n\n\n\n  [1]: http://csc.lsu.edu/~saikat/deepsat/images/sat_img.png\n  [2]: http://csc.lsu.edu/~saikat/deepsat/",
  "datasetId": 9971,
  "datasetSlug": "deepsat-sat6",
  "hasDatasetSlug": true,
  "ownerUser": "crawford",
  "hasOwnerUser": true,
  "usabilityRating": 0.7647058823529411,
  "hasUsabilityRating": true,
  "totalViews": 52940,
  "totalVotes": 87,
  "totalDownloads": 3108,
  "title": "DeepSat (SAT-6) Airborne Dataset",
  "hasTitle": true,
  "subtitle": "405,000 image patches each of size 28x28 and covering 6 landcover classes ",
  "hasSubtitle": true,
  "description": "### DeepSat SAT-6\n![Sample images][1]<br><br>\nOriginally, images were extracted from the National Agriculture Imagery Program (NAIP) dataset. The NAIP dataset consists of a total of 330,000 scenes spanning the whole of the Continental United States (CONUS). The authors used the uncompressed digital Ortho quarter quad tiles (DOQQs) which are GeoTIFF images and the area corresponds to the United States Geological Survey (USGS) topographic quadrangles. The average image tiles are ~6000 pixels in width and ~7000 pixels in height, measuring around 200 megabytes each. The entire NAIP dataset for CONUS is ~65 terabytes. The imagery is acquired at a 1-m ground sample distance (GSD) with a horizontal accuracy that lies within six meters of photo-identifiable ground control points.\n\nThe images consist of 4 bands - red, green, blue and Near Infrared (NIR). In order to maintain the high variance inherent in the entire NAIP dataset, we sample image patches from a multitude of scenes (a total of 1500 image tiles) covering different landscapes like rural areas, urban areas, densely forested, mountainous terrain, small to large water bodies, agricultural areas, etc. covering the whole state of California. An image labeling tool developed as part of this study was used to manually label uniform image patches belonging to a particular landcover class. \n\nOnce labeled, 28x28 non-overlapping sliding window blocks were extracted from the uniform image patch and saved to the dataset with the corresponding label. We chose 28x28 as the window size to maintain a significantly bigger context, and at the same time not to make it as big as to drop the relative statistical properties of the target class conditional distributions within the contextual window. Care was taken to avoid interclass overlaps within a selected and labeled image patch.\n\n### Content\n\n- Each sample image is 28x28 pixels and consists of 4 bands - red, green, blue and near infrared. \n\n- The training and test labels are one-hot encoded 1x6 vectors\n\n- The six classes represent the six broad land covers which include barren land, trees, grassland, roads, buildings and water bodies. \n\n- Training and test datasets belong to disjoint set of image tiles. \n\n- Each image patch is size normalized to 28x28 pixels.\n\n- Once generated, both the training and testing datasets were randomized using a pseudo-random number generator. \n\n### CSV files<br>\n- X_train_sat6.csv: 324,000 training images, 28x28 images each with 4 channels <br>\n- y_train_sat6.csv: 324,000 training labels, 1x6 one-hot encoded vectors <br>\n- X_test_sat6.csv: 81,000 training images, 28x28 images each with 4 channels <br>\n- y_test_sat6.csv: 81,000 training labels, 1x6 one-hot encoded vectors <br>\n\n### The original MAT file <br>\n- train_x:\t28x28x6x324000 uint8 (containing 400000 training samples of 28x28 images each with 4 channels)<br>\n- train_y:\t324,000x6 uint8 (containing 6x1 vectors having labels for the 400000 training samples)<br>\n- test_x:\t28x28x6x18000 uint8 (containing 100000 test samples of 28x28 images each with 4 channels)<br>\n- test_y:\t81,000x6 uint8 (containing 6x1 vectors having labels for the 100000 test samples)<br>\n\n### Acknowledgements\n\nThe original MATLAB file was converted to multiple CSV files \n\nThe original SAT-4 and SAT-6 airborne datasets can be found here:<br>\n[http://csc.lsu.edu/~saikat/deepsat/][2]<br>\n\nThanks to:<br>\nSaikat Basu, Robert DiBiano, Manohar Karki and Supratik Mukhopadhyay, Louisiana State University\nSangram Ganguly, Bay Area Environmental Research Institute/NASA Ames Research Center\nRamakrishna R. Nemani, NASA Advanced Supercomputing Division, NASA Ames Research Center\n\n\n\n  [1]: http://csc.lsu.edu/~saikat/deepsat/images/sat_img.png\n  [2]: http://csc.lsu.edu/~saikat/deepsat/",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "art",
    "geography",
    "computer science",
    "programming",
    "image",
    "multiclass classification"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}