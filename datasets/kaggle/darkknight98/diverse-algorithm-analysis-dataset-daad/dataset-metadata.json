{
  "id": "darkknight98/diverse-algorithm-analysis-dataset-daad",
  "id_no": 813365,
  "datasetSlugNullable": "diverse-algorithm-analysis-dataset-daad",
  "ownerUserNullable": "darkknight98",
  "usabilityRatingNullable": 0.9117647058823529,
  "titleNullable": "Diverse Algorithm Analysis Dataset - DAAD",
  "subtitleNullable": "Comprehensive dataset including Images, Time Series & Categorical data",
  "descriptionNullable": "### Context\n\nObtaining all types of data (*Numerical, Temporal, Image, categorical, CSV, Dicom*) in a short and malleable format for quick and easy use was something that I, as a learner, wished I had. The huge and complex nature of publicly available datasets were sometimes too intimidating for beginners and for professionals when they want to do just a quick sanity check for their algorithm on another dataset. So this dataset aims to solve exactly that problem.\n\nThe ****Diverse Algorithms Analysis Dataset (DAAD)**** contains several different types of datasets all grouped into one for easy access to a learner. It contains concise, and well-documented data to help you jump start your implementations of algorithms.\n\nA user can use this dataset in several ways:\n\n1. Use the datasets individually for your projects, let's say for stock prediction or temperature analysis.\n2. Compare the performance of algorithms on all datasets to analyze the versatility of the algorithm.\n3. Try different Hyper-Parameter Optimization algorithms on each of the datasets and see which framework best suits your needs.\n4. You may have a larger, more voluminous dataset which is similar to one of the datasets available here, but you want to perform a trial run on this data quickly so that you know you're doing the right thing with your original data.\n5. Perform a competitive analysis of several algorithms on different datasets to check their robustness.\n\n### Content\nThis dataset is intended to be dynamic. But the current version contains the following:\n\n1. **Pokemon__categorical:** A CSV file that contains different information relating to every pokemon in a categorical format. Information such as abilities, attack, defense, points, etc is present. The objective is to predict whether a pokemon is legendary or not. So a typical \nbinary classification problem.\n\n2. **Pokemon__numerical:** A CSV file pretty similar to Pokemon_categorical but with a lesser number of categorical features and more stress on numeric scores like points, HP, Generation including attack, special attack, defense scores, etc. The objective is once again a binary classification of whether a pokemon is legendary or not.\n\n3. **Stock__forecasting:** A CSV file that contains the stock price of a multinational company obtained over a continuous rolling 2 year period. Ideal for beginners to dive into stock-prediction and for training simple to complex regression models. Best results obtained using sequence training models like RNNs, LSTMs or GRUs \n\n4. **Temperatures__3__years:** A CSV file that contains the daily minimum temperatures of a city recorded over a rolling 3 year period. The objective can be modeled according to user needs. ou may choose to predict the temperatures for the next month or a day-wise prediction as well. This dataset performs very well with LSTMs and shows considerable performance on boosting algorithms.\n\n5. **License plate number detection:** This dataset contains about 120 train and 50 test images ( a compact version of a larger dataset) of number plates of cars. The user can try out several ROI-pooling, Image localization and detection techniques along with implementing some cool OCRs on the dataset. The small size of the dataset can help you train faster and help you generalize easily. Ideal for a beginner to Computer Vision.\n\n6. **University_Recruitment_Data:** This contains information which encompasses the bio-data of a student and his/her credentials. The work experience, degree percentage, and other such relevant factors are present. The objective is basically to solve a simple binary classification problem of whether the student will be recruited or not. \n\n\n(to be contd...)\n\n### Inspiration\n\nAs I initially mentioned, it would have been a valuable resource for me to have such a dataset where I can train and deploy my models with relative ease and have to worry less about scavenging through several data sources. I intend DAAD to be a repository that can facilitate the needs of all types of ML enthusiasts/developers. I would appreciate contributions from my fellow kagglers too in enriching this dataset making it reachable to all and ideal for simple and quick implementations without losing out on the reliability factor as in huge datasets.\n\n\nHave Fun !",
  "datasetId": 813365,
  "datasetSlug": "diverse-algorithm-analysis-dataset-daad",
  "hasDatasetSlug": true,
  "ownerUser": "darkknight98",
  "hasOwnerUser": true,
  "usabilityRating": 0.9117647058823529,
  "hasUsabilityRating": true,
  "totalViews": 5912,
  "totalVotes": 15,
  "totalDownloads": 239,
  "title": "Diverse Algorithm Analysis Dataset - DAAD",
  "hasTitle": true,
  "subtitle": "Comprehensive dataset including Images, Time Series & Categorical data",
  "hasSubtitle": true,
  "description": "### Context\n\nObtaining all types of data (*Numerical, Temporal, Image, categorical, CSV, Dicom*) in a short and malleable format for quick and easy use was something that I, as a learner, wished I had. The huge and complex nature of publicly available datasets were sometimes too intimidating for beginners and for professionals when they want to do just a quick sanity check for their algorithm on another dataset. So this dataset aims to solve exactly that problem.\n\nThe ****Diverse Algorithms Analysis Dataset (DAAD)**** contains several different types of datasets all grouped into one for easy access to a learner. It contains concise, and well-documented data to help you jump start your implementations of algorithms.\n\nA user can use this dataset in several ways:\n\n1. Use the datasets individually for your projects, let's say for stock prediction or temperature analysis.\n2. Compare the performance of algorithms on all datasets to analyze the versatility of the algorithm.\n3. Try different Hyper-Parameter Optimization algorithms on each of the datasets and see which framework best suits your needs.\n4. You may have a larger, more voluminous dataset which is similar to one of the datasets available here, but you want to perform a trial run on this data quickly so that you know you're doing the right thing with your original data.\n5. Perform a competitive analysis of several algorithms on different datasets to check their robustness.\n\n### Content\nThis dataset is intended to be dynamic. But the current version contains the following:\n\n1. **Pokemon__categorical:** A CSV file that contains different information relating to every pokemon in a categorical format. Information such as abilities, attack, defense, points, etc is present. The objective is to predict whether a pokemon is legendary or not. So a typical \nbinary classification problem.\n\n2. **Pokemon__numerical:** A CSV file pretty similar to Pokemon_categorical but with a lesser number of categorical features and more stress on numeric scores like points, HP, Generation including attack, special attack, defense scores, etc. The objective is once again a binary classification of whether a pokemon is legendary or not.\n\n3. **Stock__forecasting:** A CSV file that contains the stock price of a multinational company obtained over a continuous rolling 2 year period. Ideal for beginners to dive into stock-prediction and for training simple to complex regression models. Best results obtained using sequence training models like RNNs, LSTMs or GRUs \n\n4. **Temperatures__3__years:** A CSV file that contains the daily minimum temperatures of a city recorded over a rolling 3 year period. The objective can be modeled according to user needs. ou may choose to predict the temperatures for the next month or a day-wise prediction as well. This dataset performs very well with LSTMs and shows considerable performance on boosting algorithms.\n\n5. **License plate number detection:** This dataset contains about 120 train and 50 test images ( a compact version of a larger dataset) of number plates of cars. The user can try out several ROI-pooling, Image localization and detection techniques along with implementing some cool OCRs on the dataset. The small size of the dataset can help you train faster and help you generalize easily. Ideal for a beginner to Computer Vision.\n\n6. **University_Recruitment_Data:** This contains information which encompasses the bio-data of a student and his/her credentials. The work experience, degree percentage, and other such relevant factors are present. The objective is basically to solve a simple binary classification problem of whether the student will be recruited or not. \n\n\n(to be contd...)\n\n### Inspiration\n\nAs I initially mentioned, it would have been a valuable resource for me to have such a dataset where I can train and deploy my models with relative ease and have to worry less about scavenging through several data sources. I intend DAAD to be a repository that can facilitate the needs of all types of ML enthusiasts/developers. I would appreciate contributions from my fellow kagglers too in enriching this dataset making it reachable to all and ideal for simple and quick implementations without losing out on the reliability factor as in huge datasets.\n\n\nHave Fun !",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "categorical",
    "earth and nature",
    "business",
    "computer science",
    "time series analysis",
    "image"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}