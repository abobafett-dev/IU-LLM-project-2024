{
  "id": "dgokeeffe/specific-language-impairment",
  "id_no": 1098,
  "datasetSlugNullable": "specific-language-impairment",
  "ownerUserNullable": "dgokeeffe",
  "usabilityRatingNullable": 0.7058823529411765,
  "titleNullable": "Diagnose Specific Language Impairment in Children",
  "subtitleNullable": "Explore and create models using data derived from transcripts in CHILDES",
  "descriptionNullable": "# Context \n\nSpecific Language Impairment  is a condition that effects roughly 7% of 5-year old children. It is characterised by a lack of language ability in comparison to your peers but with no obvious mental or physical disability. Diagnosis can tend to be laborious, thus automating this process using NLP and ML techniques might be of interest to paediatricians and speech pathologists. \n\n# Content\n\nThis study evaluated three datasets obtained via the CHILDES project. All the datasets consist of narratives\nfrom a child attempting to complete a wordless picture task. The choice to use only narrative corpora was based on previous research which indicated it has the best ability to distinguish a language impairment in children. The first dataset consists of samples from British adolescents, the second from Canadian children aged 4 to 9, and the third from U.S. children aged 4 to 12. \n\nUnfortunately finding transcript data of this kind is rare, I have tried to find more data to no avail, so 1163 samples will have to do.\n\n## Conti-Ramsden 4: \n\nThe Conti-Ramsden 4 dataset was collected for a study to assess the effectiveness of narrative tests on adolescents. It consists of 99 TD and 19 SLI samples of children between the ages of 13.10 and 15.90. Ideally all the corpora would only be from children, as SLI is most prominent in children aged five years old, and is best detected early. However, it was included to enable a direct comparison between classifiers created by Gabani and this study.\n\nThe corpus contains transcripts of a story telling task based on Mayer\u2019s wordless picture book \u201cFrog, Where Are You\u201d. The children first viewed the picture book in their own time before being prompted to retell the story in the past tense. If the children started telling the story in the present tense the interviewer would prompt them with the phrase \u201cWhat happened next?\u201d in order to attempt to revert them back to the past tense. If they failed to start to retell the story in the past tense after two prompts no further prompts were made.\n\n## ENNI \n\nThe ENNI dataset was collected during the course of a study aimed at identifying SLI children using\nan index of storytelling ability based on the story grammar model. The corpus consists of 300 TD and 77 SLI samples of children aged between 4 and 9 years old. Each child was presented with two wordless picture stories with one more complicated than the other. Unlike Conti-Ramsden 4 the examiner held the book and turned the page after the child appeared to be finished telling the story for a particular picture. The children were also given the opportunity to practice on a training story, where the examiner gave more explicit prompts to the child about what to do.\n\n## Gillam\n\nThe Gillam dataset is based on another tool for narrative assessment known as \u201cThe Test of Narrative\nLanguage (TNL). It consists of 250 language impaired children, and 520 controls aged between 5 and 12. A detailed description of each of the participants does not exist. The TNL consists of four storytelling tasks, the first is a recall of a script based story, the rest being wordless picture books. The first picture set depicts a story with a main protagonist having repeated attempts at the goal, and the rest are single picture stories. The single picture stories require more input from the child, and thus is better suited to older children. The TNL appears to be intermediary in difficulty compared to ENNI.\n\n## Features\n\nAttribute | Name | Description  \n------------------------------------\n**Y**                         | *The label*  | 0 for typically developing children 1 for language impaired    \n**child_TNW**         | *Total Number of Words* | The total number of words in the transcript  \n**child_TNS**          | *Total Number of Sentences* | Children with SLI are more likely to speak in short sentences  \n**group**                 | *Same as Y* | BEWARE: Is the same as Y but easier to graph in Python and R   \n**examiner_TNW** | *Total Number of Words spoken by the examiner* | Children with SLI are more likely to need support  \n**freq_ttr**                     | *Frequency of Word Types to Word Token Ratio* | Divides word types by word tokens and provides a rough measure of lexical diversity.  \n**r_2_i_verbs**| *Ratio of raw to inflected verbs* | Children with SLI often have difficulty with the morphemes -ed, -s, be, and do. This results in the use of raw verbs instead of their inflected forms.   \n**mor_words** | *Number of words in the %mor tier* |   \n**num_pos_tags** | *Number of different Part-of-Speech tags* |  \n**n_dos** | *Number of Do's* | The number of time the word 'do' is used  \n**repetition** | *Number of Repetitions*  | Counts the number of repetitions as tagged in the CHAT format inside square brackets e.g., milk milk milk milk = milk [x 4]  \n**retracing** | *Number of Retracings* | A retracing is defined as when a speaker abandons an utterance but then continues again.  \n**fillers** | *Number of Fillers* | Counts the number of fillers used in total. A list of fillers was created by searching through the entire corpus (all 1038 samples) for all common variants of fillers such as um, umm, uh, uhh, etc.  \n**s_1g_ppl** | *Perplexity of 1-gram SLI* | The perplexity of this sample in comparison to a language model trained on all the SLI group for this corpora except the sample  \n**s_2g_ppl** | *Perplexity of 2-gram SLI* | Same as above but with a 2-gram LM  \n**s_3g_ppl** | *Perplexity of 3-gram SLI* | Same as above but with a 3-gram LM  \n**d_1g_ppl** | *Perplexity of 1-gram TD* | The perplexity of this sample in comparison to a language model trained on all the TD group for this corpora except the sample   \n**d_2g_ppl** | *Perplexity of 2-gram TD* | Same as above but with a 2-gram LM  \n**d_3g_ppl** | *Perplexity of 3-gram TD* | Same as above but with a 3-gram LM  \n**z_mlu_sli** | *Sample Z-score using SLI group's Mean Length of Utterance* |   \n**z_mlu_td** | *Sample Z-score using TD group's Mean Length of Utterance* |  \n**z_ndw_sli** | *Sample Z-score using SLI group's Raw:Inflected Verbs Ratio*  |  \n**z_ndw_td** | *Sample Z-score using TD group's Raw:Inflected Verbs Ratio* |  \n**z_ipsyn_sli** | *Sample Z-score using SLI group's Developmental Sentence Score* |  \n**z_ipsyn_td** | *Sample Z-score using TD group's Developmental Sentence Score* |  \n**z_utts_sli** |*Sample Z-score using SLI group's Number of Verb Utterances* |  \n**z_utts_td** |*Sample Z-score using TD group's Number of Verb Utterances* |  \n**average_syl** | *Average number of Syllables per word* |   I used a technique based on the number of vowels to calculate the number of syllables in a word    \n**mlu_words** | *Mean Length of Utterance of Words*  |  See https://en.wikipedia.org/wiki/Mean_length_of_utterance    \n**mlu_morphemes** |  *Mean Length of Utterance of Morphemes* |   Same as above but for sentences instead of words    \n**mlu100_utts** | *Mean Length of Utterance of 1st 100 words*  |   Only use the first 100 words to calculate MLU    \n**verb_utt** | *Number of verb utterances* |   Number of utterances consisting of verbs    \n**dss** | *Developmental Sentence Score* |   A fancy measure of sentence complexity    \n**ipsyn_total** | *Index of Productive Syntax Score* |  Another fancy measure of sentence complexity    \n    \nThe following fields are counts of instances of Brown's Stages of Morphological Development (see https://www.speech-language-therapy.com/index.php?option=com_content&view=article&id=33:brown&catid=2:uncategorised&Itemid=117)   \n \n**present_progressive**   \n**propositions_in**  \n**propositions_on**  \n**plural_s**   \n**irregular_past_tense**  \n**possessive_s**  \n**uncontractible_copula**  \n**articles**  \n**regular_past_ed**  \n**regular_3rd_person_s**  \n**irregular_3rd_person**  \n**uncontractible_aux**  \n**contractible_copula**    \n**contractible_aux**  \n\nBack to normal     \n\n\n**word_errors** |  *Number of Word Errors* | As marked in the transcripts    \n**f_k** | *Flesch-Kincaid Score* | See https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests    \n**n_v** | *Number of Nouns followed immediately by a verb*      \n**n_aux** | *Number of Nouns followed immediately by an Auxillary verb*     \n**n_3s_v** | *Number of Third Singular Nouns followed immediately by a verb*     \n**det_n_pl** | * Number of Determinant Nouns followed by a Personal Pronoun*      \n**det_pl_n** | * Number of Determinant Pronouns followed by a Noun     \n**pro_aux** | * Pronouns followed by Auxillary Verb*     \n**pro_3s_v** | * 3rd. singular nominative pronoun followed by Verb*      \n**total_error** | *Total number of morphosyntactic errors* | Sum of the columns from nouns verbs down      \n\nThis table will take some time to finish, will get to it within a few days\n\n# Past Research\nI have spent the last few months playing around with this data, I have uploaded it here mainly to speed up the computation of the analysis I have already done. But I'm excited to see what other people can do with this. There are some nice graphs to be made; especially using the MLU attributes.\n\nThus far using the combined corpora the best I have managed to get in terms of creating a predictive classifier is using Neural Networks with Feature Extraction and SMOTE to get a mean ROC of 0.8709 under 10-repeated-10-k-folds CV. You'll find that Random Forest and SVM with an RBF kernel do comparably well with SMOTE.\n\n# Acknowledgements\n\nAll the data here was derived by me using the open source transcripts provided on the CHILDES Talkbank (http://childes.talkbank.org/). The methods I used are very close to those in: \n\nK. Gabani, T. Solorio, Y. Liu, K.-n. Hassanali, and C. A. Dollaghan, \u201cExploring a corpus-based approach for detecting language impairment in monolingual english-speaking children,\u201d Artificial Intelligence in Medicine, vol. 53, no. 3, pp. 161\u2013170, 2011.\n\nConti-4:\nD. Wetherell, N. Botting, and G. Conti-Ramsden, \u201cNarrative skills in adolescents with a history of SLI in relation to non-verbal IQ scores,\u201d Child Language Teaching and Therapy, vol. 23, no. 1, pp. 95\u2013113, 2007.\n\nENNI:\nP. Schneider, D. Hayward, and R. V. Dub, \u201cStorytelling from pictures using the Edmonton Narrative Norms Instrument,\u201d 2006.\n\nGillam:\nR. Gillam and N. Pearson, Test of Narrative Language. Austin, TX: Pro-Ed Inc., 2004.\n\n# Inspiration\n\nI'm hoping somebody can beat my score. I'm keen to learn more and see if this can become anything that might be of use to some child/family someday.",
  "datasetId": 1098,
  "datasetSlug": "specific-language-impairment",
  "hasDatasetSlug": true,
  "ownerUser": "dgokeeffe",
  "hasOwnerUser": true,
  "usabilityRating": 0.7058823529411765,
  "hasUsabilityRating": true,
  "totalViews": 28659,
  "totalVotes": 55,
  "totalDownloads": 1675,
  "title": "Diagnose Specific Language Impairment in Children",
  "hasTitle": true,
  "subtitle": "Explore and create models using data derived from transcripts in CHILDES",
  "hasSubtitle": true,
  "description": "# Context \n\nSpecific Language Impairment  is a condition that effects roughly 7% of 5-year old children. It is characterised by a lack of language ability in comparison to your peers but with no obvious mental or physical disability. Diagnosis can tend to be laborious, thus automating this process using NLP and ML techniques might be of interest to paediatricians and speech pathologists. \n\n# Content\n\nThis study evaluated three datasets obtained via the CHILDES project. All the datasets consist of narratives\nfrom a child attempting to complete a wordless picture task. The choice to use only narrative corpora was based on previous research which indicated it has the best ability to distinguish a language impairment in children. The first dataset consists of samples from British adolescents, the second from Canadian children aged 4 to 9, and the third from U.S. children aged 4 to 12. \n\nUnfortunately finding transcript data of this kind is rare, I have tried to find more data to no avail, so 1163 samples will have to do.\n\n## Conti-Ramsden 4: \n\nThe Conti-Ramsden 4 dataset was collected for a study to assess the effectiveness of narrative tests on adolescents. It consists of 99 TD and 19 SLI samples of children between the ages of 13.10 and 15.90. Ideally all the corpora would only be from children, as SLI is most prominent in children aged five years old, and is best detected early. However, it was included to enable a direct comparison between classifiers created by Gabani and this study.\n\nThe corpus contains transcripts of a story telling task based on Mayer\u2019s wordless picture book \u201cFrog, Where Are You\u201d. The children first viewed the picture book in their own time before being prompted to retell the story in the past tense. If the children started telling the story in the present tense the interviewer would prompt them with the phrase \u201cWhat happened next?\u201d in order to attempt to revert them back to the past tense. If they failed to start to retell the story in the past tense after two prompts no further prompts were made.\n\n## ENNI \n\nThe ENNI dataset was collected during the course of a study aimed at identifying SLI children using\nan index of storytelling ability based on the story grammar model. The corpus consists of 300 TD and 77 SLI samples of children aged between 4 and 9 years old. Each child was presented with two wordless picture stories with one more complicated than the other. Unlike Conti-Ramsden 4 the examiner held the book and turned the page after the child appeared to be finished telling the story for a particular picture. The children were also given the opportunity to practice on a training story, where the examiner gave more explicit prompts to the child about what to do.\n\n## Gillam\n\nThe Gillam dataset is based on another tool for narrative assessment known as \u201cThe Test of Narrative\nLanguage (TNL). It consists of 250 language impaired children, and 520 controls aged between 5 and 12. A detailed description of each of the participants does not exist. The TNL consists of four storytelling tasks, the first is a recall of a script based story, the rest being wordless picture books. The first picture set depicts a story with a main protagonist having repeated attempts at the goal, and the rest are single picture stories. The single picture stories require more input from the child, and thus is better suited to older children. The TNL appears to be intermediary in difficulty compared to ENNI.\n\n## Features\n\nAttribute | Name | Description  \n------------------------------------\n**Y**                         | *The label*  | 0 for typically developing children 1 for language impaired    \n**child_TNW**         | *Total Number of Words* | The total number of words in the transcript  \n**child_TNS**          | *Total Number of Sentences* | Children with SLI are more likely to speak in short sentences  \n**group**                 | *Same as Y* | BEWARE: Is the same as Y but easier to graph in Python and R   \n**examiner_TNW** | *Total Number of Words spoken by the examiner* | Children with SLI are more likely to need support  \n**freq_ttr**                     | *Frequency of Word Types to Word Token Ratio* | Divides word types by word tokens and provides a rough measure of lexical diversity.  \n**r_2_i_verbs**| *Ratio of raw to inflected verbs* | Children with SLI often have difficulty with the morphemes -ed, -s, be, and do. This results in the use of raw verbs instead of their inflected forms.   \n**mor_words** | *Number of words in the %mor tier* |   \n**num_pos_tags** | *Number of different Part-of-Speech tags* |  \n**n_dos** | *Number of Do's* | The number of time the word 'do' is used  \n**repetition** | *Number of Repetitions*  | Counts the number of repetitions as tagged in the CHAT format inside square brackets e.g., milk milk milk milk = milk [x 4]  \n**retracing** | *Number of Retracings* | A retracing is defined as when a speaker abandons an utterance but then continues again.  \n**fillers** | *Number of Fillers* | Counts the number of fillers used in total. A list of fillers was created by searching through the entire corpus (all 1038 samples) for all common variants of fillers such as um, umm, uh, uhh, etc.  \n**s_1g_ppl** | *Perplexity of 1-gram SLI* | The perplexity of this sample in comparison to a language model trained on all the SLI group for this corpora except the sample  \n**s_2g_ppl** | *Perplexity of 2-gram SLI* | Same as above but with a 2-gram LM  \n**s_3g_ppl** | *Perplexity of 3-gram SLI* | Same as above but with a 3-gram LM  \n**d_1g_ppl** | *Perplexity of 1-gram TD* | The perplexity of this sample in comparison to a language model trained on all the TD group for this corpora except the sample   \n**d_2g_ppl** | *Perplexity of 2-gram TD* | Same as above but with a 2-gram LM  \n**d_3g_ppl** | *Perplexity of 3-gram TD* | Same as above but with a 3-gram LM  \n**z_mlu_sli** | *Sample Z-score using SLI group's Mean Length of Utterance* |   \n**z_mlu_td** | *Sample Z-score using TD group's Mean Length of Utterance* |  \n**z_ndw_sli** | *Sample Z-score using SLI group's Raw:Inflected Verbs Ratio*  |  \n**z_ndw_td** | *Sample Z-score using TD group's Raw:Inflected Verbs Ratio* |  \n**z_ipsyn_sli** | *Sample Z-score using SLI group's Developmental Sentence Score* |  \n**z_ipsyn_td** | *Sample Z-score using TD group's Developmental Sentence Score* |  \n**z_utts_sli** |*Sample Z-score using SLI group's Number of Verb Utterances* |  \n**z_utts_td** |*Sample Z-score using TD group's Number of Verb Utterances* |  \n**average_syl** | *Average number of Syllables per word* |   I used a technique based on the number of vowels to calculate the number of syllables in a word    \n**mlu_words** | *Mean Length of Utterance of Words*  |  See https://en.wikipedia.org/wiki/Mean_length_of_utterance    \n**mlu_morphemes** |  *Mean Length of Utterance of Morphemes* |   Same as above but for sentences instead of words    \n**mlu100_utts** | *Mean Length of Utterance of 1st 100 words*  |   Only use the first 100 words to calculate MLU    \n**verb_utt** | *Number of verb utterances* |   Number of utterances consisting of verbs    \n**dss** | *Developmental Sentence Score* |   A fancy measure of sentence complexity    \n**ipsyn_total** | *Index of Productive Syntax Score* |  Another fancy measure of sentence complexity    \n    \nThe following fields are counts of instances of Brown's Stages of Morphological Development (see https://www.speech-language-therapy.com/index.php?option=com_content&view=article&id=33:brown&catid=2:uncategorised&Itemid=117)   \n \n**present_progressive**   \n**propositions_in**  \n**propositions_on**  \n**plural_s**   \n**irregular_past_tense**  \n**possessive_s**  \n**uncontractible_copula**  \n**articles**  \n**regular_past_ed**  \n**regular_3rd_person_s**  \n**irregular_3rd_person**  \n**uncontractible_aux**  \n**contractible_copula**    \n**contractible_aux**  \n\nBack to normal     \n\n\n**word_errors** |  *Number of Word Errors* | As marked in the transcripts    \n**f_k** | *Flesch-Kincaid Score* | See https://en.wikipedia.org/wiki/Flesch%E2%80%93Kincaid_readability_tests    \n**n_v** | *Number of Nouns followed immediately by a verb*      \n**n_aux** | *Number of Nouns followed immediately by an Auxillary verb*     \n**n_3s_v** | *Number of Third Singular Nouns followed immediately by a verb*     \n**det_n_pl** | * Number of Determinant Nouns followed by a Personal Pronoun*      \n**det_pl_n** | * Number of Determinant Pronouns followed by a Noun     \n**pro_aux** | * Pronouns followed by Auxillary Verb*     \n**pro_3s_v** | * 3rd. singular nominative pronoun followed by Verb*      \n**total_error** | *Total number of morphosyntactic errors* | Sum of the columns from nouns verbs down      \n\nThis table will take some time to finish, will get to it within a few days\n\n# Past Research\nI have spent the last few months playing around with this data, I have uploaded it here mainly to speed up the computation of the analysis I have already done. But I'm excited to see what other people can do with this. There are some nice graphs to be made; especially using the MLU attributes.\n\nThus far using the combined corpora the best I have managed to get in terms of creating a predictive classifier is using Neural Networks with Feature Extraction and SMOTE to get a mean ROC of 0.8709 under 10-repeated-10-k-folds CV. You'll find that Random Forest and SVM with an RBF kernel do comparably well with SMOTE.\n\n# Acknowledgements\n\nAll the data here was derived by me using the open source transcripts provided on the CHILDES Talkbank (http://childes.talkbank.org/). The methods I used are very close to those in: \n\nK. Gabani, T. Solorio, Y. Liu, K.-n. Hassanali, and C. A. Dollaghan, \u201cExploring a corpus-based approach for detecting language impairment in monolingual english-speaking children,\u201d Artificial Intelligence in Medicine, vol. 53, no. 3, pp. 161\u2013170, 2011.\n\nConti-4:\nD. Wetherell, N. Botting, and G. Conti-Ramsden, \u201cNarrative skills in adolescents with a history of SLI in relation to non-verbal IQ scores,\u201d Child Language Teaching and Therapy, vol. 23, no. 1, pp. 95\u2013113, 2007.\n\nENNI:\nP. Schneider, D. Hayward, and R. V. Dub, \u201cStorytelling from pictures using the Edmonton Narrative Norms Instrument,\u201d 2006.\n\nGillam:\nR. Gillam and N. Pearson, Test of Narrative Language. Austin, TX: Pro-Ed Inc., 2004.\n\n# Inspiration\n\nI'm hoping somebody can beat my score. I'm keen to learn more and see if this can become anything that might be of use to some child/family someday.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "games",
    "healthcare",
    "social science",
    "linguistics"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}