{
  "id": "divyapatel4/cord-df",
  "id_no": 2733267,
  "datasetSlugNullable": "cord-df",
  "ownerUserNullable": "divyapatel4",
  "usabilityRatingNullable": 0.5294117647058824,
  "titleNullable": "cord_df",
  "subtitleNullable": "Cleaned and Preprocessed CORD-19 dataset",
  "descriptionNullable": "The CORD-19 preprocessed dataset is a collection of over 20,000 scientific articles related to COVID-19 and the coronavirus family of viruses. The data has been cleaned and preprocessed to make it more accessible for natural languages processing tasks, such as text classification and information retrieval. The articles are sourced from reputable scientific journals and publications. They cover a wide range of topics related to COVID-19 from the CORD-19 dataset, including virology, epidemiology, clinical treatments, and public health policy.\n\n**Data Preprocessing**\n\nThe CORD-19 dataset contains a large amount of data, which makes it difficult to analyze. In order to make the dataset more manageable, we will perform some preprocessing steps to remove unnecessary information and reduce the size of the dataset. The preprocessing steps include removing duplicate articles and removing articles that are not in English. The preprocessing steps are described in more detail below.  \n\u2022 **Tokenization**: Tokenization is the process of breaking down a sentence or a text into individual words or tokens. It is a crucial step in natural language processing (NLP) as it helps in identifying the syntactic structure of the text and aids in further analysis and text classification. \n\u2022 **Converting words to lowercase**: Converting words to lowercase is an important step in preprocessing as it helps standardise the text and reduce the data\u2019s dimensionality. It also helps reduce the number of unique words in the text, which can improve the model\u2019s efficiency. For example, the words \u201dcoronavirus\u201d and \u201dCoronavirus\u201d are the same word but are represented differently. By converting all words to lowercase, it helps in reducing the number of unique words in the text and improves the efficiency of the model. \n\u2022 **Removing Numbers**: Removing numbers from the text helps in simplifying the data for further analysis. Numbers do not add any value to the text and can be removed without affecting the overall meaning of the text. \n\u2022 **Contraction Expansion**: Contraction Expansion is the process of expanding contractions such as \u201ddidn\u2019t\u201d to \u201ddid not \u201d in the text. This step is important as it helps better understand the text\u2019s meaning. This is because contractions are informal and may be difficult to understand for NLP models. Expanding contractions makes it easier for NLP models to understand the text and improve the model\u2019s overall performance. \n\u2022 **Lemmatization**: Lemmatization is the process of reducing words to their base or root form(e.g. \u201drunning\u201d                                  becomes \u201drun\u201d). This process is important as it helps standardize the text and reduce the dimensionality of the data. It also helps in understanding the meaning of the text, as different forms of a word may have different meanings. For example, \u201drunning\u201d and \u201dran\u201d have different meanings, but they are derived from the same root word \u201drun\u201d. \n\u2022 **Removing Punctuations**: Removing punctuation marks (e.g. \u201d, \u201d, \u201d.\u201d, \u201d!\u201d, etc.) from the text is an important step in preprocessing as it helps in simplifying the data for further analysis. Punctuation marks do not carry any meaning and can add noise to the data. Removing them can improve the analysis\u2019s efficiency and the model\u2019s overall performance. \n\u2022 **Stop-Words Removal: ** Stop-words removal is the process of removing commonly used words that do not carry much meaning(e.g. \u201dis \u201d, \u201dand \u201d, \u201dthe\u201d, etc.) from the text. This step is important as it helps reduce the data\u2019s dimensionality and improve the analysis\u2019s efficiency. Stop-words do not carry any meaning and can add noise to the data. Removing them can improve the performance of the model and make it easier to understand the text. \n\u2022 **Handling N-grams**: N-grams are a sequence of n words that occur together in a text. N-grams can be used to improve the performance of the model by providing more context to the model. For example, mental health is a phrase that is used to describe the state of a person\u2019s mental well-being. If we use the word \u201dmental\u201d in isolation, it may not be clear what the word means. However, if we use the phrase \u201dmental health\u201d, it is clear that the word \u201dmental\u201d is used to describe the state of a person\u2019s mental well-being. N-grams can be used to improve the performance of the model by providing more context to the model. Therefore it is important to identify the most important n-grams in the text and use them to improve the model\u2019s performance. Also, it is necessary to process n-grams in descending order. For example, we must process tri-grams before bi-grams. This is because tri-grams contain information about bi-grams, and bi-grams contain information about unigrams. For example, we must merge \u2019acute respiratory distress syndrome ards\u2019 into a 5-gram before merging \u2019acute respiratory distress syndrome\u2019 into a 4-gram.\n",
  "datasetId": 2733267,
  "datasetSlug": "cord-df",
  "hasDatasetSlug": true,
  "ownerUser": "divyapatel4",
  "hasOwnerUser": true,
  "usabilityRating": 0.5294117647058824,
  "hasUsabilityRating": true,
  "totalViews": 1061,
  "totalVotes": 2,
  "totalDownloads": 132,
  "title": "cord_df",
  "hasTitle": true,
  "subtitle": "Cleaned and Preprocessed CORD-19 dataset",
  "hasSubtitle": true,
  "description": "The CORD-19 preprocessed dataset is a collection of over 20,000 scientific articles related to COVID-19 and the coronavirus family of viruses. The data has been cleaned and preprocessed to make it more accessible for natural languages processing tasks, such as text classification and information retrieval. The articles are sourced from reputable scientific journals and publications. They cover a wide range of topics related to COVID-19 from the CORD-19 dataset, including virology, epidemiology, clinical treatments, and public health policy.\n\n**Data Preprocessing**\n\nThe CORD-19 dataset contains a large amount of data, which makes it difficult to analyze. In order to make the dataset more manageable, we will perform some preprocessing steps to remove unnecessary information and reduce the size of the dataset. The preprocessing steps include removing duplicate articles and removing articles that are not in English. The preprocessing steps are described in more detail below.  \n\u2022 **Tokenization**: Tokenization is the process of breaking down a sentence or a text into individual words or tokens. It is a crucial step in natural language processing (NLP) as it helps in identifying the syntactic structure of the text and aids in further analysis and text classification. \n\u2022 **Converting words to lowercase**: Converting words to lowercase is an important step in preprocessing as it helps standardise the text and reduce the data\u2019s dimensionality. It also helps reduce the number of unique words in the text, which can improve the model\u2019s efficiency. For example, the words \u201dcoronavirus\u201d and \u201dCoronavirus\u201d are the same word but are represented differently. By converting all words to lowercase, it helps in reducing the number of unique words in the text and improves the efficiency of the model. \n\u2022 **Removing Numbers**: Removing numbers from the text helps in simplifying the data for further analysis. Numbers do not add any value to the text and can be removed without affecting the overall meaning of the text. \n\u2022 **Contraction Expansion**: Contraction Expansion is the process of expanding contractions such as \u201ddidn\u2019t\u201d to \u201ddid not \u201d in the text. This step is important as it helps better understand the text\u2019s meaning. This is because contractions are informal and may be difficult to understand for NLP models. Expanding contractions makes it easier for NLP models to understand the text and improve the model\u2019s overall performance. \n\u2022 **Lemmatization**: Lemmatization is the process of reducing words to their base or root form(e.g. \u201drunning\u201d                                  becomes \u201drun\u201d). This process is important as it helps standardize the text and reduce the dimensionality of the data. It also helps in understanding the meaning of the text, as different forms of a word may have different meanings. For example, \u201drunning\u201d and \u201dran\u201d have different meanings, but they are derived from the same root word \u201drun\u201d. \n\u2022 **Removing Punctuations**: Removing punctuation marks (e.g. \u201d, \u201d, \u201d.\u201d, \u201d!\u201d, etc.) from the text is an important step in preprocessing as it helps in simplifying the data for further analysis. Punctuation marks do not carry any meaning and can add noise to the data. Removing them can improve the analysis\u2019s efficiency and the model\u2019s overall performance. \n\u2022 **Stop-Words Removal: ** Stop-words removal is the process of removing commonly used words that do not carry much meaning(e.g. \u201dis \u201d, \u201dand \u201d, \u201dthe\u201d, etc.) from the text. This step is important as it helps reduce the data\u2019s dimensionality and improve the analysis\u2019s efficiency. Stop-words do not carry any meaning and can add noise to the data. Removing them can improve the performance of the model and make it easier to understand the text. \n\u2022 **Handling N-grams**: N-grams are a sequence of n words that occur together in a text. N-grams can be used to improve the performance of the model by providing more context to the model. For example, mental health is a phrase that is used to describe the state of a person\u2019s mental well-being. If we use the word \u201dmental\u201d in isolation, it may not be clear what the word means. However, if we use the phrase \u201dmental health\u201d, it is clear that the word \u201dmental\u201d is used to describe the state of a person\u2019s mental well-being. N-grams can be used to improve the performance of the model by providing more context to the model. Therefore it is important to identify the most important n-grams in the text and use them to improve the model\u2019s performance. Also, it is necessary to process n-grams in descending order. For example, we must process tri-grams before bi-grams. This is because tri-grams contain information about bi-grams, and bi-grams contain information about unigrams. For example, we must merge \u2019acute respiratory distress syndrome ards\u2019 into a 5-gram before merging \u2019acute respiratory distress syndrome\u2019 into a 4-gram.\n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "nlp",
    "text mining",
    "clustering",
    "covid19"
  ],
  "licenses": [
    {
      "nameNullable": "unknown",
      "name": "unknown",
      "hasName": true
    }
  ],
  "collaborators": [
    {
      "username": "omp217",
      "role": "writer"
    },
    {
      "username": "vanshparikh",
      "role": "writer"
    }
  ],
  "data": []
}