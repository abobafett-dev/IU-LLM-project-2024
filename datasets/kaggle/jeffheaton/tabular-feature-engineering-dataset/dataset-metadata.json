{
  "id": "jeffheaton/tabular-feature-engineering-dataset",
  "id_no": 944785,
  "datasetSlugNullable": "tabular-feature-engineering-dataset",
  "ownerUserNullable": "jeffheaton",
  "usabilityRatingNullable": 0.8823529411764706,
  "titleNullable": "Tabular Feature Engineering Dataset",
  "subtitleNullable": "What equations are most difficult for various model types to synthesize?",
  "descriptionNullable": "Machine learning models, such as neural networks, decision trees, random forests, and gradient boosting machines, accept a feature vector, and provide a prediction.  These models learn in a supervised fashion where we provide feature vectors with the expected output.  It is common practice to engineer new features from the provided feature set.  Such engineered features will either augment or replace portions of the existing feature vector.  These engineered features are essentially calculated fields based on the values of the other features.  \n\nEngineering such features is primarily a manual, time-consuming task.  Additionally, each type of model will respond differently to different kinds of engineered features.  This paper reports empirical research to demonstrate what kinds of engineered features are best suited to various machine learning model types.  We provide this recommendation by generating several datasets that we designed to benefit from a particular type of engineered feature.  The experiment demonstrates to what degree the machine learning model can synthesize the needed feature on its own.  If a model can synthesize a planned feature, it is not necessary to provide that feature.  The research demonstrated that the studied models do indeed perform differently with various types of engineered features. \n\nWe generated this dataset for the following paper:\n\nHeaton, J. (2016, April). [An Empirical Analysis of Feature Engineering for Predictive Modeling](https://arxiv.org/abs/1701.07852). In *SoutheastCon 2016* (pp. 1-6). IEEE.\n\n### Included Features\nThe dataset is made up of several files that contain the following features:\n* **BMI** (bmi)\n$$ \\frac{m}{h^2} $$\n* **Counts** (counts)\n$$ [0, 1, 1, 0, 0, 1] = 3 $$\n* **Standard Deviation** (div)\n$$ SD = \\sqrt{\\frac{\\sum{|x-\\hat{x}|^2}}{n}} $$\n* **Difference** (diff)\n$$ a-b $$\n* **Distance** (dist)\n$$ \\sqrt{(a - b)^2 + (c - d)^2} $$\n* **Log** (log)\n$$ \\log{a} $$\n* **Max** (max)\n$$ \\max{(a,b,c,d,...)} $$\n* **Polynomial** (poly)\n$$ 1+5x+8x^2 $$\n* **Powers** (pow)\n$$ x^y $$\n* **Quadratic/Roots** (quad)\n$$ \\left| \\frac{-b+\\sqrt{b^2-4ac}}{2a}- \\frac{-b-\\sqrt{b^2-4ac}}{2a} \\right| $$\n* **Ratio of Differences** (r_diff)\n$$ \\frac{a-b}{c-d} $$\n* **Ratio of Polynomial** (r_poly)\n$$ y=\\frac{1}{5x+8x^2} $$\n* **Ratio** (ratio)\n$$ \\frac{a}{b} $$\n* **Product Power Ratio** (rel)\n$$ \\frac{ab}{c^2} $$\n* **Square Root** (sqrt)\n$$ \\sqrt{a} $$\n* **Sum** (sum)\n$$ a+b $$",
  "datasetId": 944785,
  "datasetSlug": "tabular-feature-engineering-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "jeffheaton",
  "hasOwnerUser": true,
  "usabilityRating": 0.8823529411764706,
  "hasUsabilityRating": true,
  "totalViews": 6278,
  "totalVotes": 8,
  "totalDownloads": 325,
  "title": "Tabular Feature Engineering Dataset",
  "hasTitle": true,
  "subtitle": "What equations are most difficult for various model types to synthesize?",
  "hasSubtitle": true,
  "description": "Machine learning models, such as neural networks, decision trees, random forests, and gradient boosting machines, accept a feature vector, and provide a prediction.  These models learn in a supervised fashion where we provide feature vectors with the expected output.  It is common practice to engineer new features from the provided feature set.  Such engineered features will either augment or replace portions of the existing feature vector.  These engineered features are essentially calculated fields based on the values of the other features.  \n\nEngineering such features is primarily a manual, time-consuming task.  Additionally, each type of model will respond differently to different kinds of engineered features.  This paper reports empirical research to demonstrate what kinds of engineered features are best suited to various machine learning model types.  We provide this recommendation by generating several datasets that we designed to benefit from a particular type of engineered feature.  The experiment demonstrates to what degree the machine learning model can synthesize the needed feature on its own.  If a model can synthesize a planned feature, it is not necessary to provide that feature.  The research demonstrated that the studied models do indeed perform differently with various types of engineered features. \n\nWe generated this dataset for the following paper:\n\nHeaton, J. (2016, April). [An Empirical Analysis of Feature Engineering for Predictive Modeling](https://arxiv.org/abs/1701.07852). In *SoutheastCon 2016* (pp. 1-6). IEEE.\n\n### Included Features\nThe dataset is made up of several files that contain the following features:\n* **BMI** (bmi)\n$$ \\frac{m}{h^2} $$\n* **Counts** (counts)\n$$ [0, 1, 1, 0, 0, 1] = 3 $$\n* **Standard Deviation** (div)\n$$ SD = \\sqrt{\\frac{\\sum{|x-\\hat{x}|^2}}{n}} $$\n* **Difference** (diff)\n$$ a-b $$\n* **Distance** (dist)\n$$ \\sqrt{(a - b)^2 + (c - d)^2} $$\n* **Log** (log)\n$$ \\log{a} $$\n* **Max** (max)\n$$ \\max{(a,b,c,d,...)} $$\n* **Polynomial** (poly)\n$$ 1+5x+8x^2 $$\n* **Powers** (pow)\n$$ x^y $$\n* **Quadratic/Roots** (quad)\n$$ \\left| \\frac{-b+\\sqrt{b^2-4ac}}{2a}- \\frac{-b-\\sqrt{b^2-4ac}}{2a} \\right| $$\n* **Ratio of Differences** (r_diff)\n$$ \\frac{a-b}{c-d} $$\n* **Ratio of Polynomial** (r_poly)\n$$ y=\\frac{1}{5x+8x^2} $$\n* **Ratio** (ratio)\n$$ \\frac{a}{b} $$\n* **Product Power Ratio** (rel)\n$$ \\frac{ab}{c^2} $$\n* **Square Root** (sqrt)\n$$ \\sqrt{a} $$\n* **Sum** (sum)\n$$ a+b $$",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "computer science"
  ],
  "licenses": [
    {
      "nameNullable": "GNU Lesser General Public License 3.0",
      "name": "GNU Lesser General Public License 3.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}