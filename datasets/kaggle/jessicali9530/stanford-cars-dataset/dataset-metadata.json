{
  "id": "jessicali9530/stanford-cars-dataset",
  "id_no": 30084,
  "datasetSlugNullable": "stanford-cars-dataset",
  "ownerUserNullable": "jessicali9530",
  "usabilityRatingNullable": 0.8125,
  "titleNullable": "Stanford Cars Dataset",
  "subtitleNullable": "16,185 images and 196 classes of all the cars you'll ever dream of",
  "descriptionNullable": "### Context\n3D object representations are valuable resources for multi-view object class detection and scene understanding. Fine-grained recognition is a growing subfield of computer vision that has many real-world applications on distinguishing subtle appearances differences. This cars dataset contains great training and testing sets for forming models that can tell cars from one another. Data originated from Stanford University AI Lab (specific reference below in Acknowledgment section).\n\n### Content\n\nThe Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, ex. 2012 Tesla Model S or 2012 BMW M3 coupe.\n\n\n### Acknowledgements\n\nData source and banner image: http://ai.stanford.edu/~jkrause/cars/car_dataset.html contains all bounding boxes and labels for both training and tests.\n\nIf you use this dataset, please cite the following paper: \n\n**3D Object Representations for Fine-Grained Categorization**\n\nJonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei\n\n*4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.*\n\n### Inspiration\n- Can you form a model that can tell the difference between cars by type or colour?\n- Which cars are manufactured by Tesla vs BMW?",
  "datasetId": 30084,
  "datasetSlug": "stanford-cars-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "jessicali9530",
  "hasOwnerUser": true,
  "usabilityRating": 0.8125,
  "hasUsabilityRating": true,
  "totalViews": 331390,
  "totalVotes": 617,
  "totalDownloads": 41245,
  "title": "Stanford Cars Dataset",
  "hasTitle": true,
  "subtitle": "16,185 images and 196 classes of all the cars you'll ever dream of",
  "hasSubtitle": true,
  "description": "### Context\n3D object representations are valuable resources for multi-view object class detection and scene understanding. Fine-grained recognition is a growing subfield of computer vision that has many real-world applications on distinguishing subtle appearances differences. This cars dataset contains great training and testing sets for forming models that can tell cars from one another. Data originated from Stanford University AI Lab (specific reference below in Acknowledgment section).\n\n### Content\n\nThe Cars dataset contains 16,185 images of 196 classes of cars. The data is split into 8,144 training images and 8,041 testing images, where each class has been split roughly in a 50-50 split. Classes are typically at the level of Make, Model, Year, ex. 2012 Tesla Model S or 2012 BMW M3 coupe.\n\n\n### Acknowledgements\n\nData source and banner image: http://ai.stanford.edu/~jkrause/cars/car_dataset.html contains all bounding boxes and labels for both training and tests.\n\nIf you use this dataset, please cite the following paper: \n\n**3D Object Representations for Fine-Grained Categorization**\n\nJonathan Krause, Michael Stark, Jia Deng, Li Fei-Fei\n\n*4th IEEE Workshop on 3D Representation and Recognition, at ICCV 2013 (3dRR-13). Sydney, Australia. Dec. 8, 2013.*\n\n### Inspiration\n- Can you form a model that can tell the difference between cars by type or colour?\n- Which cars are manufactured by Tesla vs BMW?",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "music",
    "earth and nature",
    "education",
    "computer science",
    "automobiles and vehicles",
    "computer vision",
    "classification",
    "image"
  ],
  "licenses": [
    {
      "nameNullable": "other",
      "name": "other",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}