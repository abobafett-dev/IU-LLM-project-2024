{
  "id": "jonasbecker98/286k-topic-clustered-news-articles",
  "id_no": 1599793,
  "datasetSlugNullable": "286k-topic-clustered-news-articles",
  "ownerUserNullable": "jonasbecker98",
  "usabilityRatingNullable": 0.75,
  "titleNullable": "286k Topic Clustered News Articles",
  "subtitleNullable": "A multi-level clustered dataset from 03/2016-07/2021 with ~268.000 entries",
  "descriptionNullable": "### Context\n\nEvery day thousands of news articles with different political orientations are released.\nThe goal of this project is to create a dataset based on a high amount of news articles, which are clustered by their topics. This will provide useful information about the focus of news media during different timeframes.\nThis project has been a part of the course Key Competencies in Computer Science at the University of Wuppertal to annotate a Crossdocument Coreference Resolution Model and was supervised by Anastasia Zhukova.\n\n\n### Content\n\nThe dataset consists of ~268.000 American news articles from 03/2016 to 07/2021. The websites chosen are based on the POLUSA dataset to ensure a diverse political spectrum. Each entry contains the title, maintext, release date and other parameters. The crawled dataset has been clustered on multiple levels.\n\n**Level 1:** Latent Dritchlet Allocation\n**Level 2:** K-Means\n**Level 3:** Sorted By Release Date\n\nThe final json files are also based on the news-please format while adding some new variables.\n| Variable          | Description                          |\n| ------------------ |--------------------------------------|\n|`LDA_ID`| ID of the articles corresponding to level 1 cluster|\n| `LDA_topic_percentage`| Indicator about how well the article fits into its LDA cluster|\n|`LDA_topic_keywords`| The most dominant keywords within a LDA cluster\n|`kMeans_ID`| ID of the articles corresponding to level 2 cluster|\n|`kMeans_topic_keywords`| The most dominant keywords within a K-Means cluster|\n|`year-month`| Representing the timeframe this article has been released in|\n\n\n### Acknowledgements\n\nThis project has been supervised by Anastasia Zhukova.\nThe website domains chosen are based on the POLUSA dataset:\nLukas Gebhard and Felix Hamborg. 2020. The POLUSA Dataset: 0.9M Political News Articles Balanced by Time and Outlet Popularity. In Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020 (JCDL '20). Association for Computing Machinery, New York, NY, USA, 467\u2013468. DOI:https://doi.org/10.1145/3383583.3398567\nThe json layout follows the news-please format:\nFelix Hamborg. 2020. Newsplease Json Format. https://github.com/fhamborg/news-please/blob/master/newsplease/examples/sample.json\n\n\n### Inspiration\n\nEvery day thousands of news articles with different political orientations are released.\nThis dataset has been clustered on mutiple levels to provide useful information about the focus of news media during different timeframes. This dataset can for example be used to feed other algorithms with topic-clustered data or to train a Cross-Document Coreference Resolution Model.",
  "datasetId": 1599793,
  "datasetSlug": "286k-topic-clustered-news-articles",
  "hasDatasetSlug": true,
  "ownerUser": "jonasbecker98",
  "hasOwnerUser": true,
  "usabilityRating": 0.75,
  "hasUsabilityRating": true,
  "totalViews": 3299,
  "totalVotes": 5,
  "totalDownloads": 81,
  "title": "286k Topic Clustered News Articles",
  "hasTitle": true,
  "subtitle": "A multi-level clustered dataset from 03/2016-07/2021 with ~268.000 entries",
  "hasSubtitle": true,
  "description": "### Context\n\nEvery day thousands of news articles with different political orientations are released.\nThe goal of this project is to create a dataset based on a high amount of news articles, which are clustered by their topics. This will provide useful information about the focus of news media during different timeframes.\nThis project has been a part of the course Key Competencies in Computer Science at the University of Wuppertal to annotate a Crossdocument Coreference Resolution Model and was supervised by Anastasia Zhukova.\n\n\n### Content\n\nThe dataset consists of ~268.000 American news articles from 03/2016 to 07/2021. The websites chosen are based on the POLUSA dataset to ensure a diverse political spectrum. Each entry contains the title, maintext, release date and other parameters. The crawled dataset has been clustered on multiple levels.\n\n**Level 1:** Latent Dritchlet Allocation\n**Level 2:** K-Means\n**Level 3:** Sorted By Release Date\n\nThe final json files are also based on the news-please format while adding some new variables.\n| Variable          | Description                          |\n| ------------------ |--------------------------------------|\n|`LDA_ID`| ID of the articles corresponding to level 1 cluster|\n| `LDA_topic_percentage`| Indicator about how well the article fits into its LDA cluster|\n|`LDA_topic_keywords`| The most dominant keywords within a LDA cluster\n|`kMeans_ID`| ID of the articles corresponding to level 2 cluster|\n|`kMeans_topic_keywords`| The most dominant keywords within a K-Means cluster|\n|`year-month`| Representing the timeframe this article has been released in|\n\n\n### Acknowledgements\n\nThis project has been supervised by Anastasia Zhukova.\nThe website domains chosen are based on the POLUSA dataset:\nLukas Gebhard and Felix Hamborg. 2020. The POLUSA Dataset: 0.9M Political News Articles Balanced by Time and Outlet Popularity. In Proceedings of the ACM/IEEE Joint Conference on Digital Libraries in 2020 (JCDL '20). Association for Computing Machinery, New York, NY, USA, 467\u2013468. DOI:https://doi.org/10.1145/3383583.3398567\nThe json layout follows the news-please format:\nFelix Hamborg. 2020. Newsplease Json Format. https://github.com/fhamborg/news-please/blob/master/newsplease/examples/sample.json\n\n\n### Inspiration\n\nEvery day thousands of news articles with different political orientations are released.\nThis dataset has been clustered on mutiple levels to provide useful information about the focus of news media during different timeframes. This dataset can for example be used to feed other algorithms with topic-clustered data or to train a Cross-Document Coreference Resolution Model.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "united states",
    "nlp",
    "clustering",
    "text",
    "news"
  ],
  "licenses": [
    {
      "nameNullable": "Community Data License Agreement - Permissive - Version 1.0",
      "name": "Community Data License Agreement - Permissive - Version 1.0",
      "hasName": true
    }
  ],
  "collaborators": [
    {
      "username": "nicolaskossmann",
      "role": "writer"
    }
  ],
  "data": []
}