{
  "id": "kartikeybartwal/graphical-violence-and-safe-images-dataset",
  "id_no": 5097309,
  "datasetSlugNullable": "graphical-violence-and-safe-images-dataset",
  "ownerUserNullable": "kartikeybartwal",
  "usabilityRatingNullable": 1.0,
  "titleNullable": "Graphical Violence and Safe Images Dataset",
  "subtitleNullable": "It will help you to build models which will detect any graphically violent image",
  "descriptionNullable": "## Overview\nThis dataset is designed for the development and evaluation of a graphical violence image classifier. The dataset contains a total of 1168 images categorized into two distinct folders based on the nature of their content: graphically violent images and graphically safe images.\n\n## Folders\n\n### Graphically Violent Images\n- **Size:** 12 MB\n- **Number of Images:** 66\n- **Description:** This folder contains images that depict graphic violence. These images are intended for training and testing models to recognize and classify violent content.\n\n### Graphically Safe Images\n- **Size:** 200 MB\n- **Number of Images:** 1102\n- **Description:** This folder contains images that are safe and free from any graphic violence. These images provide a counterbalance to the violent images and are crucial for training the classifier to distinguish between violent and non-violent content.\n\n## Usage\nThe dataset is intended for researchers and developers working on image classification, particularly in the domain of content moderation, safety, and computer vision. It can be used to train models that need to detect and filter out graphically violent content from various platforms.\n\n## File Format\n- **Images:** The images are stored in standard formats (such as JPEG or PNG), compatible with most image processing libraries and machine learning frameworks.\n\n## Example Applications\n- **Content Moderation:** Developing automated systems to filter out violent images from social media, forums, and other online platforms.\n- **Safety Compliance:** Ensuring that platforms comply with regulations regarding the display of violent content.\n- **Academic Research:** Conducting studies on the effectiveness of different machine learning models in classifying violent versus non-violent images.\n",
  "datasetId": 5097309,
  "datasetSlug": "graphical-violence-and-safe-images-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "kartikeybartwal",
  "hasOwnerUser": true,
  "usabilityRating": 1.0,
  "hasUsabilityRating": true,
  "totalViews": 556,
  "totalVotes": 5,
  "totalDownloads": 29,
  "title": "Graphical Violence and Safe Images Dataset",
  "hasTitle": true,
  "subtitle": "It will help you to build models which will detect any graphically violent image",
  "hasSubtitle": true,
  "description": "## Overview\nThis dataset is designed for the development and evaluation of a graphical violence image classifier. The dataset contains a total of 1168 images categorized into two distinct folders based on the nature of their content: graphically violent images and graphically safe images.\n\n## Folders\n\n### Graphically Violent Images\n- **Size:** 12 MB\n- **Number of Images:** 66\n- **Description:** This folder contains images that depict graphic violence. These images are intended for training and testing models to recognize and classify violent content.\n\n### Graphically Safe Images\n- **Size:** 200 MB\n- **Number of Images:** 1102\n- **Description:** This folder contains images that are safe and free from any graphic violence. These images provide a counterbalance to the violent images and are crucial for training the classifier to distinguish between violent and non-violent content.\n\n## Usage\nThe dataset is intended for researchers and developers working on image classification, particularly in the domain of content moderation, safety, and computer vision. It can be used to train models that need to detect and filter out graphically violent content from various platforms.\n\n## File Format\n- **Images:** The images are stored in standard formats (such as JPEG or PNG), compatible with most image processing libraries and machine learning frameworks.\n\n## Example Applications\n- **Content Moderation:** Developing automated systems to filter out violent images from social media, forums, and other online platforms.\n- **Safety Compliance:** Ensuring that platforms comply with regulations regarding the display of violent content.\n- **Academic Research:** Conducting studies on the effectiveness of different machine learning models in classifying violent versus non-violent images.\n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "health",
    "advanced",
    "classification",
    "deep learning",
    "public safety"
  ],
  "licenses": [
    {
      "nameNullable": "Apache 2.0",
      "name": "Apache 2.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}