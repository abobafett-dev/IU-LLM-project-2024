{
  "id": "kpvisionlab/tufts-face-database",
  "id_no": 188437,
  "datasetSlugNullable": "tufts-face-database",
  "ownerUserNullable": "kpvisionlab",
  "usabilityRatingNullable": 0.8125,
  "titleNullable": "Tufts Face Database",
  "subtitleNullable": "Multi-modal face  images (112 participants; Around 100,000 images in total)",
  "descriptionNullable": "# Tufts-Face-Database\n## Multi-modal face  images (112 participants, &gt;100,000 images in total)\n## 7 image modalities: visible, near-infrared, thermal, computerized sketch, video, LYTRO and 3D images\n\n### Context\n\nTufts Face Database is the most comprehensive, large-scale (over 10,000 images, 74 females + 38 males, from more than 15 countries with an age range between 4 to 70 years old) face dataset that contains 7 image modalities: visible, near-infrared, thermal, computerized sketch, LYTRO, recorded video, and 3D images. This webpage/dataset contains the Tufts Face Database three-dimensional (3D) images. The other datasets are made available through separate links by the user.\n\nCross-modality face recognition is an emerging topic due to the wide-spread usage of different sensors in day-to-day life applications. The development of face recognition systems relies greatly on existing databases for evaluation and obtaining training examples for data-hungry machine learning algorithms. However, currently, there is no publicly available face database that includes more than two modalities for the same subject. In this work, we introduce the Tufts Face Database that includes images acquired in various modalities: photograph images, thermal images, near infrared images, a recorded video, a computerized facial sketch, and 3D images of each volunteer\u2019s face. An Institutional Research Board protocol was obtained, and images were collected from students, staff, faculty, and their family members at Tufts University. \n\nThis database will be available to researchers worldwide in order to benchmark facial recognition algorithms for sketch, thermal, NIR, 3D face recognition and heterogamous face recognition.  \n\n### Links to modalities of the Tufts Face Database\n\n1. [Tufts Face Database Computerized Sketches (TD_CS)](http://tdface.ece.tufts.edu/)\n\n2. [Tufts Face Database Thermal (TD_IR) Around+Emotion](http://tdface.ece.tufts.edu/)\n\n3.  [Tufts Face Database Thermal Cropped (TD_IR_Cropped) Emotion only](http://tdface.ece.tufts.edu/)\n\n3. [Tufts Face Database Three Dimensional (3D) (TD_3D)](http://tdface.ece.tufts.edu/)\n\n4. [Tufts Face Database Lytro (TD_LYT) *(Check Note)*](http://tdface.ece.tufts.edu/)\n\n5. [Tufts Face Database 2D RGB Around (TD_RGB_A) *(Check Note)*](http://tdface.ece.tufts.edu/) \n\n6. [Tufts Face Database 2D RGB Emotion (TD_RGB_E) *(Check Note)*](http://tdface.ece.tufts.edu/) \n\n7. [Tufts Face Database Night Vision (NIR) (TD_NIR) *(Check Note)*](http://tdface.ece.tufts.edu/)\n\n8. [Tufts Face Database Video (TD_VIDEO) *(Check Note)*](http://tdface.ece.tufts.edu/)\n\n9. [Tufts Face Thermal2RGB Dataset](http://tdface.ece.tufts.edu/)\n\n*Note: Please use http instead of https. The link appears broken when https is used.*\n\n### Image Acquisition\n\nEach participant was seated in front of a blue background in close proximity to the camera. The cameras were mounted on tripods and the height of each camera was adjusted manually to correspond to the image center. The distance to the participant was strictly controlled during the acquisition process. A constant lighting condition was maintained using diffused lights. \n\nTD_CS: Computerized facial sketches were generated using software FACES 4.0 [1], one of the most widely used software packages by law enforcement agencies, the FBI, and the US Military. The software allows researchers to choose a set of candidate facial components from the database based on their observation or memory. \n\nTD_3D: The images were captured using a quad camera (an array of 4 cameras). Each individual was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the individual. The 3D models were reconstructed using open-source structure-from-motion algorithms.\n\nTD_IR_E(E stands for expression/emotion): The images were captured using a FLIR Vue Pro camera. Each participant was asked to pose with (1) a neutral expression, (2) a smile, (3) eyes closed, (4) exaggerated shocked expression, (5) sunglasses. \n\nTD_IR_A (A stands for around):  The images were captured using a FLIR Vue Pro camera. Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant .\n\nTD_RGB_E: The images were captured using a NIKON D3100 camera. Each participant was asked to pose with (1) a neutral expression, (2) a smile, (3) eyes closed, (4) exaggerated shocked expression, (5) sunglasses. \n\nTD_RGB_A: The images were captured using a quad camera (an array of 4 visible field cameras). Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant.\n\nTD_NIR_A: The images were captured using a quad camera (an array of 4 night vision cameras). The lighting condition for NIR imaging was maintained by using an 850nm Infrared 96 LED light system. Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant.\n\nTD_LYT_A: The images were captured using a LYTRO ILLUM 40 Megaray Light Field camera. Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant.\n\nTD_VIDEO:  The images were captured using one of the visible field quad cameras. Each participant was asked to look at a fixed view-point while the camera was moved around the participant forming an approximate semi-circle.\n\n[1] H. K. Galoogahi and T. Sim, \"Face sketch recognition by local radon binary pattern: Lrbp,\" in Image Processing (ICIP), 2012 19th IEEE International Conference on, 2012, pp. 1837-1840.\n\n### Terms and Conditions\n\nThe researcher shall use the Database only for non-commercial research and educational purposes. Any commercial distribution or act related to the commercial usage of this database is strictly prohibited. Tufts University nor Panetta\u2019s Vision and Sensing System Lab makes no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose. The Researcher may not provide research associates and colleagues with access to the Database. The distribution of this database to any parties that have not read and agreed to the terms and conditions of usage is strictly prohibited. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify the Tufts University or the Panetta\u2019s Vision and Sensing System Lab, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted images that he or she may create from the Database. Neither Panetta\u2019s vision and sensing systems lab nor any third parties who may provide information to us for the dissemination purpose shall have any responsibility for or be liable in respect of the content or the accuracy of the provided information, or for any errors or omissions therein. The Panetta\u2019s vision and sensing systems lab reserves the right to revise, amend, alter or delete the information provided herein at any time, but shall not be responsible for or liable in respect of any such revisions, amendments, alterations or deletions.  The images available in this database can only be published or presented in research papers or at research conferences and cannot be used for any commercial purpose. No permission is granted to reproduce the database or post into any webpage or any other storage means. This database contains human subjects who agreed to participate in the acquisition of this database for the research purposes. To guarantee the proper use of this database, the above steps are requested and must be followed by every user. No country or institution is excluded of any of the above steps. Failure to follow the above steps will invite legal prosecution.\n\n**Any publication using this database must reference to this**\n\n\n-**Website**: http://tdface.ece.tufts.edu/, (Check note)\n\n\n-**Paper**: Panetta, Karen, Qianwen Wan, Sos Agaian, Srijith Rajeev, Shreyas Kamath, Rahul Rajendran, Shishir Rao et al. \"A comprehensive database for benchmarking imaging systems.\" IEEE Transactions on Pattern Analysis and Machine Intelligence (2018). \n\n-**Important note**: Usage of some sub-directories may require you to cite more papers related to the development of that sub-directory. Please read the readme files to get more information.\n\n*Note: if the link is broken, please use http instead of https.*\n\nIn Google chrome, use the steps recommended in the following website to view the webpage if it appears to be broken https://www.technipages.com/chrome-enabledisable-not-secure-warning\n\nFor any enquires regarding the Tufts Face Database, contact: panettavisonsensinglab@gmail.com",
  "datasetId": 188437,
  "datasetSlug": "tufts-face-database",
  "hasDatasetSlug": true,
  "ownerUser": "kpvisionlab",
  "hasOwnerUser": true,
  "usabilityRating": 0.8125,
  "hasUsabilityRating": true,
  "totalViews": 70966,
  "totalVotes": 145,
  "totalDownloads": 4773,
  "title": "Tufts Face Database",
  "hasTitle": true,
  "subtitle": "Multi-modal face  images (112 participants; Around 100,000 images in total)",
  "hasSubtitle": true,
  "description": "# Tufts-Face-Database\n## Multi-modal face  images (112 participants, &gt;100,000 images in total)\n## 7 image modalities: visible, near-infrared, thermal, computerized sketch, video, LYTRO and 3D images\n\n### Context\n\nTufts Face Database is the most comprehensive, large-scale (over 10,000 images, 74 females + 38 males, from more than 15 countries with an age range between 4 to 70 years old) face dataset that contains 7 image modalities: visible, near-infrared, thermal, computerized sketch, LYTRO, recorded video, and 3D images. This webpage/dataset contains the Tufts Face Database three-dimensional (3D) images. The other datasets are made available through separate links by the user.\n\nCross-modality face recognition is an emerging topic due to the wide-spread usage of different sensors in day-to-day life applications. The development of face recognition systems relies greatly on existing databases for evaluation and obtaining training examples for data-hungry machine learning algorithms. However, currently, there is no publicly available face database that includes more than two modalities for the same subject. In this work, we introduce the Tufts Face Database that includes images acquired in various modalities: photograph images, thermal images, near infrared images, a recorded video, a computerized facial sketch, and 3D images of each volunteer\u2019s face. An Institutional Research Board protocol was obtained, and images were collected from students, staff, faculty, and their family members at Tufts University. \n\nThis database will be available to researchers worldwide in order to benchmark facial recognition algorithms for sketch, thermal, NIR, 3D face recognition and heterogamous face recognition.  \n\n### Links to modalities of the Tufts Face Database\n\n1. [Tufts Face Database Computerized Sketches (TD_CS)](http://tdface.ece.tufts.edu/)\n\n2. [Tufts Face Database Thermal (TD_IR) Around+Emotion](http://tdface.ece.tufts.edu/)\n\n3.  [Tufts Face Database Thermal Cropped (TD_IR_Cropped) Emotion only](http://tdface.ece.tufts.edu/)\n\n3. [Tufts Face Database Three Dimensional (3D) (TD_3D)](http://tdface.ece.tufts.edu/)\n\n4. [Tufts Face Database Lytro (TD_LYT) *(Check Note)*](http://tdface.ece.tufts.edu/)\n\n5. [Tufts Face Database 2D RGB Around (TD_RGB_A) *(Check Note)*](http://tdface.ece.tufts.edu/) \n\n6. [Tufts Face Database 2D RGB Emotion (TD_RGB_E) *(Check Note)*](http://tdface.ece.tufts.edu/) \n\n7. [Tufts Face Database Night Vision (NIR) (TD_NIR) *(Check Note)*](http://tdface.ece.tufts.edu/)\n\n8. [Tufts Face Database Video (TD_VIDEO) *(Check Note)*](http://tdface.ece.tufts.edu/)\n\n9. [Tufts Face Thermal2RGB Dataset](http://tdface.ece.tufts.edu/)\n\n*Note: Please use http instead of https. The link appears broken when https is used.*\n\n### Image Acquisition\n\nEach participant was seated in front of a blue background in close proximity to the camera. The cameras were mounted on tripods and the height of each camera was adjusted manually to correspond to the image center. The distance to the participant was strictly controlled during the acquisition process. A constant lighting condition was maintained using diffused lights. \n\nTD_CS: Computerized facial sketches were generated using software FACES 4.0 [1], one of the most widely used software packages by law enforcement agencies, the FBI, and the US Military. The software allows researchers to choose a set of candidate facial components from the database based on their observation or memory. \n\nTD_3D: The images were captured using a quad camera (an array of 4 cameras). Each individual was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the individual. The 3D models were reconstructed using open-source structure-from-motion algorithms.\n\nTD_IR_E(E stands for expression/emotion): The images were captured using a FLIR Vue Pro camera. Each participant was asked to pose with (1) a neutral expression, (2) a smile, (3) eyes closed, (4) exaggerated shocked expression, (5) sunglasses. \n\nTD_IR_A (A stands for around):  The images were captured using a FLIR Vue Pro camera. Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant .\n\nTD_RGB_E: The images were captured using a NIKON D3100 camera. Each participant was asked to pose with (1) a neutral expression, (2) a smile, (3) eyes closed, (4) exaggerated shocked expression, (5) sunglasses. \n\nTD_RGB_A: The images were captured using a quad camera (an array of 4 visible field cameras). Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant.\n\nTD_NIR_A: The images were captured using a quad camera (an array of 4 night vision cameras). The lighting condition for NIR imaging was maintained by using an 850nm Infrared 96 LED light system. Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant.\n\nTD_LYT_A: The images were captured using a LYTRO ILLUM 40 Megaray Light Field camera. Each participant was asked to look at a fixed view-point while the cameras were moved to 9 equidistant positions forming an approximate semi-circle around the participant.\n\nTD_VIDEO:  The images were captured using one of the visible field quad cameras. Each participant was asked to look at a fixed view-point while the camera was moved around the participant forming an approximate semi-circle.\n\n[1] H. K. Galoogahi and T. Sim, \"Face sketch recognition by local radon binary pattern: Lrbp,\" in Image Processing (ICIP), 2012 19th IEEE International Conference on, 2012, pp. 1837-1840.\n\n### Terms and Conditions\n\nThe researcher shall use the Database only for non-commercial research and educational purposes. Any commercial distribution or act related to the commercial usage of this database is strictly prohibited. Tufts University nor Panetta\u2019s Vision and Sensing System Lab makes no representations or warranties regarding the Database, including but not limited to warranties of non-infringement or fitness for a particular purpose. The Researcher may not provide research associates and colleagues with access to the Database. The distribution of this database to any parties that have not read and agreed to the terms and conditions of usage is strictly prohibited. Researcher accepts full responsibility for his or her use of the Database and shall defend and indemnify the Tufts University or the Panetta\u2019s Vision and Sensing System Lab, including their employees, Trustees, officers and agents, against any and all claims arising from Researcher's use of the Database, including but not limited to Researcher's use of any copies of copyrighted images that he or she may create from the Database. Neither Panetta\u2019s vision and sensing systems lab nor any third parties who may provide information to us for the dissemination purpose shall have any responsibility for or be liable in respect of the content or the accuracy of the provided information, or for any errors or omissions therein. The Panetta\u2019s vision and sensing systems lab reserves the right to revise, amend, alter or delete the information provided herein at any time, but shall not be responsible for or liable in respect of any such revisions, amendments, alterations or deletions.  The images available in this database can only be published or presented in research papers or at research conferences and cannot be used for any commercial purpose. No permission is granted to reproduce the database or post into any webpage or any other storage means. This database contains human subjects who agreed to participate in the acquisition of this database for the research purposes. To guarantee the proper use of this database, the above steps are requested and must be followed by every user. No country or institution is excluded of any of the above steps. Failure to follow the above steps will invite legal prosecution.\n\n**Any publication using this database must reference to this**\n\n\n-**Website**: http://tdface.ece.tufts.edu/, (Check note)\n\n\n-**Paper**: Panetta, Karen, Qianwen Wan, Sos Agaian, Srijith Rajeev, Shreyas Kamath, Rahul Rajendran, Shishir Rao et al. \"A comprehensive database for benchmarking imaging systems.\" IEEE Transactions on Pattern Analysis and Machine Intelligence (2018). \n\n-**Important note**: Usage of some sub-directories may require you to cite more papers related to the development of that sub-directory. Please read the readme files to get more information.\n\n*Note: if the link is broken, please use http instead of https.*\n\nIn Google chrome, use the steps recommended in the following website to view the webpage if it appears to be broken https://www.technipages.com/chrome-enabledisable-not-secure-warning\n\nFor any enquires regarding the Tufts Face Database, contact: panettavisonsensinglab@gmail.com",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "computer vision",
    "image"
  ],
  "licenses": [
    {
      "nameNullable": "other",
      "name": "other",
      "hasName": true
    }
  ],
  "collaborators": [
    {
      "username": "shishirprao",
      "role": "writer"
    },
    {
      "username": "srijith2311",
      "role": "writer"
    },
    {
      "username": "shreyaskamathkm",
      "role": "writer"
    }
  ],
  "data": []
}