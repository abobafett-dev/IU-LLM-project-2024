{
  "id": "kuchhbhi/stylish-product-image-dataset",
  "id_no": 2194221,
  "datasetSlugNullable": "stylish-product-image-dataset",
  "ownerUserNullable": "kuchhbhi",
  "usabilityRatingNullable": 0.9411764705882353,
  "titleNullable": "Stylish Product Image Dataset",
  "subtitleNullable": "65K Records of Fashion Product Image",
  "descriptionNullable": "# Context:\nThe idea came to my mind to scrap this data. I was working on an e-commerce project **[Fashion Product Recommendation](https://fashnkart.herokuapp.com/)** (an end-to-end project). In this project, upload any fashion image and it will show the 10 closest recommendations. \n\n![](https://user-images.githubusercontent.com/40932902/169657090-20d3342d-d472-48e3-bc34-8a9686b09961.png)\n\n![](https://user-images.githubusercontent.com/40932902/169657035-870bb803-f985-482a-ac16-789d0fcf2a2b.png)\n\n![](https://user-images.githubusercontent.com/40932902/169013855-099838d6-8612-45ce-8961-28ccf44f81f7.png)\n\nI completed my project on this  [image dataset ](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset).\nThe problem I faced while deploying on the Heroku server. Due to the large project file size,  I was unable to deploy as **Heroku** offers limited memory space for a free account.\n\nAs currently, I am only familiar with Heroku. Learning AWS for big projects.\nSo, I decided to scrap my own image dataset with much more information that can help me to transform this project to the next level.\nScraped this data from **flipkart.com**(e-commerce website) in two formats Image and textual data in tabular format.\n\n# About this Dataset:\nThis dataset contains **65k images (400x450 pixel)**) of fashion/style products and accessories like clothing, footwear, accessories, and many more.\nThere is a **CSV** file also mapped with the image name and the id column in tabular data.\nThe name of the image is in a unique numerical format like 1.png, 62299.png\nImage name and Id columns are the same. So, suppose you want to find the details of any image then you can find them using the image name id, go to the Id column in the csv file and that id rows will be the details of the image.\nYou can find the notebook in the code section which I used to scrap this data.\n\nColumns of CSV Dataset:\n1. **id** : Unique id same as the image name\n2. **brand**: Brand name of the product\n3. **title**: Title of the product\n4. **sold_price**: selling price of the product\n5. **actual_price**: Actual price of the product \n6. **url** : unique URL of every product\n7. **img**: Image URL \n\nHow did helped me this dataset:\n1. I trained my CNN model using the image data, that's the only use of the image dataset. \n2. In my front-end page of the project to display results, I used Image URL and displayed after extracting from the web. This helped me to not upload the image dataset with the project on the server and this saved huge memory space.\n3.  Using the **url** displaying live **price** and** ratings** from the Flipkart website.\n4. And there is a Buy button mapped with the **url**  you will be redirected to the original product page and buy it from there.\nafter using this dataset I changed my project name from **Fashion Product Recommender** to **Flipkart Fashion Product Recommender**.  \ud83d\ude04\ud83d\ude04\ud83d\ude04 \n\nStill, the memory problem was not resolved as the model trained file was above 500MB on the complete dataset. So I tried on multiple sets and finally, I deployed after training on 1000 images only. In the future, I will try on another platform to deploy the complete project.\n I learned many new things while working on this dataset.\n\n## Your Job:\n1. You can use this dataset in your deep learning projects, go and try to create interesting projects.\n2.  You can use CSV data in your Machine Learning projects, first you need to do feature construction from the title columns as there is much information hidden and some data cleaning required.\n3. There is two complete records missing in csv data, your job is to find the missing data with the help of image dataset and fill as per your knowledge.\n\n### This is a huge dataset in terms of records as well as memory size. To download this dataset you need high internet speed.\nTo download the same dataset in **[small size less than 500mb](https://www.kaggle.com/datasets/kuchhbhi/flipkart-fashion-products-65k-dataset)** you can find it here,\neverything is the same as this dataset only I reduced the pixel of the image from 400x450px to ** 65x80pixels**.\n\n### Pls, Rate this work\n## Support with Upvote... that encourages me to research more.\n## Share your feedback, reviews, and suggestions if any.\n#Thanks!!",
  "datasetId": 2194221,
  "datasetSlug": "stylish-product-image-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "kuchhbhi",
  "hasOwnerUser": true,
  "usabilityRating": 0.9411764705882353,
  "hasUsabilityRating": true,
  "totalViews": 8419,
  "totalVotes": 44,
  "totalDownloads": 754,
  "title": "Stylish Product Image Dataset",
  "hasTitle": true,
  "subtitle": "65K Records of Fashion Product Image",
  "hasSubtitle": true,
  "description": "# Context:\nThe idea came to my mind to scrap this data. I was working on an e-commerce project **[Fashion Product Recommendation](https://fashnkart.herokuapp.com/)** (an end-to-end project). In this project, upload any fashion image and it will show the 10 closest recommendations. \n\n![](https://user-images.githubusercontent.com/40932902/169657090-20d3342d-d472-48e3-bc34-8a9686b09961.png)\n\n![](https://user-images.githubusercontent.com/40932902/169657035-870bb803-f985-482a-ac16-789d0fcf2a2b.png)\n\n![](https://user-images.githubusercontent.com/40932902/169013855-099838d6-8612-45ce-8961-28ccf44f81f7.png)\n\nI completed my project on this  [image dataset ](https://www.kaggle.com/datasets/paramaggarwal/fashion-product-images-dataset).\nThe problem I faced while deploying on the Heroku server. Due to the large project file size,  I was unable to deploy as **Heroku** offers limited memory space for a free account.\n\nAs currently, I am only familiar with Heroku. Learning AWS for big projects.\nSo, I decided to scrap my own image dataset with much more information that can help me to transform this project to the next level.\nScraped this data from **flipkart.com**(e-commerce website) in two formats Image and textual data in tabular format.\n\n# About this Dataset:\nThis dataset contains **65k images (400x450 pixel)**) of fashion/style products and accessories like clothing, footwear, accessories, and many more.\nThere is a **CSV** file also mapped with the image name and the id column in tabular data.\nThe name of the image is in a unique numerical format like 1.png, 62299.png\nImage name and Id columns are the same. So, suppose you want to find the details of any image then you can find them using the image name id, go to the Id column in the csv file and that id rows will be the details of the image.\nYou can find the notebook in the code section which I used to scrap this data.\n\nColumns of CSV Dataset:\n1. **id** : Unique id same as the image name\n2. **brand**: Brand name of the product\n3. **title**: Title of the product\n4. **sold_price**: selling price of the product\n5. **actual_price**: Actual price of the product \n6. **url** : unique URL of every product\n7. **img**: Image URL \n\nHow did helped me this dataset:\n1. I trained my CNN model using the image data, that's the only use of the image dataset. \n2. In my front-end page of the project to display results, I used Image URL and displayed after extracting from the web. This helped me to not upload the image dataset with the project on the server and this saved huge memory space.\n3.  Using the **url** displaying live **price** and** ratings** from the Flipkart website.\n4. And there is a Buy button mapped with the **url**  you will be redirected to the original product page and buy it from there.\nafter using this dataset I changed my project name from **Fashion Product Recommender** to **Flipkart Fashion Product Recommender**.  \ud83d\ude04\ud83d\ude04\ud83d\ude04 \n\nStill, the memory problem was not resolved as the model trained file was above 500MB on the complete dataset. So I tried on multiple sets and finally, I deployed after training on 1000 images only. In the future, I will try on another platform to deploy the complete project.\n I learned many new things while working on this dataset.\n\n## Your Job:\n1. You can use this dataset in your deep learning projects, go and try to create interesting projects.\n2.  You can use CSV data in your Machine Learning projects, first you need to do feature construction from the title columns as there is much information hidden and some data cleaning required.\n3. There is two complete records missing in csv data, your job is to find the missing data with the help of image dataset and fill as per your knowledge.\n\n### This is a huge dataset in terms of records as well as memory size. To download this dataset you need high internet speed.\nTo download the same dataset in **[small size less than 500mb](https://www.kaggle.com/datasets/kuchhbhi/flipkart-fashion-products-65k-dataset)** you can find it here,\neverything is the same as this dataset only I reduced the pixel of the image from 400x450px to ** 65x80pixels**.\n\n### Pls, Rate this work\n## Support with Upvote... that encourages me to research more.\n## Share your feedback, reviews, and suggestions if any.\n#Thanks!!",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "clothing and accessories",
    "business",
    "recommender systems",
    "tabular",
    "image"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}