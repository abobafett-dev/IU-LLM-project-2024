{
  "id": "kurianbenoy/fast-text-embeddings-without-subwords",
  "id_no": 919585,
  "datasetSlugNullable": "fast-text-embeddings-without-subwords",
  "ownerUserNullable": "kurianbenoy",
  "usabilityRatingNullable": 0.875,
  "titleNullable": "Fast Text embeddings without subwords",
  "subtitleNullable": "fast text embedding for Kagglers.",
  "descriptionNullable": "# FastText\nhttps://fasttext.cc/docs/en/english-vectors.html\n\n2 million word vectors trained on Common Crawl (600B tokens), 300-dimensional pretrained FastText English word vectors released by Facebook.\n\nFastText is an open-source, free, lightweight library that allows users to learn text representations and text classifiers. It works on standard, generic hardware. Models can later be reduced in size to even fit on mobile devices.\n\nThis text contains two embedding files without sub-words that is:\n\n- wiki-news-300d-1M.vec.zip: 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\n- crawl-300d-2M.vec.zip: 2 million word vectors trained on Common Crawl (600B tokens).\n\n\n### Acknowledgements\n\nThis  embeddings were created with the paper:\nT. Mikolov, E. Grave, P. Bojanowski, C. Puhrsch, A. Joulin. Advances in Pre-Training Distributed Word Representations\n\n```\n@inproceedings{mikolov2018advances,\n  title={Advances in Pre-Training Distributed Word Representations},\n  author={Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},\n  booktitle={Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)},\n  year={2018}\n}\n```\n\nThanks to [fastext team](https://fasttext.cc/docs/en/english-vectors.html)\n",
  "datasetId": 919585,
  "datasetSlug": "fast-text-embeddings-without-subwords",
  "hasDatasetSlug": true,
  "ownerUser": "kurianbenoy",
  "hasOwnerUser": true,
  "usabilityRating": 0.875,
  "hasUsabilityRating": true,
  "totalViews": 2251,
  "totalVotes": 5,
  "totalDownloads": 62,
  "title": "Fast Text embeddings without subwords",
  "hasTitle": true,
  "subtitle": "fast text embedding for Kagglers.",
  "hasSubtitle": true,
  "description": "# FastText\nhttps://fasttext.cc/docs/en/english-vectors.html\n\n2 million word vectors trained on Common Crawl (600B tokens), 300-dimensional pretrained FastText English word vectors released by Facebook.\n\nFastText is an open-source, free, lightweight library that allows users to learn text representations and text classifiers. It works on standard, generic hardware. Models can later be reduced in size to even fit on mobile devices.\n\nThis text contains two embedding files without sub-words that is:\n\n- wiki-news-300d-1M.vec.zip: 1 million word vectors trained on Wikipedia 2017, UMBC webbase corpus and statmt.org news dataset (16B tokens).\n- crawl-300d-2M.vec.zip: 2 million word vectors trained on Common Crawl (600B tokens).\n\n\n### Acknowledgements\n\nThis  embeddings were created with the paper:\nT. Mikolov, E. Grave, P. Bojanowski, C. Puhrsch, A. Joulin. Advances in Pre-Training Distributed Word Representations\n\n```\n@inproceedings{mikolov2018advances,\n  title={Advances in Pre-Training Distributed Word Representations},\n  author={Mikolov, Tomas and Grave, Edouard and Bojanowski, Piotr and Puhrsch, Christian and Joulin, Armand},\n  booktitle={Proceedings of the International Conference on Language Resources and Evaluation (LREC 2018)},\n  year={2018}\n}\n```\n\nThanks to [fastext team](https://fasttext.cc/docs/en/english-vectors.html)\n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "education",
    "computer science",
    "software",
    "nlp"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-SA-3.0",
      "name": "CC-BY-SA-3.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}