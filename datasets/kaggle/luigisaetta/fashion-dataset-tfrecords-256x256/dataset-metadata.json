{
  "id": "luigisaetta/fashion-dataset-tfrecords-256x256",
  "id_no": 788872,
  "datasetSlugNullable": "fashion-dataset-tfrecords-256x256",
  "ownerUserNullable": "luigisaetta",
  "usabilityRatingNullable": 0.6875,
  "titleNullable": "Fashion Dataset, TFRecords, 256x256",
  "subtitleNullable": "Fashion Classifier with TFRecords",
  "descriptionNullable": "### Context\n\nThis dataset has been created to support a set of experiments about using TFRecord for full GPU usage. I have taken the Fashion Classification Dataset and then I have reduced the size of images (now 256x256) and stored in a set of TFRecords files that can be easily used in TF2 code, for fast processing with GPU and TPU.\n\n\n### Content\n\nIt is a set of files in TFRecords format. Each record contains an image of a clothes or boot or something similar, together with a set of metadata. This is the format\n\n\n\nLABELED_TFREC_FORMAT = { \n       \n         \"image\": tf.io.FixedLenFeature([], tf.string), \n         \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"base_colour\" : tf.io.FixedLenFeature([], tf.int64),\n        \"target\" : tf.io.FixedLenFeature([], tf.int64)\n    }\n\nbase_colour and target have been codified:\n\nThis is the list of Master Categories (target):\n* Accessories\n* Apparel \n* Footwear \n* Free Items \n* Home \n* Personal Care \n* Sporting Goods \n\ncodified with [0, .. 6]\n\n### Acknowledgements\n\nOriginal images taken from Param Aggarwal dataset: https://www.kaggle.com/paramaggarwal/fashion-product-images-dataset\n\n### Inspiration\n\nI created this dataset to support a set of experiments around TFRecords. With it, you can easily create a Fashion Classifier that can be quickly trained. Using a two-GPU machine (p100) it takes 120 sec. per epoch and with around 20 epochs you can easily reach 0.994 accuracy on the test set.",
  "datasetId": 788872,
  "datasetSlug": "fashion-dataset-tfrecords-256x256",
  "hasDatasetSlug": true,
  "ownerUser": "luigisaetta",
  "hasOwnerUser": true,
  "usabilityRating": 0.6875,
  "hasUsabilityRating": true,
  "totalViews": 3106,
  "totalVotes": 4,
  "totalDownloads": 80,
  "title": "Fashion Dataset, TFRecords, 256x256",
  "hasTitle": true,
  "subtitle": "Fashion Classifier with TFRecords",
  "hasSubtitle": true,
  "description": "### Context\n\nThis dataset has been created to support a set of experiments about using TFRecord for full GPU usage. I have taken the Fashion Classification Dataset and then I have reduced the size of images (now 256x256) and stored in a set of TFRecords files that can be easily used in TF2 code, for fast processing with GPU and TPU.\n\n\n### Content\n\nIt is a set of files in TFRecords format. Each record contains an image of a clothes or boot or something similar, together with a set of metadata. This is the format\n\n\n\nLABELED_TFREC_FORMAT = { \n       \n         \"image\": tf.io.FixedLenFeature([], tf.string), \n         \"image_name\": tf.io.FixedLenFeature([], tf.string),\n        \"base_colour\" : tf.io.FixedLenFeature([], tf.int64),\n        \"target\" : tf.io.FixedLenFeature([], tf.int64)\n    }\n\nbase_colour and target have been codified:\n\nThis is the list of Master Categories (target):\n* Accessories\n* Apparel \n* Footwear \n* Free Items \n* Home \n* Personal Care \n* Sporting Goods \n\ncodified with [0, .. 6]\n\n### Acknowledgements\n\nOriginal images taken from Param Aggarwal dataset: https://www.kaggle.com/paramaggarwal/fashion-product-images-dataset\n\n### Inspiration\n\nI created this dataset to support a set of experiments around TFRecords. With it, you can easily create a Fashion Classifier that can be quickly trained. Using a two-GPU machine (p100) it takes 120 sec. per epoch and with around 20 epochs you can easily reach 0.994 accuracy on the test set.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "earth and nature",
    "multiclass classification"
  ],
  "licenses": [
    {
      "nameNullable": "unknown",
      "name": "unknown",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}