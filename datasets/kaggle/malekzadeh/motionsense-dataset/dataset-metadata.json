{
  "id": "malekzadeh/motionsense-dataset",
  "id_no": 16752,
  "datasetSlugNullable": "motionsense-dataset",
  "ownerUserNullable": "malekzadeh",
  "usabilityRatingNullable": 0.7647058823529411,
  "titleNullable": "MotionSense Dataset : Smartphone Sensor Data - HAR",
  "subtitleNullable": "Human Activity and Attribute Recognition:  Phone Accelerometer and Gyroscope",
  "descriptionNullable": "## MotionSense Dataset: Sensor Based Human Activity and Attribute Recognition\n# Context\nThis dataset includes time-series data generated by accelerometer and gyroscope sensors (attitude, gravity, userAcceleration, and rotationRate). It is collected with an iPhone 6s kept in the participant's front pocket using [SensingKit](https://www.sensingkit.org/) which collects information from [Core Motion](https://developer.apple.com/documentation/coremotion/cmdevicemotion) framework on iOS devices. A total of 24 participants in a range of gender, age, weight, and height performed 6 activities in 15 trials in the same environment and conditions: downstairs, upstairs, walking, jogging, sitting, and standing. With this dataset, we aim to look for  *personal attributes fingerprints* in time-series of sensor data, i.e. attribute-specific patterns that can be used to infer gender or personality of the data subjects in addition to their activities. \n\n[A simple code for importing dataset and to get your hands in][1]\n\n# Content\n\nFor each participant, the study had been commenced by collecting their demographic (age and gender) and physically-related (height and weight) information. Then, we provided them with a dedicated smartphone (iPhone 6) and asked them to store it in their trousers' front pocket during the experiment. All the participant were asked to wear flat shoes. We then asked them to perform 6 different activities (walk downstairs, walk upstairs, sit, stand and jogging) around the Queen Mary University of London's Mile End campus. For each trial, the researcher set up the phone and gave it to the current participants, then the researcher stood in a corner. Then, the participant pressed the start button of [Crowdsense app](https://itunes.apple.com/us/app/crowdsense/id930853606?mt=8) and put it in their trousers' front pocket and performed the specified activity. We asked them to do it as natural as possible, like their everyday life. At the end of each trial, they took the phone out of their pocket and pressed the stop button. The exact places and routes for running all the activities are shown in the illustrative map in the following Figure.  \n\nAs we can see, there are 15 trials:\n\n1. Long trials: those with number 1 to 9 with around 2 to 3 minutes duration.\n2. Short trials: those with number 11 to 16 that are around 30 seconds to 1 minutes duration.\n\nThere are 24 data subjects. The `A_DeviceMotion_data` folder contains time-series collected by both Accelerometer and Gyroscope for all 15 trials. For every trial we have a multivariate time-series. Thus, we have time-series with 12 features: attitude.roll, attitude.pitch, attitude.yaw, gravity.x, gravity.y, gravity.z, rotationRate.x, rotationRate.y, rotationRate.z, userAcceleration.x, userAcceleration.y, userAcceleration.z.\n\nThe accelerometer measures the sum of two acceleration vectors: gravity and user acceleration. User acceleration is the acceleration that the user imparts to the device. Because Core Motion is able to track a device\u2019s attitude using both the gyroscope and the accelerometer, it can differentiate between gravity and user acceleration. A CMDeviceMotion object provides both measurements in the gravity and userAcceleration properties. ([More info][3])\n\nThere are 6 different labels: \n\n1. **dws**: downstairs\n\n2. **ups**: upstairs\n\n3. **sit**: sitting\n\n4. **std**: standing\n\n5. **wlk**: walking\n\n6. **jog**: jogging\n\n\n## Acknowledgements\nIf you use this dataset, please cite the following paper:\n\n&gt; @inproceedings{Malekzadeh:2019:MSD:3302505.3310068,\n\n&gt;  author = {Malekzadeh, Mohammad and Clegg, Richard G. and Cavallaro, Andrea and Haddadi, Hamed},\n\n&gt;  title = {Mobile Sensor Data Anonymization},\n\n&gt;  booktitle = {Proceedings of the International Conference on Internet of Things Design and Implementation},\n\n&gt;  series = {IoTDI '19},\n\n&gt;  year = {2019},\n\n&gt;  isbn = {978-1-4503-6283-2},\n\n&gt;  location = {Montreal, Quebec, Canada},\n  pages = {49--58},\n\n&gt;  numpages = {10},\n\n&gt;  url = {http://doi.acm.org/10.1145/3302505.3310068},\n\n&gt;  doi = {10.1145/3302505.3310068},\n\n&gt;  acmid = {3310068},\n\n&gt;  publisher = {ACM},\n\n&gt;  address = {New York, NY, USA},\n\n&gt;  keywords = {adversarial training, deep learning, edge computing, sensor data privacy, time series analysis},\n\n&gt;  } \n\nOr\n\n&gt; @inproceedings{Malekzadeh:2018:PSD:3195258.3195260,\n\n&gt; author = {Malekzadeh, Mohammad and Clegg, Richard G. and Cavallaro, Andrea and Haddadi, Hamed},\n\n&gt; title = {Protecting Sensory Data Against Sensitive Inferences},\n\n&gt; booktitle = {Proceedings of the 1st Workshop on Privacy by Design in Distributed Systems},\n\n&gt; series = {W-P2DS'18},\n\n&gt; year = {2018},\n\n&gt; isbn = {978-1-4503-5654-1},\n\n&gt; location = {Porto, Portugal},\n\n&gt; pages = {2:1--2:6},\n\n&gt; articleno = {2},\n\n&gt; numpages = {6},\n\n&gt; url = {http://doi.acm.org/10.1145/3195258.3195260},\n\n&gt; doi = {10.1145/3195258.3195260},\n\n&gt; acmid = {3195260},\n\n&gt; publisher = {ACM},\n\n&gt; address = {New York, NY, USA},\n\n&gt; keywords = {Activity Recognition, Machine Learning, Privacy, Sensor Data, Time-Series Analysis},\n\n&gt; }\n \n  [1]: https://github.com/mmalekzadeh/motion-sense\n  [3]: https://developer.apple.com/documentation/coremotion/cmdevicemotion",
  "datasetId": 16752,
  "datasetSlug": "motionsense-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "malekzadeh",
  "hasOwnerUser": true,
  "usabilityRating": 0.7647058823529411,
  "hasUsabilityRating": true,
  "totalViews": 126181,
  "totalVotes": 269,
  "totalDownloads": 12365,
  "title": "MotionSense Dataset : Smartphone Sensor Data - HAR",
  "hasTitle": true,
  "subtitle": "Human Activity and Attribute Recognition:  Phone Accelerometer and Gyroscope",
  "hasSubtitle": true,
  "description": "## MotionSense Dataset: Sensor Based Human Activity and Attribute Recognition\n# Context\nThis dataset includes time-series data generated by accelerometer and gyroscope sensors (attitude, gravity, userAcceleration, and rotationRate). It is collected with an iPhone 6s kept in the participant's front pocket using [SensingKit](https://www.sensingkit.org/) which collects information from [Core Motion](https://developer.apple.com/documentation/coremotion/cmdevicemotion) framework on iOS devices. A total of 24 participants in a range of gender, age, weight, and height performed 6 activities in 15 trials in the same environment and conditions: downstairs, upstairs, walking, jogging, sitting, and standing. With this dataset, we aim to look for  *personal attributes fingerprints* in time-series of sensor data, i.e. attribute-specific patterns that can be used to infer gender or personality of the data subjects in addition to their activities. \n\n[A simple code for importing dataset and to get your hands in][1]\n\n# Content\n\nFor each participant, the study had been commenced by collecting their demographic (age and gender) and physically-related (height and weight) information. Then, we provided them with a dedicated smartphone (iPhone 6) and asked them to store it in their trousers' front pocket during the experiment. All the participant were asked to wear flat shoes. We then asked them to perform 6 different activities (walk downstairs, walk upstairs, sit, stand and jogging) around the Queen Mary University of London's Mile End campus. For each trial, the researcher set up the phone and gave it to the current participants, then the researcher stood in a corner. Then, the participant pressed the start button of [Crowdsense app](https://itunes.apple.com/us/app/crowdsense/id930853606?mt=8) and put it in their trousers' front pocket and performed the specified activity. We asked them to do it as natural as possible, like their everyday life. At the end of each trial, they took the phone out of their pocket and pressed the stop button. The exact places and routes for running all the activities are shown in the illustrative map in the following Figure.  \n\nAs we can see, there are 15 trials:\n\n1. Long trials: those with number 1 to 9 with around 2 to 3 minutes duration.\n2. Short trials: those with number 11 to 16 that are around 30 seconds to 1 minutes duration.\n\nThere are 24 data subjects. The `A_DeviceMotion_data` folder contains time-series collected by both Accelerometer and Gyroscope for all 15 trials. For every trial we have a multivariate time-series. Thus, we have time-series with 12 features: attitude.roll, attitude.pitch, attitude.yaw, gravity.x, gravity.y, gravity.z, rotationRate.x, rotationRate.y, rotationRate.z, userAcceleration.x, userAcceleration.y, userAcceleration.z.\n\nThe accelerometer measures the sum of two acceleration vectors: gravity and user acceleration. User acceleration is the acceleration that the user imparts to the device. Because Core Motion is able to track a device\u2019s attitude using both the gyroscope and the accelerometer, it can differentiate between gravity and user acceleration. A CMDeviceMotion object provides both measurements in the gravity and userAcceleration properties. ([More info][3])\n\nThere are 6 different labels: \n\n1. **dws**: downstairs\n\n2. **ups**: upstairs\n\n3. **sit**: sitting\n\n4. **std**: standing\n\n5. **wlk**: walking\n\n6. **jog**: jogging\n\n\n## Acknowledgements\nIf you use this dataset, please cite the following paper:\n\n&gt; @inproceedings{Malekzadeh:2019:MSD:3302505.3310068,\n\n&gt;  author = {Malekzadeh, Mohammad and Clegg, Richard G. and Cavallaro, Andrea and Haddadi, Hamed},\n\n&gt;  title = {Mobile Sensor Data Anonymization},\n\n&gt;  booktitle = {Proceedings of the International Conference on Internet of Things Design and Implementation},\n\n&gt;  series = {IoTDI '19},\n\n&gt;  year = {2019},\n\n&gt;  isbn = {978-1-4503-6283-2},\n\n&gt;  location = {Montreal, Quebec, Canada},\n  pages = {49--58},\n\n&gt;  numpages = {10},\n\n&gt;  url = {http://doi.acm.org/10.1145/3302505.3310068},\n\n&gt;  doi = {10.1145/3302505.3310068},\n\n&gt;  acmid = {3310068},\n\n&gt;  publisher = {ACM},\n\n&gt;  address = {New York, NY, USA},\n\n&gt;  keywords = {adversarial training, deep learning, edge computing, sensor data privacy, time series analysis},\n\n&gt;  } \n\nOr\n\n&gt; @inproceedings{Malekzadeh:2018:PSD:3195258.3195260,\n\n&gt; author = {Malekzadeh, Mohammad and Clegg, Richard G. and Cavallaro, Andrea and Haddadi, Hamed},\n\n&gt; title = {Protecting Sensory Data Against Sensitive Inferences},\n\n&gt; booktitle = {Proceedings of the 1st Workshop on Privacy by Design in Distributed Systems},\n\n&gt; series = {W-P2DS'18},\n\n&gt; year = {2018},\n\n&gt; isbn = {978-1-4503-5654-1},\n\n&gt; location = {Porto, Portugal},\n\n&gt; pages = {2:1--2:6},\n\n&gt; articleno = {2},\n\n&gt; numpages = {6},\n\n&gt; url = {http://doi.acm.org/10.1145/3195258.3195260},\n\n&gt; doi = {10.1145/3195258.3195260},\n\n&gt; acmid = {3195260},\n\n&gt; publisher = {ACM},\n\n&gt; address = {New York, NY, USA},\n\n&gt; keywords = {Activity Recognition, Machine Learning, Privacy, Sensor Data, Time-Series Analysis},\n\n&gt; }\n \n  [1]: https://github.com/mmalekzadeh/motion-sense\n  [3]: https://developer.apple.com/documentation/coremotion/cmdevicemotion",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "computer science",
    "mobile and wireless",
    "software",
    "electronics",
    "time series analysis",
    "classification",
    "regression"
  ],
  "licenses": [
    {
      "nameNullable": "ODbL-1.0",
      "name": "ODbL-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}