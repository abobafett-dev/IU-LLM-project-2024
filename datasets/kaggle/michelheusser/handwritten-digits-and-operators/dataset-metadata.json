{
  "id": "michelheusser/handwritten-digits-and-operators",
  "id_no": 763806,
  "datasetSlugNullable": "handwritten-digits-and-operators",
  "ownerUserNullable": "michelheusser",
  "usabilityRatingNullable": 0.9375,
  "titleNullable": "Dataset: Handwritten Digits and Operators",
  "subtitleNullable": "Includes digits (0-9) and simple mathematical operators (+-*/[]) ",
  "descriptionNullable": "# Context\nI created this dataset as part of a larger, rather educational project, which aims to create a simple web-interface to write simple numerical mathematical operations on a drawing grid (either on a PC, tablet, or smartphone), which is then recognized and evaluated. It also aims, however, to contribute and help other projects that may involve or require large datasets of handwritten digits.\n\n### Dataset Characteristics\nWhat makes this dataset different from existing ones, is that it lays emphasis on the actual strokes of handwritten signs, instead of just being a compilation of scanned images of existing records (the way, for example, the MNIST dataset was created). Each pixel is strictly full black, or full white (no greytones), and the strokes are rather thin. It is meant to have the information of the stroke itself, and not just a scanned image.\n\n### **In the Context of Neural Networks and Deep Learning**\nThe dataset is meant to stretch and challenge the understanding of a neural network about what makes a specific symbol mean what it does. For this, I initially created a starting dataset of the different ways people write symbols, playing with their internal proportions and adding \"ill\"-written signs that are still barely recognizable from the rest. After that, I artificially augmented the dataset by performing stretches and small rotations on all images, making sure that a human being would still recognize them. A neural network would be then forced to understand better what gives a symbol its characteristics. I made sure not to delete many, rather ambiguous, cases (e.g. a clockwise-rotated '1' and '/') for the neural network to have to deal and understand nuances during training and classification.\n\nUsing 60% of the dataset (randomly selected) to train a neural network with two inner layers, and 20% to validate it, I achieved a **+96%** validation accuracy using my own implementation of the stochastic gradient descent and backpropagation algorithm.\n\n### **Data Augmentation**\nThe resizing, rotating, and scaling algorithms I wrote do not work with images by modifying each pixel, but rather the stroke. This means, that each line of one pixel width is scaled/resized/rotated to a line (longer or shorter) of the same pixel width. This is advantageous for the following reasons:\n- When I created the dataset, the original images containing many symbols had a pen-stroke that was very thin compared to the symbol's proportions. Using the stroke scaling methods mentioned, resizing to smaller images made the strokes thinner, which is desirable\n- Transformations on the symbols that change their proportions would not increase stroke width or make the stroke disappear\n- It is easy to create new datasets out of this one by easily thickening strokes, or adding noise and artificial irregularities\n\n### **Tools for the Dataset Creation**\nIn the following github repository, one can access the code, as well as the modules I created to perform the following tasks:\n- Import large images containing multiple symbols to be extracted\n- Agglomerate each independent symbol, perform image processes on them (resizing, scaling, and rotating) and save them to individual images\n- Create custom datasets out of the individual images for training, validation, and testing of machine learning models (e.g. neural networks)\n\nhttps://github.com/michheusser/neural-network-training\n- *main_dataset_creation.py* - Creation of datasets\n- *main_neural_network_training.py* - Training of neural network\n- *datatools* (Folder) - Package for dataset and image manipulation\n- *nntools* (Folder) - Package with neural network tools (incl. training)\n\n# Content\n*CompleteImages* - ca. 300'000 symbol images as .png containing transformation information in their name with syntax: [symbol]_[papersheet_index]_[rotation]_[index in untransformed dataset]_scaled_x[scaling in x]y[scaling in y].png (e.g. +_1_8ccw_26_scaled_x1_2y1_2.png)\n\n- *CompleteDataSet_tuples.npy* - List of tuples with all datapoints. (ca. 300'000 Datapoints)\n- *CompleteDataSet_training_tuples.npy* - Training dataset (60% of CompleteDataSet.npy randomly selected)\n- *CompleteDataSet_validation_tuples.npy* - Validation dataset (20% of CompleteDataSet.npy randomly selected)\n- *CompleteDataSet_testing_tuples.npy*- Testing dataset (20% of CompleteDataSet.npy randomly selected)\n\n### **Creation**\nThe datasets were created in the following way:\n- I drew each symbol in ~500 ways on pieces of white paper using a thin pen, and scanned them to .pdf images.\n- All images were run through my 'datatool' module for each symbol to be isolated and fit into a 28x28 greyscale .png with each pixel being either black or white\n- Each image was transformed with all possible combinations of the following: rotation (-15\u00b0, -8\u00b0, 0\u00b0, 8\u00b0, 15\u00b0), stretching in each axis (1, 1.2, 1.3). Each transformed image was saved as a .png\n- Datasets were created as lists of tuples containing a numpy array with the image pixel information (0 or 1) and the corresponding symbol as a string, and saved with a .npy extension\n\n**Disclaimer**: since the strokes sometimes tend to be more than one pixel thick, white spaces might appear in scaled images, which is a consequence of the stroke scaling algorithm. this does not affect the performance of the trained network since it can be considered a type of added \"noise\"\n\n\n# Acknowledgements\nGreatful to the StackOverflow community for it's responsiveness in practical problem-solving, as well as the various papers that allowed a better, deeper understanding of handwritten symbol recognition in the context of neural networks. To name a few:\nhttps://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00052\nhttps://ieeexplore.ieee.org/abstract/document/291440\nhttps://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541",
  "datasetId": 763806,
  "datasetSlug": "handwritten-digits-and-operators",
  "hasDatasetSlug": true,
  "ownerUser": "michelheusser",
  "hasOwnerUser": true,
  "usabilityRating": 0.9375,
  "hasUsabilityRating": true,
  "totalViews": 14514,
  "totalVotes": 33,
  "totalDownloads": 1534,
  "title": "Dataset: Handwritten Digits and Operators",
  "hasTitle": true,
  "subtitle": "Includes digits (0-9) and simple mathematical operators (+-*/[]) ",
  "hasSubtitle": true,
  "description": "# Context\nI created this dataset as part of a larger, rather educational project, which aims to create a simple web-interface to write simple numerical mathematical operations on a drawing grid (either on a PC, tablet, or smartphone), which is then recognized and evaluated. It also aims, however, to contribute and help other projects that may involve or require large datasets of handwritten digits.\n\n### Dataset Characteristics\nWhat makes this dataset different from existing ones, is that it lays emphasis on the actual strokes of handwritten signs, instead of just being a compilation of scanned images of existing records (the way, for example, the MNIST dataset was created). Each pixel is strictly full black, or full white (no greytones), and the strokes are rather thin. It is meant to have the information of the stroke itself, and not just a scanned image.\n\n### **In the Context of Neural Networks and Deep Learning**\nThe dataset is meant to stretch and challenge the understanding of a neural network about what makes a specific symbol mean what it does. For this, I initially created a starting dataset of the different ways people write symbols, playing with their internal proportions and adding \"ill\"-written signs that are still barely recognizable from the rest. After that, I artificially augmented the dataset by performing stretches and small rotations on all images, making sure that a human being would still recognize them. A neural network would be then forced to understand better what gives a symbol its characteristics. I made sure not to delete many, rather ambiguous, cases (e.g. a clockwise-rotated '1' and '/') for the neural network to have to deal and understand nuances during training and classification.\n\nUsing 60% of the dataset (randomly selected) to train a neural network with two inner layers, and 20% to validate it, I achieved a **+96%** validation accuracy using my own implementation of the stochastic gradient descent and backpropagation algorithm.\n\n### **Data Augmentation**\nThe resizing, rotating, and scaling algorithms I wrote do not work with images by modifying each pixel, but rather the stroke. This means, that each line of one pixel width is scaled/resized/rotated to a line (longer or shorter) of the same pixel width. This is advantageous for the following reasons:\n- When I created the dataset, the original images containing many symbols had a pen-stroke that was very thin compared to the symbol's proportions. Using the stroke scaling methods mentioned, resizing to smaller images made the strokes thinner, which is desirable\n- Transformations on the symbols that change their proportions would not increase stroke width or make the stroke disappear\n- It is easy to create new datasets out of this one by easily thickening strokes, or adding noise and artificial irregularities\n\n### **Tools for the Dataset Creation**\nIn the following github repository, one can access the code, as well as the modules I created to perform the following tasks:\n- Import large images containing multiple symbols to be extracted\n- Agglomerate each independent symbol, perform image processes on them (resizing, scaling, and rotating) and save them to individual images\n- Create custom datasets out of the individual images for training, validation, and testing of machine learning models (e.g. neural networks)\n\nhttps://github.com/michheusser/neural-network-training\n- *main_dataset_creation.py* - Creation of datasets\n- *main_neural_network_training.py* - Training of neural network\n- *datatools* (Folder) - Package for dataset and image manipulation\n- *nntools* (Folder) - Package with neural network tools (incl. training)\n\n# Content\n*CompleteImages* - ca. 300'000 symbol images as .png containing transformation information in their name with syntax: [symbol]_[papersheet_index]_[rotation]_[index in untransformed dataset]_scaled_x[scaling in x]y[scaling in y].png (e.g. +_1_8ccw_26_scaled_x1_2y1_2.png)\n\n- *CompleteDataSet_tuples.npy* - List of tuples with all datapoints. (ca. 300'000 Datapoints)\n- *CompleteDataSet_training_tuples.npy* - Training dataset (60% of CompleteDataSet.npy randomly selected)\n- *CompleteDataSet_validation_tuples.npy* - Validation dataset (20% of CompleteDataSet.npy randomly selected)\n- *CompleteDataSet_testing_tuples.npy*- Testing dataset (20% of CompleteDataSet.npy randomly selected)\n\n### **Creation**\nThe datasets were created in the following way:\n- I drew each symbol in ~500 ways on pieces of white paper using a thin pen, and scanned them to .pdf images.\n- All images were run through my 'datatool' module for each symbol to be isolated and fit into a 28x28 greyscale .png with each pixel being either black or white\n- Each image was transformed with all possible combinations of the following: rotation (-15\u00b0, -8\u00b0, 0\u00b0, 8\u00b0, 15\u00b0), stretching in each axis (1, 1.2, 1.3). Each transformed image was saved as a .png\n- Datasets were created as lists of tuples containing a numpy array with the image pixel information (0 or 1) and the corresponding symbol as a string, and saved with a .npy extension\n\n**Disclaimer**: since the strokes sometimes tend to be more than one pixel thick, white spaces might appear in scaled images, which is a consequence of the stroke scaling algorithm. this does not affect the performance of the trained network since it can be considered a type of added \"noise\"\n\n\n# Acknowledgements\nGreatful to the StackOverflow community for it's responsiveness in practical problem-solving, as well as the various papers that allowed a better, deeper understanding of handwritten symbol recognition in the context of neural networks. To name a few:\nhttps://www.mitpressjournals.org/doi/abs/10.1162/NECO_a_00052\nhttps://ieeexplore.ieee.org/abstract/document/291440\nhttps://www.mitpressjournals.org/doi/abs/10.1162/neco.1989.1.4.541",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "biology",
    "computer science",
    "software",
    "classification",
    "deep learning",
    "neural networks"
  ],
  "licenses": [
    {
      "nameNullable": "other",
      "name": "other",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}