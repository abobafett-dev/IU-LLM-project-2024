{
  "id": "nexuswho/tomatod",
  "id_no": 3875084,
  "datasetSlugNullable": "tomatod",
  "ownerUserNullable": "nexuswho",
  "usabilityRatingNullable": 0.875,
  "titleNullable": "tomatOD ",
  "subtitleNullable": "Annotated tomato fruit ripening classification",
  "descriptionNullable": "# tomatOD\n**tomatOD** is a dataset for tomato fruit localization and ripening classification, containing images of tomato fruits in a greenhouse and high-quality expert annotations from agriculturists. It is a task-specific object detection dataset for tomato fruits, suitable for precision agriculture applications that typically require highly-accurate localization.\n\nThe tomatOD dataset consists of 277 images with 2418 annotated tomato fruit samples of unripe, semi-ripe and fully-ripe classes.\n\n\nThe images and the annotations  are licensed under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. The contents of this repository are released under the [license](https://github.com/up2metric/tomatOD/blob/master/LICENSE).\n\nSample images with tomato fruit annotations are shown below.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/tomatOD_img1.png?raw=true\"> \n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/tomatOD_img1.png?raw=true\">\n\n\n### Data organization\nThe dataset was split into train and test set according to a 80%/20% train-test split ratio.\nPlease, note that the selection of the training and test data was conducted in a semi-random manner. The following table shows the number of images and annotated boxes of train and test sets of the tomatOD dataset.\n\n|                 | Train | Test |\n|:-----------------:|:-------:|:------:|\n| Images          | 222   | 55   |\n| Annotated <br> boxes | 1952  | 466  |\n\n### Data Format\nThe annotations of the tomatOD dataset are provided in a COCO compatible format.\n\n&gt;Fix for test annotations error in with categorical ids contributed by [ARTURO-BANDINI-JR ](https://www.kaggle.com/datasets/banddaniel)\n\n### Statistics and data analysis\n##### tomatOD classes\nThe table below shows the number of annotated objects for each class of the **tomatOD** dataset.\n\n| unripe | semi-ripe | fully-ripe |\n|:------:|:---------:|:----------:|\n| 1592   | 395       | 431        |\n\nAdditionally, the following figure illustrates the relative appearance frequencies of those three classes of the dataset.\nThe classes of the tomatOD dataset are clearly not balanced, however their relative proportion is in line with the actual appearance frequency of each class in a realistic scenario.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/classes_proportions_tomatOD.png?raw=true\">\n\n##### Size distribution of bounding boxes\nThe percentile relative size of each bounding box is calculated, which indicates the proportion of the diagonal length of each box over the diagonal length of the image.\nIn the image below, the histogram of the percentile relative size distribution of the tomatOD bounding boxes is presented.\nMost of the bounding boxes have a size of 3% to 15% relative to the image size.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/histogramm_boxes.png?raw=true\">\n\n##### Number of labelled instances per image\nOnly 1% of images have one category per image and 11% of images include 8 instances, while the maximum number of instances per image, which is 20, is found only in 0.72% of the images.\nThe tomatOD dataset has an average of 8.7 instances per image. The image displays the histogram of the number of annotation instances per image.\n\n<img src=\"./assets/instances_per_image.png\">\n\n\n##### Number of categories in images\nAs the next figure shows, more than 50% of the tomatOD images contain objects of all 3 categories, while less than 8% of the images have objects of a single category.  \n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/categories_in_images.png?raw=true\">\n\n\n### Experiment\nSix state-of-the-art detectors are evaluated at the proposed tomatOD dataset. In detail, Faster RCNN with Inception v2, SSD with both Inception v2 and Mobilenet v2, PPN with Inception v2, RetinaNet (ResNet 101) and Yolo v3 are trained on tomatOD train set for 450 epochs, all of them pretrained on COCO dataset. Afterwards, they are evaluated on test set. Hyperparameter fine-tuning was performed for all networks in order to perform optimally on the tomatOD dataset.\n\nThe figure below illustrates the accuracy over epochs for both the train and the test set for every trained model.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/accuracy_vs_epochs.png?raw=true\">\n\nRetina outperformed the rest detectors, yielding an accuracy of 79.4 %. The average precision of each class, the mAP metrics and precision-recall curves for classes of RetinaNet are listed.\n\nIn the precision-recall curves diagram, the unripe class is indicated by the green line, the semi-ripe class by the orange line, while the fully-ripe class by red line.\n\n| | unripe AP (%)| semi-ripe AP (%)| fully-ripe  (%)| mAP  (%)|\n|:------:|:------:|:---------:|:----------:|:----------:|\n| RetinaNet | 91.47   | 55.28       | 76.77       | 74.51 |\n\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/pr_curves_retinanet.png?raw=true\">\n\n\n### Citations\nWe hope that researchers in any domain will find the tomatOD dataset helpful for their own research. If you use the tomatOD dataset in your work, please cite it as:\n\n\"Tsironis V., Bourou S., Stentoumis C. (2020). tomatOD: Evaluation of object detection algorithms on a new real-world tomato dataset. In ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. Available from https://github.com/up2metric/tomatOD \".",
  "datasetId": 3875084,
  "datasetSlug": "tomatod",
  "hasDatasetSlug": true,
  "ownerUser": "nexuswho",
  "hasOwnerUser": true,
  "usabilityRating": 0.875,
  "hasUsabilityRating": true,
  "totalViews": 3263,
  "totalVotes": 16,
  "totalDownloads": 321,
  "title": "tomatOD ",
  "hasTitle": true,
  "subtitle": "Annotated tomato fruit ripening classification",
  "hasSubtitle": true,
  "description": "# tomatOD\n**tomatOD** is a dataset for tomato fruit localization and ripening classification, containing images of tomato fruits in a greenhouse and high-quality expert annotations from agriculturists. It is a task-specific object detection dataset for tomato fruits, suitable for precision agriculture applications that typically require highly-accurate localization.\n\nThe tomatOD dataset consists of 277 images with 2418 annotated tomato fruit samples of unripe, semi-ripe and fully-ripe classes.\n\n\nThe images and the annotations  are licensed under [CC BY-NC-SA 4.0](https://creativecommons.org/licenses/by-nc-sa/4.0/) license. The contents of this repository are released under the [license](https://github.com/up2metric/tomatOD/blob/master/LICENSE).\n\nSample images with tomato fruit annotations are shown below.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/tomatOD_img1.png?raw=true\"> \n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/tomatOD_img1.png?raw=true\">\n\n\n### Data organization\nThe dataset was split into train and test set according to a 80%/20% train-test split ratio.\nPlease, note that the selection of the training and test data was conducted in a semi-random manner. The following table shows the number of images and annotated boxes of train and test sets of the tomatOD dataset.\n\n|                 | Train | Test |\n|:-----------------:|:-------:|:------:|\n| Images          | 222   | 55   |\n| Annotated <br> boxes | 1952  | 466  |\n\n### Data Format\nThe annotations of the tomatOD dataset are provided in a COCO compatible format.\n\n&gt;Fix for test annotations error in with categorical ids contributed by [ARTURO-BANDINI-JR ](https://www.kaggle.com/datasets/banddaniel)\n\n### Statistics and data analysis\n##### tomatOD classes\nThe table below shows the number of annotated objects for each class of the **tomatOD** dataset.\n\n| unripe | semi-ripe | fully-ripe |\n|:------:|:---------:|:----------:|\n| 1592   | 395       | 431        |\n\nAdditionally, the following figure illustrates the relative appearance frequencies of those three classes of the dataset.\nThe classes of the tomatOD dataset are clearly not balanced, however their relative proportion is in line with the actual appearance frequency of each class in a realistic scenario.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/classes_proportions_tomatOD.png?raw=true\">\n\n##### Size distribution of bounding boxes\nThe percentile relative size of each bounding box is calculated, which indicates the proportion of the diagonal length of each box over the diagonal length of the image.\nIn the image below, the histogram of the percentile relative size distribution of the tomatOD bounding boxes is presented.\nMost of the bounding boxes have a size of 3% to 15% relative to the image size.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/histogramm_boxes.png?raw=true\">\n\n##### Number of labelled instances per image\nOnly 1% of images have one category per image and 11% of images include 8 instances, while the maximum number of instances per image, which is 20, is found only in 0.72% of the images.\nThe tomatOD dataset has an average of 8.7 instances per image. The image displays the histogram of the number of annotation instances per image.\n\n<img src=\"./assets/instances_per_image.png\">\n\n\n##### Number of categories in images\nAs the next figure shows, more than 50% of the tomatOD images contain objects of all 3 categories, while less than 8% of the images have objects of a single category.  \n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/categories_in_images.png?raw=true\">\n\n\n### Experiment\nSix state-of-the-art detectors are evaluated at the proposed tomatOD dataset. In detail, Faster RCNN with Inception v2, SSD with both Inception v2 and Mobilenet v2, PPN with Inception v2, RetinaNet (ResNet 101) and Yolo v3 are trained on tomatOD train set for 450 epochs, all of them pretrained on COCO dataset. Afterwards, they are evaluated on test set. Hyperparameter fine-tuning was performed for all networks in order to perform optimally on the tomatOD dataset.\n\nThe figure below illustrates the accuracy over epochs for both the train and the test set for every trained model.\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/accuracy_vs_epochs.png?raw=true\">\n\nRetina outperformed the rest detectors, yielding an accuracy of 79.4 %. The average precision of each class, the mAP metrics and precision-recall curves for classes of RetinaNet are listed.\n\nIn the precision-recall curves diagram, the unripe class is indicated by the green line, the semi-ripe class by the orange line, while the fully-ripe class by red line.\n\n| | unripe AP (%)| semi-ripe AP (%)| fully-ripe  (%)| mAP  (%)|\n|:------:|:------:|:---------:|:----------:|:----------:|\n| RetinaNet | 91.47   | 55.28       | 76.77       | 74.51 |\n\n\n<img src=\"https://github.com/nexuswho/tomatOD/blob/master/assets/pr_curves_retinanet.png?raw=true\">\n\n\n### Citations\nWe hope that researchers in any domain will find the tomatOD dataset helpful for their own research. If you use the tomatOD dataset in your work, please cite it as:\n\n\"Tsironis V., Bourou S., Stentoumis C. (2020). tomatOD: Evaluation of object detection algorithms on a new real-world tomato dataset. In ISPRS - International Archives of the Photogrammetry, Remote Sensing and Spatial Information Sciences. Available from https://github.com/up2metric/tomatOD \".",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "computer vision",
    "classification",
    "image",
    "food"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}