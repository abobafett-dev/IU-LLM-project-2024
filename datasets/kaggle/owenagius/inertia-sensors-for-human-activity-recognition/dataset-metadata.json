{
  "id": "owenagius/inertia-sensors-for-human-activity-recognition",
  "id_no": 1440292,
  "datasetSlugNullable": "inertia-sensors-for-human-activity-recognition",
  "ownerUserNullable": "owenagius",
  "usabilityRatingNullable": 0.9411764705882353,
  "titleNullable": "Inertia Sensors for Human Activity Recognition",
  "subtitleNullable": "Accelerometer, Linear Acceleration, Gravity and Gyroscopic inertia readings",
  "descriptionNullable": "The main scope of this project is to implement a Human Activity Recognition System (HAR System). The purpose of this system is to identify the action which the user would be doing, solely based off of the changes in motion of the user\u2019s body during the performance of specific actions.\n\nMost HAR systems implemented would use specialised motion sensors that would be secured to the users\u2019 body, including, but not limited to, the waist, chest, arms and legs. However, the main problem with this type of system is the complex setup the user would be required to wear during the activity, in addition to the added expenses when purchasing these sensors. Considering the simplicity of the application, many users are more likely to get discouraged in using such a complex, albeit excessive, set up. As a result of the rapid advancements in the technological field as well as the efforts of many researchers, this setup has been reduced to needing only a smartphone. This initial set-up made use of a bulkier mounting system through the use of a belt, an aspect of the set-up which can be improved upon, with the users\u2019 comfort being the main priority.\n\nTherefore, for our project, we were aiming to develop a simple Human Activity Recognition prototype which only uses the built-in sensors found in an average smartphone and eliminating the use of a belt mount, allowing the user to carry their phone in their pockets. While this may result in less accurate predictions, it allows users to retain their usual habits; keeping their phone in their pockets.\n\nMoreover, two separate datasets were gathered by the three members working on this APT. The first dataset was done to mimic that made in the paper [1] with six total actions: Walking, Walking Downstairs, Walking Upstairs, Sitting, Standing, and Laying. This dataset was created in order to compare the difference in results gathered and processed by Anguita et al. and ourselves. However, we also collected a second dataset in which we chose physical activities which were not included in the existing data. These also required body movement from the user and were recorded through the accelerometer and gyroscope sensors found in the smartphone. The final new activities are Cycling, Football, Swimming, Tennis, Jump Rope and Push-ups. In summary, the main aim of this project was not only to interpret the original six activities that most Human Activity Recognition papers tend to focus on, but also to recognise another six unique physical activities.\n \nThe process of classifying the data with a high accuracy can be divided into two steps: data collection and modelling. In order to collect a sufficient amount of data, the free app \u2018AndroSensor\u2019 was used. Using this app allowed for the collection of data using the four main inertia sensors: gyroscope, gravity, accelerometer and linear acceleration. The data collected consists of roughly one hour worth of data for each of the 12 activities mentioned above, allowing for the model to be developed with an even distribution of data across all the categories.\n\nAfter the data is collected, it is pre-processed. The pre-processing entails the removal of \u201cNaN\u201d and duplicated values while also generating statistical readings from the \u2018csv\u2019 file produced by \u2018AndroSensor\u2019. After being processed, the data is analysed via a t-SNE algorithm which aids the visualisation of data clusters. Finally, the data is modelled and classified using four different supervised machine learning algorithms: Logistic Regression, Support Vector Machines, Decision Trees and K-Nearest Neighbours.\n\nDo not hestitate to contact me on owenagius24@gmail.com if you wish to see the whole report.",
  "datasetId": 1440292,
  "datasetSlug": "inertia-sensors-for-human-activity-recognition",
  "hasDatasetSlug": true,
  "ownerUser": "owenagius",
  "hasOwnerUser": true,
  "usabilityRating": 0.9411764705882353,
  "hasUsabilityRating": true,
  "totalViews": 5974,
  "totalVotes": 19,
  "totalDownloads": 593,
  "title": "Inertia Sensors for Human Activity Recognition",
  "hasTitle": true,
  "subtitle": "Accelerometer, Linear Acceleration, Gravity and Gyroscopic inertia readings",
  "hasSubtitle": true,
  "description": "The main scope of this project is to implement a Human Activity Recognition System (HAR System). The purpose of this system is to identify the action which the user would be doing, solely based off of the changes in motion of the user\u2019s body during the performance of specific actions.\n\nMost HAR systems implemented would use specialised motion sensors that would be secured to the users\u2019 body, including, but not limited to, the waist, chest, arms and legs. However, the main problem with this type of system is the complex setup the user would be required to wear during the activity, in addition to the added expenses when purchasing these sensors. Considering the simplicity of the application, many users are more likely to get discouraged in using such a complex, albeit excessive, set up. As a result of the rapid advancements in the technological field as well as the efforts of many researchers, this setup has been reduced to needing only a smartphone. This initial set-up made use of a bulkier mounting system through the use of a belt, an aspect of the set-up which can be improved upon, with the users\u2019 comfort being the main priority.\n\nTherefore, for our project, we were aiming to develop a simple Human Activity Recognition prototype which only uses the built-in sensors found in an average smartphone and eliminating the use of a belt mount, allowing the user to carry their phone in their pockets. While this may result in less accurate predictions, it allows users to retain their usual habits; keeping their phone in their pockets.\n\nMoreover, two separate datasets were gathered by the three members working on this APT. The first dataset was done to mimic that made in the paper [1] with six total actions: Walking, Walking Downstairs, Walking Upstairs, Sitting, Standing, and Laying. This dataset was created in order to compare the difference in results gathered and processed by Anguita et al. and ourselves. However, we also collected a second dataset in which we chose physical activities which were not included in the existing data. These also required body movement from the user and were recorded through the accelerometer and gyroscope sensors found in the smartphone. The final new activities are Cycling, Football, Swimming, Tennis, Jump Rope and Push-ups. In summary, the main aim of this project was not only to interpret the original six activities that most Human Activity Recognition papers tend to focus on, but also to recognise another six unique physical activities.\n \nThe process of classifying the data with a high accuracy can be divided into two steps: data collection and modelling. In order to collect a sufficient amount of data, the free app \u2018AndroSensor\u2019 was used. Using this app allowed for the collection of data using the four main inertia sensors: gyroscope, gravity, accelerometer and linear acceleration. The data collected consists of roughly one hour worth of data for each of the 12 activities mentioned above, allowing for the model to be developed with an even distribution of data across all the categories.\n\nAfter the data is collected, it is pre-processed. The pre-processing entails the removal of \u201cNaN\u201d and duplicated values while also generating statistical readings from the \u2018csv\u2019 file produced by \u2018AndroSensor\u2019. After being processed, the data is analysed via a t-SNE algorithm which aids the visualisation of data clusters. Finally, the data is modelled and classified using four different supervised machine learning algorithms: Logistic Regression, Support Vector Machines, Decision Trees and K-Nearest Neighbours.\n\nDo not hestitate to contact me on owenagius24@gmail.com if you wish to see the whole report.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "health",
    "artificial intelligence"
  ],
  "licenses": [
    {
      "nameNullable": "EU ODP Legal Notice",
      "name": "EU ODP Legal Notice",
      "hasName": true
    }
  ],
  "collaborators": [
    {
      "username": "francescamariamizzi",
      "role": "writer"
    },
    {
      "username": "seanfarrugia8",
      "role": "writer"
    }
  ],
  "data": []
}