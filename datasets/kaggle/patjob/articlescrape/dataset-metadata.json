{
  "id": "patjob/articlescrape",
  "id_no": 1264,
  "datasetSlugNullable": "articlescrape",
  "ownerUserNullable": "patjob",
  "usabilityRatingNullable": 0.7647058823529411,
  "titleNullable": "News and Blog Data Crawl",
  "subtitleNullable": "Content section from over 160,000 news and blog articles",
  "descriptionNullable": "# Context \n\nThis content was scraped for a previous project in 2014. I thought this community might find it useful. \n\nIt was originally used as part of an English learning application, which automatically tailored exercises that were optimized to accelerate language acquisition.  Unfortunately, the app was not commercially viable.\n\n# Content\n\nEach record contains the following variables\n\n - body: The article body text.\n - title: The article header.\n - last_crawl_date: The date that this article was crawled.\n - url: The original URL of the article.\n\nDue to upload size limits, I've had to remove many of the articles. But the original is well over the 500MB upload limit.\n\nThe file may contain duplicate or low-value records. It also contains broken tags and characters. The corpus should be cleaned before use. \n\n# Inspiration\n\nUse NLP and classification to figure out which web site an article came from. ",
  "datasetId": 1264,
  "datasetSlug": "articlescrape",
  "hasDatasetSlug": true,
  "ownerUser": "patjob",
  "hasOwnerUser": true,
  "usabilityRating": 0.7647058823529411,
  "hasUsabilityRating": true,
  "totalViews": 9624,
  "totalVotes": 10,
  "totalDownloads": 665,
  "title": "News and Blog Data Crawl",
  "hasTitle": true,
  "subtitle": "Content section from over 160,000 news and blog articles",
  "hasSubtitle": true,
  "description": "# Context \n\nThis content was scraped for a previous project in 2014. I thought this community might find it useful. \n\nIt was originally used as part of an English learning application, which automatically tailored exercises that were optimized to accelerate language acquisition.  Unfortunately, the app was not commercially viable.\n\n# Content\n\nEach record contains the following variables\n\n - body: The article body text.\n - title: The article header.\n - last_crawl_date: The date that this article was crawled.\n - url: The original URL of the article.\n\nDue to upload size limits, I've had to remove many of the articles. But the original is well over the 500MB upload limit.\n\nThe file may contain duplicate or low-value records. It also contains broken tags and characters. The corpus should be cleaned before use. \n\n# Inspiration\n\nUse NLP and classification to figure out which web site an article came from. ",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "linguistics",
    "internet",
    "news"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}