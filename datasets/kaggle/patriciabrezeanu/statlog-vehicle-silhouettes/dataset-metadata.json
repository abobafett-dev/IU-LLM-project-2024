{
  "id": "patriciabrezeanu/statlog-vehicle-silhouettes",
  "id_no": 3125513,
  "datasetSlugNullable": "statlog-vehicle-silhouettes",
  "ownerUserNullable": "patriciabrezeanu",
  "usabilityRatingNullable": 1.0,
  "titleNullable": "Statlog Vehicle Silhouettes",
  "subtitleNullable": "Classify a given silhouette as one of four types of vehicle",
  "descriptionNullable": "**NAME** \nVehicle silhouettes\n\n**PURPOSE**\nTo classify a given silhouette as one of four types of vehicle, using a set of features extracted from the silhouette. The\tvehicle may be viewed from one of many different angles.  \n\n**PROBLEM TYPE** \nClassification\t\n\n**SOURCE**\nDrs.Pete Mowforth and Barry Shepherd\nTuring Institute\nGeorge House\n36 North Hanover St.\nGlasgow\nG1 2AD\n\n**CONTACT**\nAlistair Sutherland\nStatistics Dept.\nStrathclyde University\nLivingstone Tower\n26 Richmond St.\nGLASGOW G1 1XH\nGreat Britain\nTel: 041 552 4400 x3033\nFax: 041 552 4711 \ne-mail: alistair@uk.ac.strathclyde.stams\n\n**HISTORY**\nThis data was originally gathered at the TI in 1986-87 by JP Siebert. It was partially financed by Barr and Stroud Ltd. The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects. Measures of shape features extracted from example silhouettes of objects to be discriminated were used to generate a classification rule tree by means of computer induction. This object recognition strategy was successfully used to discriminate between silhouettes of model cars, vans, and buses viewed from constrained elevation but all angles of rotation.\nThe rule tree classification performance compared favourably to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neighbour) statistical classifiers in terms of both error rate and computational efficiency. An investigation of these rule trees generated by example indicated that the tree structure was heavily influenced by the orientation of the objects, and grouped similar object views into single decisions.\n\n**DESCRIPTION**\nThe features were extracted from the silhouettes by the HIPS (Hierarchical Image Processing System) extension BINATTS, which extracts a combination of scale-independent features utilising both classical moments-based measures such as scaled variance, skewness and kurtosis about the major/minor axes and heuristic measures such as hollows, circularity, rectangularity, and compactness.\nFour \"Corgie\" model vehicles were used for the experiment: a double-decker bus, a Chevrolet van, a Saab 9000, and an Opel Manta 400. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.\nThe images were acquired by a camera looking downwards at the model vehicle from a fixed angle of elevation (34.2 degrees to the horizontal). The vehicles were placed on a diffuse backlit surface (lightbox). The vehicles were painted matte black to minimize highlights. The images were captured using a CRS4000 Framestore connected to a Vax 750. All images were captured with a spatial resolution of 128x128 pixels quantized to 64 grey levels. These images were thresholded to produce binary vehicle silhouettes, negated (to comply with the processing requirements of BINATTS), and thereafter subjected to shrink-expand-expand-shrink HIPS modules to remove the \"salt and pepper\" image noise. The vehicles were rotated and their angle of orientation was measured using a radial graticule beneath the vehicle. 0 and 180 degrees corresponded to \"head on\" and \"rear\" views respectively while 90 and 270 corresponded to profiles in opposite directions. Two sets of 60 images, each set covering a full 360-degree rotation, were captured for each vehicle. The vehicle was rotated by a fixed angle between images. These datasets are known as e2 and e3 respectively. A further two sets of images, e4, and e5, were captured with the camera at elevations of 37.5 degrees and 30.8 degrees respectively. These sets also contain 60 images per vehicle apart from e4.van which contains only 46 owing to the difficulty of containing the van in the image at some orientations.",
  "datasetId": 3125513,
  "datasetSlug": "statlog-vehicle-silhouettes",
  "hasDatasetSlug": true,
  "ownerUser": "patriciabrezeanu",
  "hasOwnerUser": true,
  "usabilityRating": 1.0,
  "hasUsabilityRating": true,
  "totalViews": 1587,
  "totalVotes": 10,
  "totalDownloads": 264,
  "title": "Statlog Vehicle Silhouettes",
  "hasTitle": true,
  "subtitle": "Classify a given silhouette as one of four types of vehicle",
  "hasSubtitle": true,
  "description": "**NAME** \nVehicle silhouettes\n\n**PURPOSE**\nTo classify a given silhouette as one of four types of vehicle, using a set of features extracted from the silhouette. The\tvehicle may be viewed from one of many different angles.  \n\n**PROBLEM TYPE** \nClassification\t\n\n**SOURCE**\nDrs.Pete Mowforth and Barry Shepherd\nTuring Institute\nGeorge House\n36 North Hanover St.\nGlasgow\nG1 2AD\n\n**CONTACT**\nAlistair Sutherland\nStatistics Dept.\nStrathclyde University\nLivingstone Tower\n26 Richmond St.\nGLASGOW G1 1XH\nGreat Britain\nTel: 041 552 4400 x3033\nFax: 041 552 4711 \ne-mail: alistair@uk.ac.strathclyde.stams\n\n**HISTORY**\nThis data was originally gathered at the TI in 1986-87 by JP Siebert. It was partially financed by Barr and Stroud Ltd. The original purpose was to find a method of distinguishing 3D objects within a 2D image by application of an ensemble of shape feature extractors to the 2D silhouettes of the objects. Measures of shape features extracted from example silhouettes of objects to be discriminated were used to generate a classification rule tree by means of computer induction. This object recognition strategy was successfully used to discriminate between silhouettes of model cars, vans, and buses viewed from constrained elevation but all angles of rotation.\nThe rule tree classification performance compared favourably to MDC (Minimum Distance Classifier) and k-NN (k-Nearest Neighbour) statistical classifiers in terms of both error rate and computational efficiency. An investigation of these rule trees generated by example indicated that the tree structure was heavily influenced by the orientation of the objects, and grouped similar object views into single decisions.\n\n**DESCRIPTION**\nThe features were extracted from the silhouettes by the HIPS (Hierarchical Image Processing System) extension BINATTS, which extracts a combination of scale-independent features utilising both classical moments-based measures such as scaled variance, skewness and kurtosis about the major/minor axes and heuristic measures such as hollows, circularity, rectangularity, and compactness.\nFour \"Corgie\" model vehicles were used for the experiment: a double-decker bus, a Chevrolet van, a Saab 9000, and an Opel Manta 400. This particular combination of vehicles was chosen with the expectation that the bus, van and either one of the cars would be readily distinguishable, but it would be more difficult to distinguish between the cars.\nThe images were acquired by a camera looking downwards at the model vehicle from a fixed angle of elevation (34.2 degrees to the horizontal). The vehicles were placed on a diffuse backlit surface (lightbox). The vehicles were painted matte black to minimize highlights. The images were captured using a CRS4000 Framestore connected to a Vax 750. All images were captured with a spatial resolution of 128x128 pixels quantized to 64 grey levels. These images were thresholded to produce binary vehicle silhouettes, negated (to comply with the processing requirements of BINATTS), and thereafter subjected to shrink-expand-expand-shrink HIPS modules to remove the \"salt and pepper\" image noise. The vehicles were rotated and their angle of orientation was measured using a radial graticule beneath the vehicle. 0 and 180 degrees corresponded to \"head on\" and \"rear\" views respectively while 90 and 270 corresponded to profiles in opposite directions. Two sets of 60 images, each set covering a full 360-degree rotation, were captured for each vehicle. The vehicle was rotated by a fixed angle between images. These datasets are known as e2 and e3 respectively. A further two sets of images, e4, and e5, were captured with the camera at elevations of 37.5 degrees and 30.8 degrees respectively. These sets also contain 60 images per vehicle apart from e4.van which contains only 46 owing to the difficulty of containing the van in the image at some orientations.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "automobiles and vehicles",
    "beginner",
    "logistic regression",
    "tabular",
    "multiclass classification"
  ],
  "licenses": [
    {
      "nameNullable": "other",
      "name": "other",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}