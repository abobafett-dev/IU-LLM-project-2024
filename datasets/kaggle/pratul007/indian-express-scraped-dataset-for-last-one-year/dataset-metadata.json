{
  "id": "pratul007/indian-express-scraped-dataset-for-last-one-year",
  "id_no": 3610287,
  "datasetSlugNullable": "indian-express-scraped-dataset-for-last-one-year",
  "ownerUserNullable": "pratul007",
  "usabilityRatingNullable": 1.0,
  "titleNullable": "Indian Express Scraped Dataset for Last One Year",
  "subtitleNullable": "Scraped Indian Political Last One Year Data",
  "descriptionNullable": "### Dataset Description: Indian Express Articles (Last One Year)\n\n**Source**: \nThe dataset appears to have been extracted from the Indian Express website, containing articles from the past year.\n\n**Columns**:\n\n1. **Headline**: The title or headline of the news article.\n2. **Link**: The URL where the full article can be accessed.\n3. **Written By**: The author or journalist who penned the article. This can be useful for analyzing articles by specific authors or understanding the most prolific writers.\n4. **Timestamp**: The date and time the article was published. This is crucial for temporal analysis or understanding news trends over time.\n5. **News Content**: The primary content of the article. This column is the most vital for most textual analyses like sentiment analysis, topic modeling, and keyword extraction.\n\n**Potential Unnamed Columns**: \nThere seem to be a number of unnamed columns, possibly due to data extraction issues or formatting errors in the CSV. These columns might need cleaning or removal for more streamlined analysis.\n\n**Content Overview**: \n\n- The articles cover a broad range of topics, as is typical for a mainstream newspaper. \n- Based on our preliminary analysis, there is a significant focus on political entities and events, with mentions of figures like \"Narendra Modi\", \"Rahul Gandhi\", and \"Amit Shah\", as well as political parties like \"BJP\" and \"Congress\".\n- The dataset provides a rich source for sentiment analysis, understanding the news cycle's ebb and flow, and gaining insights into the primary issues covered by the Indian Express over the last year.\n\n**Use Cases**:\n\n1. **Sentiment Analysis**: Understand the general sentiment of articles over time or towards specific entities.\n2. **Topic Modeling**: Extract the main themes or topics covered in the dataset.\n3. **Temporal Analysis**: Investigate the frequency and type of articles over time.\n4. **Author Analysis**: Analyze the writing style, frequency, and topics covered by specific authors.\n5. **Keyword Extraction and Co-occurrence**: Identify the most discussed terms and how they are interrelated.\n\n**Recommendations for Data Processing**:\n\n1. Cleaning or removing the unnamed columns to reduce noise in the dataset.\n2. Handling missing values, especially in the 'News Content' column, as they can affect textual analysis.\n3. Potential categorization or tagging of articles based on extracted topics or themes for easier retrieval and analysis.\n\n---\n\n### Web Scraping Script for Indian Express Articles\n\nThe below script was used to scrape articles from the Indian Express website:\n\n```python\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\nBASE_URL = \"https://indianexpress.com/section/political-pulse/page/{}/\"\n\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n\ndef get_article_content(url):\n    try:\n        response = requests.get(url, headers=headers)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        p_tags = soup.find_all('p')\n        content = ' '.join([p.text for p in p_tags])\n        return content\n    except Exception as e:\n        print(f\"Error fetching content for URL: {url}. Error: {e}\")\n        return None\n\ndef scrape_data():\n    all_data = []\n\n    for page_number in range(1, 201):\n        url = BASE_URL.format(page_number)\n        response = requests.get(url, headers=headers)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        articles = soup.find_all('div', class_='articles')\n\n        for article in articles:\n            headline_tag = article.find('h2')\n            link = headline_tag.a['href'] if headline_tag and headline_tag.a else \"N/A\"\n            \n            article_response = requests.get(link, headers=headers)\n            article_soup = BeautifulSoup(article_response.content, 'html.parser')\n\n            written_by_tag = article_soup.find('a', class_='bulletProj', id='written_by1')\n            written_by = written_by_tag.text.strip() if written_by_tag else \"N/A\"\n            \n            timestamp_tag = article_soup.find('span', itemprop='dateModified')\n            timestamp = timestamp_tag.text.replace(\"Updated: \", \"\").strip() if timestamp_tag else \"N/A\"\n            \n            content = get_article_content(link)\n\n            all_data.append([headline_tag.text.strip(), link, written_by, timestamp, content])\n    \n    return all_data\n\ndef save_to_csv(data):\n    df = pd.DataFrame(data, columns=['Headline', 'Link', 'Written By', 'Timestamp', 'News Content'])\n    df.to_csv('indian_express_political_article_one_year_scraped.csv, index=False, encoding='utf-8')\n    print(\"Data saved to indian_express_article_details_all.csv\")\n\ndef main():\n    data = scrape_data()\n    save_to_csv(data)\n\nif __name__ == \"__main__\":\n    main()\n```",
  "datasetId": 3610287,
  "datasetSlug": "indian-express-scraped-dataset-for-last-one-year",
  "hasDatasetSlug": true,
  "ownerUser": "pratul007",
  "hasOwnerUser": true,
  "usabilityRating": 1.0,
  "hasUsabilityRating": true,
  "totalViews": 483,
  "totalVotes": 3,
  "totalDownloads": 76,
  "title": "Indian Express Scraped Dataset for Last One Year",
  "hasTitle": true,
  "subtitle": "Scraped Indian Political Last One Year Data",
  "hasSubtitle": true,
  "description": "### Dataset Description: Indian Express Articles (Last One Year)\n\n**Source**: \nThe dataset appears to have been extracted from the Indian Express website, containing articles from the past year.\n\n**Columns**:\n\n1. **Headline**: The title or headline of the news article.\n2. **Link**: The URL where the full article can be accessed.\n3. **Written By**: The author or journalist who penned the article. This can be useful for analyzing articles by specific authors or understanding the most prolific writers.\n4. **Timestamp**: The date and time the article was published. This is crucial for temporal analysis or understanding news trends over time.\n5. **News Content**: The primary content of the article. This column is the most vital for most textual analyses like sentiment analysis, topic modeling, and keyword extraction.\n\n**Potential Unnamed Columns**: \nThere seem to be a number of unnamed columns, possibly due to data extraction issues or formatting errors in the CSV. These columns might need cleaning or removal for more streamlined analysis.\n\n**Content Overview**: \n\n- The articles cover a broad range of topics, as is typical for a mainstream newspaper. \n- Based on our preliminary analysis, there is a significant focus on political entities and events, with mentions of figures like \"Narendra Modi\", \"Rahul Gandhi\", and \"Amit Shah\", as well as political parties like \"BJP\" and \"Congress\".\n- The dataset provides a rich source for sentiment analysis, understanding the news cycle's ebb and flow, and gaining insights into the primary issues covered by the Indian Express over the last year.\n\n**Use Cases**:\n\n1. **Sentiment Analysis**: Understand the general sentiment of articles over time or towards specific entities.\n2. **Topic Modeling**: Extract the main themes or topics covered in the dataset.\n3. **Temporal Analysis**: Investigate the frequency and type of articles over time.\n4. **Author Analysis**: Analyze the writing style, frequency, and topics covered by specific authors.\n5. **Keyword Extraction and Co-occurrence**: Identify the most discussed terms and how they are interrelated.\n\n**Recommendations for Data Processing**:\n\n1. Cleaning or removing the unnamed columns to reduce noise in the dataset.\n2. Handling missing values, especially in the 'News Content' column, as they can affect textual analysis.\n3. Potential categorization or tagging of articles based on extracted topics or themes for easier retrieval and analysis.\n\n---\n\n### Web Scraping Script for Indian Express Articles\n\nThe below script was used to scrape articles from the Indian Express website:\n\n```python\nimport pandas as pd\nimport requests\nfrom bs4 import BeautifulSoup\nimport csv\n\nBASE_URL = \"https://indianexpress.com/section/political-pulse/page/{}/\"\n\nheaders = {\n    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n}\n\ndef get_article_content(url):\n    try:\n        response = requests.get(url, headers=headers)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        p_tags = soup.find_all('p')\n        content = ' '.join([p.text for p in p_tags])\n        return content\n    except Exception as e:\n        print(f\"Error fetching content for URL: {url}. Error: {e}\")\n        return None\n\ndef scrape_data():\n    all_data = []\n\n    for page_number in range(1, 201):\n        url = BASE_URL.format(page_number)\n        response = requests.get(url, headers=headers)\n        soup = BeautifulSoup(response.content, 'html.parser')\n        articles = soup.find_all('div', class_='articles')\n\n        for article in articles:\n            headline_tag = article.find('h2')\n            link = headline_tag.a['href'] if headline_tag and headline_tag.a else \"N/A\"\n            \n            article_response = requests.get(link, headers=headers)\n            article_soup = BeautifulSoup(article_response.content, 'html.parser')\n\n            written_by_tag = article_soup.find('a', class_='bulletProj', id='written_by1')\n            written_by = written_by_tag.text.strip() if written_by_tag else \"N/A\"\n            \n            timestamp_tag = article_soup.find('span', itemprop='dateModified')\n            timestamp = timestamp_tag.text.replace(\"Updated: \", \"\").strip() if timestamp_tag else \"N/A\"\n            \n            content = get_article_content(link)\n\n            all_data.append([headline_tag.text.strip(), link, written_by, timestamp, content])\n    \n    return all_data\n\ndef save_to_csv(data):\n    df = pd.DataFrame(data, columns=['Headline', 'Link', 'Written By', 'Timestamp', 'News Content'])\n    df.to_csv('indian_express_political_article_one_year_scraped.csv, index=False, encoding='utf-8')\n    print(\"Data saved to indian_express_article_details_all.csv\")\n\ndef main():\n    data = scrape_data()\n    save_to_csv(data)\n\nif __name__ == \"__main__\":\n    main()\n```",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "india",
    "business",
    "politics",
    "news"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}