{
  "id": "renanaferreira/snips-natural-language-understanding-benchmark",
  "id_no": 5279371,
  "datasetSlugNullable": "snips-natural-language-understanding-benchmark",
  "ownerUserNullable": "renanaferreira",
  "usabilityRatingNullable": 0.6875,
  "titleNullable": "SNIPS Natural Language Understanding Benchmark:",
  "subtitleNullable": "",
  "descriptionNullable": "# Natural Language Understanding benchmark\n\nThis repository contains the results of three benchmarks that compare natural language understanding services offering:\n1. **built-in intents** (Apple\u2019s SiriKit, Amazon\u2019s Alexa, Microsoft\u2019s Luis,\nGoogle\u2019s API.ai, and [Snips.ai](https://snips.ai/)) on a selection of\nvarious intents. This benchmark was performed in December 2016. Its results\nare described in length in the [following post](https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d).\n2. **custom intent engines** (Google's API.ai, Facebook's Wit, Microsoft's Luis, Amazon's Alexa, and Snips' NLU) for seven chosen intents. This benchmark was performed in June 2017. Its results are described in a [paper](https://arxiv.org/abs/1805.10190) and a [blog post](https://medium.com/@alicecoucke/benchmarking-natural-language-understanding-systems-google-facebook-microsoft-and-snips-2b8ddcf9fb19).\n3. **extension of Braun et al., 2017** (Google's API.AI, Microsoft's Luis, IBM's Watson, Rasa)\nThis experiment replicates the analysis made by Braun et al., 2017, published in Evaluating Natural Language Understanding Services for Conversational Question Answering Systems as part of SIGDIAL 2017 proceedings. Snips and Rasa are added. Details are available in a [paper](https://arxiv.org/abs/1805.10190) and a [blog post](https://medium.com/snips-ai/an-introduction-to-snips-nlu-the-open-source-library-behind-snips-embedded-voice-platform-b12b1a60a41a).\n\nThe data is provided for each benchmark and more details about the methods are available in the README file in each folder.\n\n**Any publication based on these datasets must include a full citation to the following paper in which the results were published by the Snips Team:** \n\n[Coucke A. et al., \"Snips Voice Platform: an embedded Spoken Language Understanding system \nfor private-by-design voice interfaces.\" 2018,](https://arxiv.org/abs/1805.10190)\n\naccepted for a spotlight presentation at the [Privacy in Machine Learning and Artificial Intelligence workshop](https://pimlai.github.io/pimlai18/#papers) colocated with ICML 2018.\n\n\n\n *The Snips team has joined Sonos in November 2019. These open datasets remain available and their access is now managed by the Sonos Voice Experience Team. Please email sve-research@sonos.com with any question.*",
  "datasetId": 5279371,
  "datasetSlug": "snips-natural-language-understanding-benchmark",
  "hasDatasetSlug": true,
  "ownerUser": "renanaferreira",
  "hasOwnerUser": true,
  "usabilityRating": 0.6875,
  "hasUsabilityRating": true,
  "totalViews": 10,
  "totalVotes": 0,
  "totalDownloads": 2,
  "title": "SNIPS Natural Language Understanding Benchmark:",
  "hasTitle": true,
  "subtitle": "",
  "hasSubtitle": true,
  "description": "# Natural Language Understanding benchmark\n\nThis repository contains the results of three benchmarks that compare natural language understanding services offering:\n1. **built-in intents** (Apple\u2019s SiriKit, Amazon\u2019s Alexa, Microsoft\u2019s Luis,\nGoogle\u2019s API.ai, and [Snips.ai](https://snips.ai/)) on a selection of\nvarious intents. This benchmark was performed in December 2016. Its results\nare described in length in the [following post](https://medium.com/snips-ai/benchmarking-natural-language-understanding-systems-d35be6ce568d).\n2. **custom intent engines** (Google's API.ai, Facebook's Wit, Microsoft's Luis, Amazon's Alexa, and Snips' NLU) for seven chosen intents. This benchmark was performed in June 2017. Its results are described in a [paper](https://arxiv.org/abs/1805.10190) and a [blog post](https://medium.com/@alicecoucke/benchmarking-natural-language-understanding-systems-google-facebook-microsoft-and-snips-2b8ddcf9fb19).\n3. **extension of Braun et al., 2017** (Google's API.AI, Microsoft's Luis, IBM's Watson, Rasa)\nThis experiment replicates the analysis made by Braun et al., 2017, published in Evaluating Natural Language Understanding Services for Conversational Question Answering Systems as part of SIGDIAL 2017 proceedings. Snips and Rasa are added. Details are available in a [paper](https://arxiv.org/abs/1805.10190) and a [blog post](https://medium.com/snips-ai/an-introduction-to-snips-nlu-the-open-source-library-behind-snips-embedded-voice-platform-b12b1a60a41a).\n\nThe data is provided for each benchmark and more details about the methods are available in the README file in each folder.\n\n**Any publication based on these datasets must include a full citation to the following paper in which the results were published by the Snips Team:** \n\n[Coucke A. et al., \"Snips Voice Platform: an embedded Spoken Language Understanding system \nfor private-by-design voice interfaces.\" 2018,](https://arxiv.org/abs/1805.10190)\n\naccepted for a spotlight presentation at the [Privacy in Machine Learning and Artificial Intelligence workshop](https://pimlai.github.io/pimlai18/#papers) colocated with ICML 2018.\n\n\n\n *The Snips team has joined Sonos in November 2019. These open datasets remain available and their access is now managed by the Sonos Voice Experience Team. Please email sve-research@sonos.com with any question.*",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "education"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}