{
  "id": "rhammell/ships-in-satellite-imagery",
  "id_no": 2869,
  "datasetSlugNullable": "ships-in-satellite-imagery",
  "ownerUserNullable": "rhammell",
  "usabilityRatingNullable": 0.9375,
  "titleNullable": "Ships in Satellite Imagery",
  "subtitleNullable": "Classify ships in San Franciso Bay using Planet satellite imagery",
  "descriptionNullable": "# Context\nSatellite imagery provides unique insights into various markets, including agriculture, defense and intelligence, energy, and finance. New commercial imagery providers, such as [Planet](https://www.planet.com/), are using constellations of small satellites to capture images of the entire Earth every day. \n\nThis flood of new imagery is outgrowing the ability for organizations to manually look at each image that gets captured, and there is a need for machine learning and computer vision algorithms to help automate the analysis process. \n\nThe aim of this dataset is to help address the difficult task of detecting the location of large ships in satellite images. Automating this process can be applied to many issues including monitoring port activity levels and supply chain analysis.\n \n# Content\nThe dataset consists of images extracted from Planet satellite imagery collected over the San Francisco Bay and San Pedro Bay areas of California. It includes 4000 80x80 RGB images labeled with either a \"ship\" or \"no-ship\" classification. Images were derived from PlanetScope full-frame visual scene products, which are orthorectified to a 3-meter pixel size. \n\nProvided is a zipped directory `shipsnet.zip` that contains the entire dataset as .png images. Each individual image filename follows a specific format: {label} __ {scene id} __ {longitude} _ {latitude}.png\n\n- **label:** Valued 1 or 0, representing the \"ship\" class and \"no-ship\" class, respectively. \n- **scene id:** The unique identifier of the PlanetScope visual scene the image was extracted from. The scene id can be used with the [Planet API](https://www.planet.com/docs/reference/data-api/) to discover and download the entire scene.\n- **longitude_latitude:** The longitude and latitude coordinates of the image center point, with values separated by a single underscore. \n\nThe dataset is also distributed as a JSON formatted text file `shipsnet.json`. The loaded object contains **data**, **label**, **scene_ids**, and **location** lists. \n\nThe pixel value data for each 80x80 RGB image is stored as a list of 19200 integers within the **data** list. The first 6400 entries contain the red channel values, the next 6400 the green, and the final 6400 the blue. The image is stored in row-major order so that the first 80 entries of the array are the red channel values of the first row of the image.\n\nThe list values at index *i* in **labels**, **scene_ids**, and **locations** each correspond to the *i*-th image in the **data** list.\n\n## Class Labels   \nThe \"ship\" class includes 1000 images. Images in this class are centered on the body of a single ship. Ships of different sizes, orientations, and atmospheric collection conditions are included. Example images from this class are shown below. \n\n![ship](https://i.imgur.com/tLsSoTz.png)\n\nThe \"no-ship\" class includes 3000 images. A third of these are a random sampling of different land cover features - water, vegetation, bare earth, buildings, etc. - that do not include any portion of a ship. The next third are \"partial ships\" that contain only a portion of a ship, but not enough to meet the full definition of the \"ship\" class. The last third are images that have previously been mislabeled by machine learning models, typically caused by bright pixels or strong linear features. Example images from this class are shown below.\n\n![no-ship](https://i.imgur.com/cyG2Z54.png)\n\n# Scenes\nEight full-scene images are included in the `scenes` directory. Scenes can be used to visualize the performance of classification models trained on the dataset. Verify a model's accuracy by applying it across a scene and viewing where 'ship' classifications occur - the context provided by the scene helps determine positive hits from false alarms. An example scene is shown below. \n\n![Scene_1](https://i.imgur.com/FEttq8o.png)\n\n# Acknowledgements\nSatellite imagery used to build this dataset is made available through Planet's [Open California](https://www.planet.com/products/open-california/) dataset, which is [openly licensed](https://creativecommons.org/licenses/by-sa/4.0/). As such, this dataset is also available under the same CC-BY-SA license. Users can sign up for a free Planet account to search, view, and download their imagery and gain access to their API. ",
  "datasetId": 2869,
  "datasetSlug": "ships-in-satellite-imagery",
  "hasDatasetSlug": true,
  "ownerUser": "rhammell",
  "hasOwnerUser": true,
  "usabilityRating": 0.9375,
  "hasUsabilityRating": true,
  "totalViews": 174543,
  "totalVotes": 470,
  "totalDownloads": 20449,
  "title": "Ships in Satellite Imagery",
  "hasTitle": true,
  "subtitle": "Classify ships in San Franciso Bay using Planet satellite imagery",
  "hasSubtitle": true,
  "description": "# Context\nSatellite imagery provides unique insights into various markets, including agriculture, defense and intelligence, energy, and finance. New commercial imagery providers, such as [Planet](https://www.planet.com/), are using constellations of small satellites to capture images of the entire Earth every day. \n\nThis flood of new imagery is outgrowing the ability for organizations to manually look at each image that gets captured, and there is a need for machine learning and computer vision algorithms to help automate the analysis process. \n\nThe aim of this dataset is to help address the difficult task of detecting the location of large ships in satellite images. Automating this process can be applied to many issues including monitoring port activity levels and supply chain analysis.\n \n# Content\nThe dataset consists of images extracted from Planet satellite imagery collected over the San Francisco Bay and San Pedro Bay areas of California. It includes 4000 80x80 RGB images labeled with either a \"ship\" or \"no-ship\" classification. Images were derived from PlanetScope full-frame visual scene products, which are orthorectified to a 3-meter pixel size. \n\nProvided is a zipped directory `shipsnet.zip` that contains the entire dataset as .png images. Each individual image filename follows a specific format: {label} __ {scene id} __ {longitude} _ {latitude}.png\n\n- **label:** Valued 1 or 0, representing the \"ship\" class and \"no-ship\" class, respectively. \n- **scene id:** The unique identifier of the PlanetScope visual scene the image was extracted from. The scene id can be used with the [Planet API](https://www.planet.com/docs/reference/data-api/) to discover and download the entire scene.\n- **longitude_latitude:** The longitude and latitude coordinates of the image center point, with values separated by a single underscore. \n\nThe dataset is also distributed as a JSON formatted text file `shipsnet.json`. The loaded object contains **data**, **label**, **scene_ids**, and **location** lists. \n\nThe pixel value data for each 80x80 RGB image is stored as a list of 19200 integers within the **data** list. The first 6400 entries contain the red channel values, the next 6400 the green, and the final 6400 the blue. The image is stored in row-major order so that the first 80 entries of the array are the red channel values of the first row of the image.\n\nThe list values at index *i* in **labels**, **scene_ids**, and **locations** each correspond to the *i*-th image in the **data** list.\n\n## Class Labels   \nThe \"ship\" class includes 1000 images. Images in this class are centered on the body of a single ship. Ships of different sizes, orientations, and atmospheric collection conditions are included. Example images from this class are shown below. \n\n![ship](https://i.imgur.com/tLsSoTz.png)\n\nThe \"no-ship\" class includes 3000 images. A third of these are a random sampling of different land cover features - water, vegetation, bare earth, buildings, etc. - that do not include any portion of a ship. The next third are \"partial ships\" that contain only a portion of a ship, but not enough to meet the full definition of the \"ship\" class. The last third are images that have previously been mislabeled by machine learning models, typically caused by bright pixels or strong linear features. Example images from this class are shown below.\n\n![no-ship](https://i.imgur.com/cyG2Z54.png)\n\n# Scenes\nEight full-scene images are included in the `scenes` directory. Scenes can be used to visualize the performance of classification models trained on the dataset. Verify a model's accuracy by applying it across a scene and viewing where 'ship' classifications occur - the context provided by the scene helps determine positive hits from false alarms. An example scene is shown below. \n\n![Scene_1](https://i.imgur.com/FEttq8o.png)\n\n# Acknowledgements\nSatellite imagery used to build this dataset is made available through Planet's [Open California](https://www.planet.com/products/open-california/) dataset, which is [openly licensed](https://creativecommons.org/licenses/by-sa/4.0/). As such, this dataset is also available under the same CC-BY-SA license. Users can sign up for a free Planet account to search, view, and download their imagery and gain access to their API. ",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "business",
    "geospatial analysis",
    "computer vision",
    "image",
    "image classification",
    "object detection"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-SA-4.0",
      "name": "CC-BY-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}