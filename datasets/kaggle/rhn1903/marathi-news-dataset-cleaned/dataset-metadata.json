{
  "id": "rhn1903/marathi-news-dataset-cleaned",
  "id_no": 788320,
  "datasetSlugNullable": "marathi-news-dataset-cleaned",
  "ownerUserNullable": "rhn1903",
  "usabilityRatingNullable": 0.5882352941176471,
  "titleNullable": "Marathi News Dataset (cleaned)",
  "subtitleNullable": "Text Classification Dataset for Marathi",
  "descriptionNullable": "### Content\nThis data set contains ~12000 news article headlines which were cleaned from the original dataset ([iNLTK](https://www.kaggle.com/disisbig/marathi-news-dataset)).\n\n- Cleaning Steps : Romanization, Normalization, Removing Duplicates, Trivial Tokenization (Indic-NLP-Library)\n- Mapped Arabic numerals to Devanagari numerals\n- Cleaned out non-Devanagari Text from the headlines\n- Duplicates found in the original dataset are included in errors.csv & errors_cleaned.csv\n\nThe original dataset doesn't have a separate validation split which made it difficult to compare results to the baseline (which reported the validation accuracy). The splits available here are stratifically split using SKlearn.\n\n### Acknowledgements\niNLTK - For the datasets\nIndic-NLP - For the amazing text processing tools",
  "datasetId": 788320,
  "datasetSlug": "marathi-news-dataset-cleaned",
  "hasDatasetSlug": true,
  "ownerUser": "rhn1903",
  "hasOwnerUser": true,
  "usabilityRating": 0.5882352941176471,
  "hasUsabilityRating": true,
  "totalViews": 2294,
  "totalVotes": 4,
  "totalDownloads": 96,
  "title": "Marathi News Dataset (cleaned)",
  "hasTitle": true,
  "subtitle": "Text Classification Dataset for Marathi",
  "hasSubtitle": true,
  "description": "### Content\nThis data set contains ~12000 news article headlines which were cleaned from the original dataset ([iNLTK](https://www.kaggle.com/disisbig/marathi-news-dataset)).\n\n- Cleaning Steps : Romanization, Normalization, Removing Duplicates, Trivial Tokenization (Indic-NLP-Library)\n- Mapped Arabic numerals to Devanagari numerals\n- Cleaned out non-Devanagari Text from the headlines\n- Duplicates found in the original dataset are included in errors.csv & errors_cleaned.csv\n\nThe original dataset doesn't have a separate validation split which made it difficult to compare results to the baseline (which reported the validation accuracy). The splits available here are stratifically split using SKlearn.\n\n### Acknowledgements\niNLTK - For the datasets\nIndic-NLP - For the amazing text processing tools",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "internet",
    "classification",
    "deep learning",
    "news"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-SA-4.0",
      "name": "CC-BY-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}