{
  "id": "sergiosaharovskiy/s3e14-oofs",
  "id_no": 3274330,
  "datasetSlugNullable": "s3e14-oofs",
  "ownerUserNullable": "sergiosaharovskiy",
  "usabilityRatingNullable": 0.9411764705882353,
  "titleNullable": "S3E14 OOFS",
  "subtitleNullable": "The competition winning solutiion oofs",
  "descriptionNullable": "The dataset is consist of 10 submission files and 10 respective out-fold-predictions + 1 file called ffs.\n\nSome of the oofs were not used during the final ensemble but added as acknowledgment of the authors\u2019 work. \n\n\n**ffs.csv** file was obtrained by using the following code:\n```python\nffs = ['fruitset', 'fruitmass', 'id']\n\n# merges train and test and finds final common samples.\nids = train[ffs].merge(test[ffs], on=ffs[:-1], how='inner')['id_y'].unique()\nfinal_samples = test[test.id.isin(ids)].drop_duplicates(subset=ffs[:-1])[ffs[:-1]]\ntrain['pred'] = cop # already blended and corrected oofs up to mae 335.9858.\nd = dict()\n\nVERBOSE = False\n\n# runs for loop to check what re-assigned value gives the bigger improvement \n# for out-of-fold predictions, in the end of the loop it sets values to default.\nfor i in tqdm(final_samples.values):\n    best_mae = 335.9858\n    for yl in sorted(train['yield'].unique()):\n        train.loc[train['fruitset'].eq(i[0]) & train['fruitmass'].eq(i[1]), 'pred'] = yl\n        sc = mae(train[target_name[0]], train['pred'])\n        if sc &lt; best_mae:\n            best_mae = sc\n            d['_'.join(i.astype(str))] = [sc, yl]\n            \n            if VERBOSE and sc &lt; 335.95:\n                print(sc, yl)\n        \n        train['pred'] = cop\n```",
  "datasetId": 3274330,
  "datasetSlug": "s3e14-oofs",
  "hasDatasetSlug": true,
  "ownerUser": "sergiosaharovskiy",
  "hasOwnerUser": true,
  "usabilityRating": 0.9411764705882353,
  "hasUsabilityRating": true,
  "totalViews": 1310,
  "totalVotes": 22,
  "totalDownloads": 243,
  "title": "S3E14 OOFS",
  "hasTitle": true,
  "subtitle": "The competition winning solutiion oofs",
  "hasSubtitle": true,
  "description": "The dataset is consist of 10 submission files and 10 respective out-fold-predictions + 1 file called ffs.\n\nSome of the oofs were not used during the final ensemble but added as acknowledgment of the authors\u2019 work. \n\n\n**ffs.csv** file was obtrained by using the following code:\n```python\nffs = ['fruitset', 'fruitmass', 'id']\n\n# merges train and test and finds final common samples.\nids = train[ffs].merge(test[ffs], on=ffs[:-1], how='inner')['id_y'].unique()\nfinal_samples = test[test.id.isin(ids)].drop_duplicates(subset=ffs[:-1])[ffs[:-1]]\ntrain['pred'] = cop # already blended and corrected oofs up to mae 335.9858.\nd = dict()\n\nVERBOSE = False\n\n# runs for loop to check what re-assigned value gives the bigger improvement \n# for out-of-fold predictions, in the end of the loop it sets values to default.\nfor i in tqdm(final_samples.values):\n    best_mae = 335.9858\n    for yl in sorted(train['yield'].unique()):\n        train.loc[train['fruitset'].eq(i[0]) & train['fruitmass'].eq(i[1]), 'pred'] = yl\n        sc = mae(train[target_name[0]], train['pred'])\n        if sc &lt; best_mae:\n            best_mae = sc\n            d['_'.join(i.astype(str))] = [sc, yl]\n            \n            if VERBOSE and sc &lt; 335.95:\n                print(sc, yl)\n        \n        train['pred'] = cop\n```",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "computer science",
    "programming",
    "tabular",
    "regression",
    "pandas",
    "scipy"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}