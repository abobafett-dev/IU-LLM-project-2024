{
  "id": "sp1thas/book-depository-dataset",
  "id_no": 467291,
  "datasetSlugNullable": "book-depository-dataset",
  "ownerUserNullable": "sp1thas",
  "usabilityRatingNullable": 1.0,
  "titleNullable": "Book Depository Dataset",
  "subtitleNullable": "A large collection of books, scraped from bookdepository.com ",
  "descriptionNullable": "### Context\n\nWhile I was trying to master `scrapy` framework I came up with this project. This is a large collection of books, scraped from bookdepository.com. [sp1thas/book-depository-dataset](https://github.com/sp1thas/book-depository-dataset) repository contains the implementation of this dataset. Feel free to contribute in any way.\n\n\n### Content\n\nThis dataset contains books from [bookdepository.com](https://bookdepository.com), not the actual content of the book but a list of metadata like title, description, dimensions, category, cover image and others. Please find below an extensive list of fields for every sample:\n\n * `authors`: Author(s) (`list of str`)\n * `bestsellers-rank`: Bestsellers ranking (`int`)\n * `categories`: Categories. Check `authors.csv` for mapping (`list of int`)\n * `description`: Description (`str`)\n * `dimension-x`: Dimension X (`float` in cm)\n * `dimension-y`: Dimension Y (`float` in cm)\n * `dimension-z`: Dimension Z (`float` in mm)\n * `edition`: Edition (`str`)\n * `edition-statement`: Edition statement (`str`)\n * `for-ages`: Range of ages (`str`)\n * `format`: Format. Check `formats.csv` for mapping (`int`)\n * `id`: Unique identifier (`int`)\n * `illustrations-note`: \n * `image-checksum`: Cover image checksum\n * `image-path`: Cover image file path\n * `image-url`: Cover image url\n * `imprint`: \n * `index-date`: Crawling date (`date`)\n * `isbn10`: ISBN-10 (`str`)\n * `isbn13`: ISBN-13 (`str`)\n * `lang`: List of book's language(s)\n * `publication-date`: Publication date (`date`)\n * `publication-place`: Publication place (`id`)\n * `rating-avg`: Rating average [0-5] (`float`)\n * `rating-count`: Number of ratings\n * `title`: Book's title (`str`)\n * `url`: Relative url (https://bookdepository.com + `url`)\n * `weight`: Weight (in kgr)\n\n### Acknowledgements\n\nI would like to thank bookdepository and specifically it's [`robots.txt`](https://bookdepository.com/robots.txt)\n\n\n### Inspiration\n\nThis dataset could be used for NLP, Text Classification, Computer Vision and other tasks. Any feedback regarding dataset is more than welcome.\n",
  "datasetId": 467291,
  "datasetSlug": "book-depository-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "sp1thas",
  "hasOwnerUser": true,
  "usabilityRating": 1.0,
  "hasUsabilityRating": true,
  "totalViews": 35163,
  "totalVotes": 53,
  "totalDownloads": 2841,
  "title": "Book Depository Dataset",
  "hasTitle": true,
  "subtitle": "A large collection of books, scraped from bookdepository.com ",
  "hasSubtitle": true,
  "description": "### Context\n\nWhile I was trying to master `scrapy` framework I came up with this project. This is a large collection of books, scraped from bookdepository.com. [sp1thas/book-depository-dataset](https://github.com/sp1thas/book-depository-dataset) repository contains the implementation of this dataset. Feel free to contribute in any way.\n\n\n### Content\n\nThis dataset contains books from [bookdepository.com](https://bookdepository.com), not the actual content of the book but a list of metadata like title, description, dimensions, category, cover image and others. Please find below an extensive list of fields for every sample:\n\n * `authors`: Author(s) (`list of str`)\n * `bestsellers-rank`: Bestsellers ranking (`int`)\n * `categories`: Categories. Check `authors.csv` for mapping (`list of int`)\n * `description`: Description (`str`)\n * `dimension-x`: Dimension X (`float` in cm)\n * `dimension-y`: Dimension Y (`float` in cm)\n * `dimension-z`: Dimension Z (`float` in mm)\n * `edition`: Edition (`str`)\n * `edition-statement`: Edition statement (`str`)\n * `for-ages`: Range of ages (`str`)\n * `format`: Format. Check `formats.csv` for mapping (`int`)\n * `id`: Unique identifier (`int`)\n * `illustrations-note`: \n * `image-checksum`: Cover image checksum\n * `image-path`: Cover image file path\n * `image-url`: Cover image url\n * `imprint`: \n * `index-date`: Crawling date (`date`)\n * `isbn10`: ISBN-10 (`str`)\n * `isbn13`: ISBN-13 (`str`)\n * `lang`: List of book's language(s)\n * `publication-date`: Publication date (`date`)\n * `publication-place`: Publication place (`id`)\n * `rating-avg`: Rating average [0-5] (`float`)\n * `rating-count`: Number of ratings\n * `title`: Book's title (`str`)\n * `url`: Relative url (https://bookdepository.com + `url`)\n * `weight`: Weight (in kgr)\n\n### Acknowledgements\n\nI would like to thank bookdepository and specifically it's [`robots.txt`](https://bookdepository.com/robots.txt)\n\n\n### Inspiration\n\nThis dataset could be used for NLP, Text Classification, Computer Vision and other tasks. Any feedback regarding dataset is more than welcome.\n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "literature",
    "finance",
    "computer science"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}