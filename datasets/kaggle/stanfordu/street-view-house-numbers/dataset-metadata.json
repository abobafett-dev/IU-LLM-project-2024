{
  "id": "/street-view-house-numbers",
  "id_no": 26161,
  "datasetSlugNullable": "street-view-house-numbers",
  "ownerUserNullable": null,
  "usabilityRatingNullable": 0.75,
  "titleNullable": "Street View House Numbers (SVHN)",
  "subtitleNullable": "Over 600k Real-World Images of House Numbers From Google Street View Images",
  "descriptionNullable": "Dataset uploaded by [Jessica Li][1]\n\n----------\n\n\n### Context\n\nObject recognition and image processing has become one of the hottest topics in machine learning due to its vast and creative potential applications in the real world. The ability to process visual information using machine learning algorithms can be very useful, such as [measuring the quality of NYC Bike Lanes through street imagery][2]. Within this field, the Street View House Numbers (SVHN) dataset is one of the most popular ones. It has been used in [neural networks created by Google][3] to read house numbers and match them to their geolocations. This is a great benchmark dataset to play with, learn and train models that accurately identify street numbers, and incorporate into all sorts of projects.\n\n### Content\n\nThis dataset contains three .zip files that contain over 600k labelled real-world images of house numbers taken from Google Street View. The sequence of numbers in the images are of bounded length. \n\n - **test.zip**: 26,032 digits for testing\n - **train.zip**: 73,257 digits for training\n - **extra.zip**: 531,131 additional, somewhat less difficult samples, to use as extra training data\n\n**Additional Notes**\n \n- There are 10 classes, 1 for each digit. Digit '1' has label 1, '9' has label 9 and '0' has label 10.\n- The images are the original, variable-resolution, color house-number images with character level bounding boxes in .png format.\n- **digitStruct.mat**: Contains bounding box information for each respective .zip file are stored as **digitStruct.mat**, which can be loaded using Matlab. The digitStruct.mat files contain a struct called digitStruct with the same length as the number of original images. \n- Each element in digitStruct has the following fields:\n      - **name**: string containing the filename of the corresponding image\n      - **bbox**: struct array that contains the position, size and label of each digit bounding box in the image. Ex. digitStruct(300).bbox(2).height gives height of the 2nd digit bounding box in the 300th image. \n\n### Acknowledgements\nThe SVHN dataset originates from http://ufldl.stanford.edu/housenumbers/. The banner photo was by Annie Spratt on Unsplash.\n\nThe original paper that introduces and examines this data:\n\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.\n\n### Inspiration & Resources\n\n- Given the testing and training data, can you train a model (try Keras and/or TensorFlow) that accurately identifies house numbers in an image (with difficulties like picture brightness, blurriness)?\n- What are some interesting datasets that can be merged with object detection datasets like this to form new applications?\n- Additional resources are [Getting Started with SVHN Dataset][4] and [Ji Yan's project][5] that aims to tackle the SHVN dataset using Convolutional Network in Tensorflow.\n\n\n  [1]: https://www.kaggle.com/jessicali9530\n  [2]: https://medium.com/a-r-g-o/classifying-nyc-bike-lane-quality-with-image-processing-and-computer-vision-in-python-76b13147ec2d\n  [3]: https://www.technologyreview.com/s/523326/how-google-cracked-house-number-identification-in-street-view/\n  [4]: https://agi.io/2018/01/31/getting-started-street-view-house-numbers-svhn-dataset/\n  [5]: https://experimentationground.wordpress.com/2016/09/26/digit-recognition-from-google-street-view-images/",
  "datasetId": 26161,
  "datasetSlug": "street-view-house-numbers",
  "hasDatasetSlug": true,
  "ownerUser": "",
  "hasOwnerUser": false,
  "usabilityRating": 0.75,
  "hasUsabilityRating": true,
  "totalViews": 61605,
  "totalVotes": 106,
  "totalDownloads": 3931,
  "title": "Street View House Numbers (SVHN)",
  "hasTitle": true,
  "subtitle": "Over 600k Real-World Images of House Numbers From Google Street View Images",
  "hasSubtitle": true,
  "description": "Dataset uploaded by [Jessica Li][1]\n\n----------\n\n\n### Context\n\nObject recognition and image processing has become one of the hottest topics in machine learning due to its vast and creative potential applications in the real world. The ability to process visual information using machine learning algorithms can be very useful, such as [measuring the quality of NYC Bike Lanes through street imagery][2]. Within this field, the Street View House Numbers (SVHN) dataset is one of the most popular ones. It has been used in [neural networks created by Google][3] to read house numbers and match them to their geolocations. This is a great benchmark dataset to play with, learn and train models that accurately identify street numbers, and incorporate into all sorts of projects.\n\n### Content\n\nThis dataset contains three .zip files that contain over 600k labelled real-world images of house numbers taken from Google Street View. The sequence of numbers in the images are of bounded length. \n\n - **test.zip**: 26,032 digits for testing\n - **train.zip**: 73,257 digits for training\n - **extra.zip**: 531,131 additional, somewhat less difficult samples, to use as extra training data\n\n**Additional Notes**\n \n- There are 10 classes, 1 for each digit. Digit '1' has label 1, '9' has label 9 and '0' has label 10.\n- The images are the original, variable-resolution, color house-number images with character level bounding boxes in .png format.\n- **digitStruct.mat**: Contains bounding box information for each respective .zip file are stored as **digitStruct.mat**, which can be loaded using Matlab. The digitStruct.mat files contain a struct called digitStruct with the same length as the number of original images. \n- Each element in digitStruct has the following fields:\n      - **name**: string containing the filename of the corresponding image\n      - **bbox**: struct array that contains the position, size and label of each digit bounding box in the image. Ex. digitStruct(300).bbox(2).height gives height of the 2nd digit bounding box in the 300th image. \n\n### Acknowledgements\nThe SVHN dataset originates from http://ufldl.stanford.edu/housenumbers/. The banner photo was by Annie Spratt on Unsplash.\n\nThe original paper that introduces and examines this data:\n\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011.\n\n### Inspiration & Resources\n\n- Given the testing and training data, can you train a model (try Keras and/or TensorFlow) that accurately identifies house numbers in an image (with difficulties like picture brightness, blurriness)?\n- What are some interesting datasets that can be merged with object detection datasets like this to form new applications?\n- Additional resources are [Getting Started with SVHN Dataset][4] and [Ji Yan's project][5] that aims to tackle the SHVN dataset using Convolutional Network in Tensorflow.\n\n\n  [1]: https://www.kaggle.com/jessicali9530\n  [2]: https://medium.com/a-r-g-o/classifying-nyc-bike-lane-quality-with-image-processing-and-computer-vision-in-python-76b13147ec2d\n  [3]: https://www.technologyreview.com/s/523326/how-google-cracked-house-number-identification-in-street-view/\n  [4]: https://agi.io/2018/01/31/getting-started-street-view-house-numbers-svhn-dataset/\n  [5]: https://experimentationground.wordpress.com/2016/09/26/digit-recognition-from-google-street-view-images/",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "computer science",
    "programming",
    "computer vision",
    "classification",
    "image"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}