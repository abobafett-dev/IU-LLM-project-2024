{
  "id": "surekharamireddy/malignant-comment-classification",
  "id_no": 1030945,
  "datasetSlugNullable": "malignant-comment-classification",
  "ownerUserNullable": "surekharamireddy",
  "usabilityRatingNullable": 0.7647058823529411,
  "titleNullable": "Malignant Comment Classification",
  "subtitleNullable": "Classifying Malignant Comment weather it is positive or not ",
  "descriptionNullable": "## Problem Statement\nThe proliferation of social media enables people to express their opinions widely online. However, at the same time, this has resulted in the emergence of conflict and hate, making online environments uninviting for users. Although researchers have found that hate is a problem across multiple platforms, there is a lack of models for online hate detection.\nOnline hate, described as abusive language, aggression, cyberbullying, hatefulness and many others has been identified as a major threat on online social media platforms. Social media platforms are the most prominent grounds for such toxic behavior.   \nThere has been a remarkable increase in the cases of cyberbullying and trolls on various social media platforms. Many celebrities and influences are facing backlashes from people and have to come across hateful and offensive comments. This can take a toll on anyone and affect them mentally leading to depression, mental illness, self-hatred and suicidal thoughts.   \nInternet comments are bastions of hatred and vitriol. While online anonymity has provided a new outlet for aggression and hate speech, machine learning can be used to fight it. The problem we sought to solve was the tagging of internet comments that are aggressive towards other users. This means that insults to third parties such as celebrities will be tagged as un offensive, but \u201cu are an idiot\u201d is clearly offensive.\nOur goal is to build a prototype of online hate and abuse comment classifier which can used to classify hate and offensive comments so that it can be controlled and restricted from spreading hatred and cyberbullying. \n\n\n### Data set Description\nThe data set contains the training set, which has approximately 1,59,000 samples and the test set which contains nearly 1,53,000samples. All the data samples contain 8 fields which includes \u2018Id\u2019, \u2018Comments\u2019, \u2018Malignant\u2019, \u2018Highly malignant\u2019, \u2018Rude\u2019, \u2018Threat\u2019, \u2018Abuse\u2019 and \u2018Loathe\u2019. \nThe label can be either 0 or 1, where 0denotes a NO while 1 denotes a YES. There are various comments which have multiple labels. The first attribute is a unique ID associated with each comment.\nThe data set includes:\n-\tMalignant: It is the Label column, which includes values 0 and 1, denoting if the comment is malignant or not. \n-\tHighly Malignant: It denotes comments that are highly malignant and hurtful.\n-\tRude: It denotes comments that are very rude and offensive.\n-\tThreat: It contains indication of the comments that are giving any threat to someone. \t\n-\tAbuse: It is for comments that are abusive in nature. \n-\tLoathe: It describes the comments which are hateful and loathing in nature.  \n-\tID:It includes unique Ids associated with each comment text given. \n-\tComment text: This column contains the comments extracted from various social media platforms. \n\n\n\n### Acknowledgements\n\nWe wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?",
  "datasetId": 1030945,
  "datasetSlug": "malignant-comment-classification",
  "hasDatasetSlug": true,
  "ownerUser": "surekharamireddy",
  "hasOwnerUser": true,
  "usabilityRating": 0.7647058823529411,
  "hasUsabilityRating": true,
  "totalViews": 15092,
  "totalVotes": 33,
  "totalDownloads": 1511,
  "title": "Malignant Comment Classification",
  "hasTitle": true,
  "subtitle": "Classifying Malignant Comment weather it is positive or not ",
  "hasSubtitle": true,
  "description": "## Problem Statement\nThe proliferation of social media enables people to express their opinions widely online. However, at the same time, this has resulted in the emergence of conflict and hate, making online environments uninviting for users. Although researchers have found that hate is a problem across multiple platforms, there is a lack of models for online hate detection.\nOnline hate, described as abusive language, aggression, cyberbullying, hatefulness and many others has been identified as a major threat on online social media platforms. Social media platforms are the most prominent grounds for such toxic behavior.   \nThere has been a remarkable increase in the cases of cyberbullying and trolls on various social media platforms. Many celebrities and influences are facing backlashes from people and have to come across hateful and offensive comments. This can take a toll on anyone and affect them mentally leading to depression, mental illness, self-hatred and suicidal thoughts.   \nInternet comments are bastions of hatred and vitriol. While online anonymity has provided a new outlet for aggression and hate speech, machine learning can be used to fight it. The problem we sought to solve was the tagging of internet comments that are aggressive towards other users. This means that insults to third parties such as celebrities will be tagged as un offensive, but \u201cu are an idiot\u201d is clearly offensive.\nOur goal is to build a prototype of online hate and abuse comment classifier which can used to classify hate and offensive comments so that it can be controlled and restricted from spreading hatred and cyberbullying. \n\n\n### Data set Description\nThe data set contains the training set, which has approximately 1,59,000 samples and the test set which contains nearly 1,53,000samples. All the data samples contain 8 fields which includes \u2018Id\u2019, \u2018Comments\u2019, \u2018Malignant\u2019, \u2018Highly malignant\u2019, \u2018Rude\u2019, \u2018Threat\u2019, \u2018Abuse\u2019 and \u2018Loathe\u2019. \nThe label can be either 0 or 1, where 0denotes a NO while 1 denotes a YES. There are various comments which have multiple labels. The first attribute is a unique ID associated with each comment.\nThe data set includes:\n-\tMalignant: It is the Label column, which includes values 0 and 1, denoting if the comment is malignant or not. \n-\tHighly Malignant: It denotes comments that are highly malignant and hurtful.\n-\tRude: It denotes comments that are very rude and offensive.\n-\tThreat: It contains indication of the comments that are giving any threat to someone. \t\n-\tAbuse: It is for comments that are abusive in nature. \n-\tLoathe: It describes the comments which are hateful and loathing in nature.  \n-\tID:It includes unique Ids associated with each comment text given. \n-\tComment text: This column contains the comments extracted from various social media platforms. \n\n\n\n### Acknowledgements\n\nWe wouldn't be here without the help of others. If you owe any attributions or thanks, include them here along with any citations of past research.\n\n\n### Inspiration\n\nYour data will be in front of the world's largest data science community. What questions do you want to see answered?",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "health",
    "cancer",
    "online communities",
    "social networks"
  ],
  "licenses": [
    {
      "nameNullable": "copyright-authors",
      "name": "copyright-authors",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}