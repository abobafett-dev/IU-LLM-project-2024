{
  "id": "thedevastator/databricks-chatgpt-dataset",
  "id_no": 4054172,
  "datasetSlugNullable": "databricks-chatgpt-dataset",
  "ownerUserNullable": "thedevastator",
  "usabilityRatingNullable": 1.0,
  "titleNullable": "Databricks Dolly (15K)",
  "subtitleNullable": "Over 15,000 Language Models and Dialogues for Interactive Chat Applications",
  "descriptionNullable": "_____\n# Databricks Dolly (15K)\n### Over 15,000 Language Models and Dialogues for Interactive Chat Applications\nBy Huggingface Hub [[source]](https://huggingface.co/datasets/databricks/databricks-dolly-15k)\n_____\n\n### About this dataset\n&gt; This exceptional dataset, created by Databricks employees, provides 15,000+ language models and dialogues to power dynamic ChatGPT applications. By generating prompt-response pairs from 8 different instruction categories, our goal is to facilitate the use of large language models for interactive dialogue interactions\u2014all while avoiding information taken from any web sources except Wikipedia for particular instruction sets. Use this open-source dataset to explore the boundaries of text-based conversations and uncover new insights about natural language processing!\n\n### More Datasets\n&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).\n\n### Featured Notebooks\n&gt; - \ud83d\udea8 **Your notebook can be here!** \ud83d\udea8! \n\n### How to use the dataset\n&gt; \n&gt; First, let's take a look at the columns in this dataset: Instruction (string), Context (string), Response (string), Category (string). Each record represents a prompt-response pair or conversation between two people. The Instruction and Context fields contain what is said by one individual and the Response holds what is said back by another, culminating in a conversation. These paired entries are then classified into one of 8 different categories based on their content. Knowing this information can help you best utilize the corpus to your desired purposes. \n&gt; \n&gt; For example: if you are training a dialogue system you could develop multiple funneling pipelines using this dataset to enrich your model with real-world conversations or create intelligent chatbot interactions. If you want to generate natural language answers as part of Q&A systems then you could utilize excerpts from Wikipedia for particular subsets of instruction categories as well drawing upon prompt-response pairs within those given instructions all from within the Databricks set. Furthermore, since each record is independently labeled into one of 8 defined categories - such as make reservations or compare products - there are many possibilities for leveraging these classification labels with supervised learning techniques such as multi-class classification neural networks or logistic regression classifiers. \n&gt; \n&gt; In short, this substantial resource offers an array of creative ways to explore different types of dialogue related applications without being limited by needing data from external web sources \u2013 all that\u2019s needed from here is your own imagination!\n\n### Research Ideas\n&gt; - Generating deep learning models to detect and respond to conversational intent. \n&gt; - Training language models to use natural language processing (NLP) for customer service queries. \n&gt; - Creating custom dialogue agents that are better able to handle more complex conversational interactions, such as those powered by machine learning techniques like supervised or unsupervised learning methods\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; [Data Source](https://huggingface.co/datasets/databricks/databricks-dolly-15k)\n&gt; \n&gt;\n\n\n### License\n&gt; \n&gt; \n&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**\n&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).\n\n### Columns\n\n**File: train.csv**\n| Column name     | Description                                                                                                                                         |\n|:----------------|:----------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Instruction** | Text prompt that should generate an appropriate response from a machine learning model/chatbot using natural language processing techniques. (Text) |\n| **Context**     | Provides context to improve accuracy by giving the model more information about what\u2019s happening in a conversation or request execution. (Text)     |\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/databricks/databricks-dolly-15k).\n\n",
  "datasetId": 4054172,
  "datasetSlug": "databricks-chatgpt-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "thedevastator",
  "hasOwnerUser": true,
  "usabilityRating": 1.0,
  "hasUsabilityRating": true,
  "totalViews": 631,
  "totalVotes": 8,
  "totalDownloads": 107,
  "title": "Databricks Dolly (15K)",
  "hasTitle": true,
  "subtitle": "Over 15,000 Language Models and Dialogues for Interactive Chat Applications",
  "hasSubtitle": true,
  "description": "_____\n# Databricks Dolly (15K)\n### Over 15,000 Language Models and Dialogues for Interactive Chat Applications\nBy Huggingface Hub [[source]](https://huggingface.co/datasets/databricks/databricks-dolly-15k)\n_____\n\n### About this dataset\n&gt; This exceptional dataset, created by Databricks employees, provides 15,000+ language models and dialogues to power dynamic ChatGPT applications. By generating prompt-response pairs from 8 different instruction categories, our goal is to facilitate the use of large language models for interactive dialogue interactions\u2014all while avoiding information taken from any web sources except Wikipedia for particular instruction sets. Use this open-source dataset to explore the boundaries of text-based conversations and uncover new insights about natural language processing!\n\n### More Datasets\n&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).\n\n### Featured Notebooks\n&gt; - \ud83d\udea8 **Your notebook can be here!** \ud83d\udea8! \n\n### How to use the dataset\n&gt; \n&gt; First, let's take a look at the columns in this dataset: Instruction (string), Context (string), Response (string), Category (string). Each record represents a prompt-response pair or conversation between two people. The Instruction and Context fields contain what is said by one individual and the Response holds what is said back by another, culminating in a conversation. These paired entries are then classified into one of 8 different categories based on their content. Knowing this information can help you best utilize the corpus to your desired purposes. \n&gt; \n&gt; For example: if you are training a dialogue system you could develop multiple funneling pipelines using this dataset to enrich your model with real-world conversations or create intelligent chatbot interactions. If you want to generate natural language answers as part of Q&A systems then you could utilize excerpts from Wikipedia for particular subsets of instruction categories as well drawing upon prompt-response pairs within those given instructions all from within the Databricks set. Furthermore, since each record is independently labeled into one of 8 defined categories - such as make reservations or compare products - there are many possibilities for leveraging these classification labels with supervised learning techniques such as multi-class classification neural networks or logistic regression classifiers. \n&gt; \n&gt; In short, this substantial resource offers an array of creative ways to explore different types of dialogue related applications without being limited by needing data from external web sources \u2013 all that\u2019s needed from here is your own imagination!\n\n### Research Ideas\n&gt; - Generating deep learning models to detect and respond to conversational intent. \n&gt; - Training language models to use natural language processing (NLP) for customer service queries. \n&gt; - Creating custom dialogue agents that are better able to handle more complex conversational interactions, such as those powered by machine learning techniques like supervised or unsupervised learning methods\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; [Data Source](https://huggingface.co/datasets/databricks/databricks-dolly-15k)\n&gt; \n&gt;\n\n\n### License\n&gt; \n&gt; \n&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**\n&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).\n\n### Columns\n\n**File: train.csv**\n| Column name     | Description                                                                                                                                         |\n|:----------------|:----------------------------------------------------------------------------------------------------------------------------------------------------|\n| **Instruction** | Text prompt that should generate an appropriate response from a machine learning model/chatbot using natural language processing techniques. (Text) |\n| **Context**     | Provides context to improve accuracy by giving the model more information about what\u2019s happening in a conversation or request execution. (Text)     |\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/databricks/databricks-dolly-15k).\n\n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "signal processing",
    "nlp",
    "text mining",
    "data type"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}