{
  "id": "thedevastator/east-african-news-classification",
  "id_no": 2851224,
  "datasetSlugNullable": "east-african-news-classification",
  "ownerUserNullable": "thedevastator",
  "usabilityRatingNullable": 0.9411764705882353,
  "titleNullable": "East African News Classification",
  "subtitleNullable": "Classifying Text Content Across East Africa",
  "descriptionNullable": "_____\n# East African News Classification\n### Classifying Text Content Across East Africa\nBy  [[source]](https://zenodo.org/record/5514203#.Y9Y_R9JBwUE)\n_____\n\n### About this dataset\n> This Swahili News Classification Dataset offers critical insights into media streams across East Africa, allowing for tailored insights related to racial tensions and social shifts. By utilizing the columns of text, label and content, this dataset allows researchers and data scientists to track classified news content from different countries in the region. \n> From political unrest to gender-based violence, this dataset offers a comprehensive portrait of the various news stories from East African nations with practical applications for understanding how culture shapes press reporting and how media outlets portray world events. Alongside direct text information about individual stories, it is important that we study classifications like category and label in order to draw important conclusions about our society; by addressing these research questions with precise categorizations at hand we can ensure alignment between collected data points while also recognizing the unique nuances that characterize each country's media stream. This comprehensive dataset is essential for any project related to understanding communication processes between societies or tracking information flows within an interconnected global system\n\n### More Datasets\n> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).\n\n### Featured Notebooks\n> - \ud83d\udea8 **Your notebook can be here!** \ud83d\udea8! \n\n### How to use the dataset\n> This dataset is perfect for anyone looking to build a machine learning model to classify news content across East Africa. With this dataset, you can create a classifier that can automatically identify and categorize news stories into topics such as politics, economics, health, sports, environment and entertainment. This dataset contains labeled text data for training a model to learn how to classify the content of news articles written in Swahili.\n> \n> #### Step 1: Understand the Dataset \n> The first step towards building your classifier is getting familiar with the dataset provided. The list below outlines each column in the dataset: \n> \n>   - **text**: The text of the news article \n>   - **label**: The category or topic assigned to the article \n>   - **content**: The text content of the news article  \n>   - **category**: The category or topic assigned to the article  \n> \n>  This dataset contains all you need for creating your classification model\u2014 pre-labeled articles with topics assigned by human annotators. Additionally, there are no date values associated with any of these columns listed. All articles have been labeled already so we won\u2019t need those when creating our classifier!   \n> \n>  We also need information about what languages are used in this context\u2013 good thing we\u2019re working on classifying Swahili texts! After understanding more about which language these texts use we can move on towards selecting an appropriate algorithm for our task at hand \u2013 i.e., applying supervised machine learning algorithms that leverage both labeled and unlabeled data sets within this circumstances such as Language Modeling and Text Classification models like Naive Bayes Classifiers (NBCs), Maximum Entropy (MaxEnt) models among other traditional ML Models too but they most probably won\u2019t be up enough robustness & accuracy merely when predicting unseen texts correctly; deep learning techniques often known as multi-layer perceptron (MLPs) may boost out best reporting performance results as desired from expected predictions from our trained/tested set yet since it sounds kinda costly computation complexity wise regarding its many layers involved nature than just classic linear sequence network ones \u2014 something could easily cover most cases am sure\u2013 however this tutorial does not focus precisely upon such topics since its part will take us way beyond current bounds so just keep moving along! ^^    \n> \n>  #### Step 2 Preprocess Text Data  \n> \n>  Once you understand what each column represents we can start preparing our data by preprocessing it so that it is ready to be used by any algorithm chosen\n\n### Research Ideas\n> - Predicting trend topics of news coverage across East Africa by identifying news categories with the highest frequency of occurrences over given time periods.\n> - Identifying and flagging potential bias in news coverage across East Africa by analyzing the prevalence of certain labels or topics to discover potential trends in reporting style. \n> - Developing a predictive model to determine which topic or category will have higher visibility based on the amount of related content that is published in each region around East Africa\n\n### Acknowledgements\n> If you use this dataset in your research, please credit the original authors.\n> [Data Source](https://zenodo.org/record/5514203#.Y9Y_R9JBwUE)\n> \n>\n\n\n### License\n> \n> \n> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**\n> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).\n\n### Columns\n\n**File: train_v0.2.csv**\n| Column name   | Description                                                          |\n|:--------------|:---------------------------------------------------------------------|\n| **text**      | The full article content of each news item. (String)                 |\n| **label**     | Labels that define what subject matter each article covers. (String) |\n\n_____\n\n**File: train.csv**\n| Column name   | Description                                                               |\n|:--------------|:--------------------------------------------------------------------------|\n| **content**   | The full article content of each news item. (Text)                        |\n| **category**  | Labels that define what subject matter each article covers. (Categorical) |\n\n### Acknowledgements\n> If you use this dataset in your research, please credit the original authors.\n> If you use this dataset in your research, please credit [](https://zenodo.org/record/5514203#.Y9Y_R9JBwUE).\n\n",
  "datasetId": 2851224,
  "datasetSlug": "east-african-news-classification",
  "hasDatasetSlug": true,
  "ownerUser": "thedevastator",
  "hasOwnerUser": true,
  "usabilityRating": 0.9411764705882353,
  "hasUsabilityRating": true,
  "totalViews": 1022,
  "totalVotes": 2,
  "totalDownloads": 113,
  "title": "East African News Classification",
  "hasTitle": true,
  "subtitle": "Classifying Text Content Across East Africa",
  "hasSubtitle": true,
  "description": "_____\n# East African News Classification\n### Classifying Text Content Across East Africa\nBy  [[source]](https://zenodo.org/record/5514203#.Y9Y_R9JBwUE)\n_____\n\n### About this dataset\n> This Swahili News Classification Dataset offers critical insights into media streams across East Africa, allowing for tailored insights related to racial tensions and social shifts. By utilizing the columns of text, label and content, this dataset allows researchers and data scientists to track classified news content from different countries in the region. \n> From political unrest to gender-based violence, this dataset offers a comprehensive portrait of the various news stories from East African nations with practical applications for understanding how culture shapes press reporting and how media outlets portray world events. Alongside direct text information about individual stories, it is important that we study classifications like category and label in order to draw important conclusions about our society; by addressing these research questions with precise categorizations at hand we can ensure alignment between collected data points while also recognizing the unique nuances that characterize each country's media stream. This comprehensive dataset is essential for any project related to understanding communication processes between societies or tracking information flows within an interconnected global system\n\n### More Datasets\n> For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).\n\n### Featured Notebooks\n> - \ud83d\udea8 **Your notebook can be here!** \ud83d\udea8! \n\n### How to use the dataset\n> This dataset is perfect for anyone looking to build a machine learning model to classify news content across East Africa. With this dataset, you can create a classifier that can automatically identify and categorize news stories into topics such as politics, economics, health, sports, environment and entertainment. This dataset contains labeled text data for training a model to learn how to classify the content of news articles written in Swahili.\n> \n> #### Step 1: Understand the Dataset \n> The first step towards building your classifier is getting familiar with the dataset provided. The list below outlines each column in the dataset: \n> \n>   - **text**: The text of the news article \n>   - **label**: The category or topic assigned to the article \n>   - **content**: The text content of the news article  \n>   - **category**: The category or topic assigned to the article  \n> \n>  This dataset contains all you need for creating your classification model\u2014 pre-labeled articles with topics assigned by human annotators. Additionally, there are no date values associated with any of these columns listed. All articles have been labeled already so we won\u2019t need those when creating our classifier!   \n> \n>  We also need information about what languages are used in this context\u2013 good thing we\u2019re working on classifying Swahili texts! After understanding more about which language these texts use we can move on towards selecting an appropriate algorithm for our task at hand \u2013 i.e., applying supervised machine learning algorithms that leverage both labeled and unlabeled data sets within this circumstances such as Language Modeling and Text Classification models like Naive Bayes Classifiers (NBCs), Maximum Entropy (MaxEnt) models among other traditional ML Models too but they most probably won\u2019t be up enough robustness & accuracy merely when predicting unseen texts correctly; deep learning techniques often known as multi-layer perceptron (MLPs) may boost out best reporting performance results as desired from expected predictions from our trained/tested set yet since it sounds kinda costly computation complexity wise regarding its many layers involved nature than just classic linear sequence network ones \u2014 something could easily cover most cases am sure\u2013 however this tutorial does not focus precisely upon such topics since its part will take us way beyond current bounds so just keep moving along! ^^    \n> \n>  #### Step 2 Preprocess Text Data  \n> \n>  Once you understand what each column represents we can start preparing our data by preprocessing it so that it is ready to be used by any algorithm chosen\n\n### Research Ideas\n> - Predicting trend topics of news coverage across East Africa by identifying news categories with the highest frequency of occurrences over given time periods.\n> - Identifying and flagging potential bias in news coverage across East Africa by analyzing the prevalence of certain labels or topics to discover potential trends in reporting style. \n> - Developing a predictive model to determine which topic or category will have higher visibility based on the amount of related content that is published in each region around East Africa\n\n### Acknowledgements\n> If you use this dataset in your research, please credit the original authors.\n> [Data Source](https://zenodo.org/record/5514203#.Y9Y_R9JBwUE)\n> \n>\n\n\n### License\n> \n> \n> **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**\n> No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).\n\n### Columns\n\n**File: train_v0.2.csv**\n| Column name   | Description                                                          |\n|:--------------|:---------------------------------------------------------------------|\n| **text**      | The full article content of each news item. (String)                 |\n| **label**     | Labels that define what subject matter each article covers. (String) |\n\n_____\n\n**File: train.csv**\n| Column name   | Description                                                               |\n|:--------------|:--------------------------------------------------------------------------|\n| **content**   | The full article content of each news item. (Text)                        |\n| **category**  | Labels that define what subject matter each article covers. (Categorical) |\n\n### Acknowledgements\n> If you use this dataset in your research, please credit the original authors.\n> If you use this dataset in your research, please credit [](https://zenodo.org/record/5514203#.Y9Y_R9JBwUE).\n\n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "computer science",
    "data cleaning",
    "nlp",
    "news"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}