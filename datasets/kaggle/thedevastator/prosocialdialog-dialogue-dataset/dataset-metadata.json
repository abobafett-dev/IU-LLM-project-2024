{
  "id": "thedevastator/prosocialdialog-dialogue-dataset",
  "id_no": 4068963,
  "datasetSlugNullable": "prosocialdialog-dialogue-dataset",
  "ownerUserNullable": "thedevastator",
  "usabilityRatingNullable": 1.0,
  "titleNullable": "ProsocialDialog - Problematic Content Dialogue",
  "subtitleNullable": "Teach conversation agents to respond to problematic topics",
  "descriptionNullable": "_____\n# ProsocialDialog - Problematic Content Dialogue Dataset\n### Teach conversation agents to respond to problematic topics\nBy Huggingface Hub [[source]](https://huggingface.co/datasets/allenai/prosocial-dialog)\n_____\n\n### About this dataset\n&gt; ProsocialDialog is the first large-scale multi-turn English dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists of 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue safety labels accompanied by free-form rationales.\n\n### More Datasets\n&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).\n\n### Featured Notebooks\n&gt; - \ud83d\udea8 **Your notebook can be here!** \ud83d\udea8! \n\n### How to use the dataset\n&gt; \n&gt; This guide will explain how to use the data in this dataset for teaching conversational agents normative responses to problematic content. \n&gt; \n&gt; - Understand the columns: Familiarizing yourself with the columns provided in this dataset is important so you know what types of information are available for your analysis. The following columns are included in this dataset: 'context','response','rots','safety_label', 'safety_annotations','safety_annotation_reasons', 'source', and 'etc'. Each column contains different information about dialogue conversations including the context, response, rules of thumb (RoTs), safety label, annotations, rationale and sources used for conversations. \n&gt;     \n&gt; - Explore Safety Labels : Exploring through each safety label will allow you understand what type of conversation is deemed appropriate or inappropriate by its corresponding label in the \u2018safety_label\u2019 column . In addition to exploring these labels it can also be helpful to explore through its respective \u2018safety annotations\u2019 as well as their associated \u2018free-form rationales\u2019 which allows sees where certain decisions were made within these conversations when giving ratings towards them . \n&gt; \n&gt; - Learn from Rules of Thumb (ROTs): Examining both individually listed ROTs and actuall dialogues that have been culturally deemed as acceptable or unacceptable can help you better understand what actions ought to be taken when providing a normative response towards any type of problematic content one may encounter within their own conversation settings .\n&gt; \n&gt; - Analyze Sources : Analyzing sources plays an important role since they give insight into where they obtained any given data from , whether they are first party interviews or third party websites, analyzing sources gives us insight into why that particular piece was labeled a certain way while others may have been given higher/lower ratings depending on such factors like trustworthiness among other things which should be kept into consideration when using this source for training models .   \n&gt; \n&gt; 5 Taking Action: After familiarizing yourself with all these various components , try mapping out scenarios between two people engaging in conversation and write directions based on each ROT applicable provide scenarios demonstrating socially acceptable behavior when confronted with nonnormative behavior throughout conversations using networks like self reinforcing looping can produce\n\n### Research Ideas\n&gt; - Designing Conversational Agents: This dataset can be used to build natural language processing (NLP) models that can recognize and classify problematic content. The safety labels, rationales, and RoTs can be leveraged to teach conversational agents how to respond to such content in a socially acceptable manner.  \n&gt; - Benchmark Systems: ProsocialDialog could be used as a benchmark system for assessing the performance of existing conversation datasets in terms of recognizing, responding to, and helping prevent problematic content interactions. \n&gt; - Automated Moderation: The dialogue safety labels and associated free-form rationales found in the dataset can be leveraged by technology platforms for automated moderation tasks such as flagging or banning offensive messages or involved users when needed\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; [Data Source](https://huggingface.co/datasets/allenai/prosocial-dialog)\n&gt; \n&gt;\n\n\n### License\n&gt; \n&gt; \n&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**\n&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).\n\n### Columns\n\n**File: validation.csv**\n| Column name                   | Description                                                           |\n|:------------------------------|:----------------------------------------------------------------------|\n| **context**                   | The context of the conversation. (String)                             |\n| **response**                  | The response to the conversation. (String)                            |\n| **rots**                      | Rules of thumb associated with the conversation. (String)             |\n| **safety_label**              | The safety label associated with the conversation. (String)           |\n| **safety_annotations**        | Annotations associated with the conversation. (String)                |\n| **safety_annotation_reasons** | Reasons for the safety annotations. (String)                          |\n| **source**                    | The source of the conversation. (String)                              |\n| **etc**                       | Any additional information associated with the conversation. (String) |\n| **episode_done**              | Whether the conversation is complete or not. (Boolean)                |\n\n_____\n\n**File: train.csv**\n| Column name                   | Description                                                           |\n|:------------------------------|:----------------------------------------------------------------------|\n| **context**                   | The context of the conversation. (String)                             |\n| **response**                  | The response to the conversation. (String)                            |\n| **rots**                      | Rules of thumb associated with the conversation. (String)             |\n| **safety_label**              | The safety label associated with the conversation. (String)           |\n| **safety_annotations**        | Annotations associated with the conversation. (String)                |\n| **safety_annotation_reasons** | Reasons for the safety annotations. (String)                          |\n| **source**                    | The source of the conversation. (String)                              |\n| **etc**                       | Any additional information associated with the conversation. (String) |\n| **episode_done**              | Whether the conversation is complete or not. (Boolean)                |\n\n_____\n\n**File: test.csv**\n| Column name                   | Description                                                           |\n|:------------------------------|:----------------------------------------------------------------------|\n| **context**                   | The context of the conversation. (String)                             |\n| **response**                  | The response to the conversation. (String)                            |\n| **rots**                      | Rules of thumb associated with the conversation. (String)             |\n| **safety_label**              | The safety label associated with the conversation. (String)           |\n| **safety_annotations**        | Annotations associated with the conversation. (String)                |\n| **safety_annotation_reasons** | Reasons for the safety annotations. (String)                          |\n| **source**                    | The source of the conversation. (String)                              |\n| **etc**                       | Any additional information associated with the conversation. (String) |\n| **episode_done**              | Whether the conversation is complete or not. (Boolean)                |\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/allenai/prosocial-dialog).\n\n",
  "datasetId": 4068963,
  "datasetSlug": "prosocialdialog-dialogue-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "thedevastator",
  "hasOwnerUser": true,
  "usabilityRating": 1.0,
  "hasUsabilityRating": true,
  "totalViews": 1294,
  "totalVotes": 16,
  "totalDownloads": 154,
  "title": "ProsocialDialog - Problematic Content Dialogue",
  "hasTitle": true,
  "subtitle": "Teach conversation agents to respond to problematic topics",
  "hasSubtitle": true,
  "description": "_____\n# ProsocialDialog - Problematic Content Dialogue Dataset\n### Teach conversation agents to respond to problematic topics\nBy Huggingface Hub [[source]](https://huggingface.co/datasets/allenai/prosocial-dialog)\n_____\n\n### About this dataset\n&gt; ProsocialDialog is the first large-scale multi-turn English dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists of 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue safety labels accompanied by free-form rationales.\n\n### More Datasets\n&gt; For more datasets, click [here](https://www.kaggle.com/thedevastator/datasets).\n\n### Featured Notebooks\n&gt; - \ud83d\udea8 **Your notebook can be here!** \ud83d\udea8! \n\n### How to use the dataset\n&gt; \n&gt; This guide will explain how to use the data in this dataset for teaching conversational agents normative responses to problematic content. \n&gt; \n&gt; - Understand the columns: Familiarizing yourself with the columns provided in this dataset is important so you know what types of information are available for your analysis. The following columns are included in this dataset: 'context','response','rots','safety_label', 'safety_annotations','safety_annotation_reasons', 'source', and 'etc'. Each column contains different information about dialogue conversations including the context, response, rules of thumb (RoTs), safety label, annotations, rationale and sources used for conversations. \n&gt;     \n&gt; - Explore Safety Labels : Exploring through each safety label will allow you understand what type of conversation is deemed appropriate or inappropriate by its corresponding label in the \u2018safety_label\u2019 column . In addition to exploring these labels it can also be helpful to explore through its respective \u2018safety annotations\u2019 as well as their associated \u2018free-form rationales\u2019 which allows sees where certain decisions were made within these conversations when giving ratings towards them . \n&gt; \n&gt; - Learn from Rules of Thumb (ROTs): Examining both individually listed ROTs and actuall dialogues that have been culturally deemed as acceptable or unacceptable can help you better understand what actions ought to be taken when providing a normative response towards any type of problematic content one may encounter within their own conversation settings .\n&gt; \n&gt; - Analyze Sources : Analyzing sources plays an important role since they give insight into where they obtained any given data from , whether they are first party interviews or third party websites, analyzing sources gives us insight into why that particular piece was labeled a certain way while others may have been given higher/lower ratings depending on such factors like trustworthiness among other things which should be kept into consideration when using this source for training models .   \n&gt; \n&gt; 5 Taking Action: After familiarizing yourself with all these various components , try mapping out scenarios between two people engaging in conversation and write directions based on each ROT applicable provide scenarios demonstrating socially acceptable behavior when confronted with nonnormative behavior throughout conversations using networks like self reinforcing looping can produce\n\n### Research Ideas\n&gt; - Designing Conversational Agents: This dataset can be used to build natural language processing (NLP) models that can recognize and classify problematic content. The safety labels, rationales, and RoTs can be leveraged to teach conversational agents how to respond to such content in a socially acceptable manner.  \n&gt; - Benchmark Systems: ProsocialDialog could be used as a benchmark system for assessing the performance of existing conversation datasets in terms of recognizing, responding to, and helping prevent problematic content interactions. \n&gt; - Automated Moderation: The dialogue safety labels and associated free-form rationales found in the dataset can be leveraged by technology platforms for automated moderation tasks such as flagging or banning offensive messages or involved users when needed\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; [Data Source](https://huggingface.co/datasets/allenai/prosocial-dialog)\n&gt; \n&gt;\n\n\n### License\n&gt; \n&gt; \n&gt; **License: [CC0 1.0 Universal (CC0 1.0) - Public Domain Dedication](https://creativecommons.org/publicdomain/zero/1.0/)**\n&gt; No Copyright - You can copy, modify, distribute and perform the work, even for commercial purposes, all without asking permission. [See Other Information](https://creativecommons.org/publicdomain/zero/1.0/).\n\n### Columns\n\n**File: validation.csv**\n| Column name                   | Description                                                           |\n|:------------------------------|:----------------------------------------------------------------------|\n| **context**                   | The context of the conversation. (String)                             |\n| **response**                  | The response to the conversation. (String)                            |\n| **rots**                      | Rules of thumb associated with the conversation. (String)             |\n| **safety_label**              | The safety label associated with the conversation. (String)           |\n| **safety_annotations**        | Annotations associated with the conversation. (String)                |\n| **safety_annotation_reasons** | Reasons for the safety annotations. (String)                          |\n| **source**                    | The source of the conversation. (String)                              |\n| **etc**                       | Any additional information associated with the conversation. (String) |\n| **episode_done**              | Whether the conversation is complete or not. (Boolean)                |\n\n_____\n\n**File: train.csv**\n| Column name                   | Description                                                           |\n|:------------------------------|:----------------------------------------------------------------------|\n| **context**                   | The context of the conversation. (String)                             |\n| **response**                  | The response to the conversation. (String)                            |\n| **rots**                      | Rules of thumb associated with the conversation. (String)             |\n| **safety_label**              | The safety label associated with the conversation. (String)           |\n| **safety_annotations**        | Annotations associated with the conversation. (String)                |\n| **safety_annotation_reasons** | Reasons for the safety annotations. (String)                          |\n| **source**                    | The source of the conversation. (String)                              |\n| **etc**                       | Any additional information associated with the conversation. (String) |\n| **episode_done**              | Whether the conversation is complete or not. (Boolean)                |\n\n_____\n\n**File: test.csv**\n| Column name                   | Description                                                           |\n|:------------------------------|:----------------------------------------------------------------------|\n| **context**                   | The context of the conversation. (String)                             |\n| **response**                  | The response to the conversation. (String)                            |\n| **rots**                      | Rules of thumb associated with the conversation. (String)             |\n| **safety_label**              | The safety label associated with the conversation. (String)           |\n| **safety_annotations**        | Annotations associated with the conversation. (String)                |\n| **safety_annotation_reasons** | Reasons for the safety annotations. (String)                          |\n| **source**                    | The source of the conversation. (String)                              |\n| **etc**                       | Any additional information associated with the conversation. (String) |\n| **episode_done**              | Whether the conversation is complete or not. (Boolean)                |\n\n### Acknowledgements\n&gt; If you use this dataset in your research, please credit the original authors.\n&gt; If you use this dataset in your research, please credit [Huggingface Hub](https://huggingface.co/datasets/allenai/prosocial-dialog).\n\n",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "mental health",
    "people and society",
    "education",
    "psychology",
    "nlp",
    "social networks"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}