{
  "id": "/customer-support-on-twitter",
  "id_no": 4133,
  "datasetSlugNullable": "customer-support-on-twitter",
  "ownerUserNullable": null,
  "usabilityRatingNullable": 0.9117647058823529,
  "titleNullable": "Customer Support on Twitter",
  "subtitleNullable": "Over 3 million tweets and replies from the biggest brands on Twitter",
  "descriptionNullable": "The Customer Support on Twitter dataset is a large, modern corpus of tweets and replies to aid innovation in natural language understanding and conversational models, and for study of modern customer support practices and impact.\n\n![Example Analysis - Inbound Volume for the Top 20 Brands](https://i.imgur.com/nTv3Iuu.png)\n\n### Context\nNatural language remains the densest encoding of human experience we have, and innovation in NLP has accelerated to power understanding of that data, but the datasets driving this innovation don't match the real language in use today.  The Customer Support on Twitter dataset offers a large corpus of modern English (mostly) conversations between consumers and customer support agents on Twitter, and has three important advantages over other conversational text datasets:\n\n- **Focused** - Consumers contact customer support to have a specific problem solved, and the manifold of problems to be discussed is relatively small, especially compared to unconstrained conversational datasets like the reddit Corpus.\n- **Natural** - Consumers in this dataset come from a much broader segment than those in the Ubuntu Dialogue Corpus and have much more natural and recent use of typed text than the Cornell Movie Dialogs Corpus.\n- **Succinct** - Twitter's brevity causes more natural responses from support agents (rather than scripted), and to-the-point descriptions of problems and solutions.  Also, its convenient in allowing for a relatively low message limit size for recurrent nets.\n\n### Inspiration\nThe size and breadth of this dataset inspires many interesting questions:\n\n- Can we predict company responses? Given the bounded set of subjects handled by each company, the answer seems like yes!\n- Do requests get stale?  How quickly do the best companies respond, compared to the worst?\n- Can we learn high quality dense embeddings or representations of similarity for topical clustering?\n- How does tone affect the customer support conversation?  Does saying sorry help?\n- Can we help companies identify new problems, or ones most affecting their customers?\n\n### Acknowledgements\n\nDataset built with [PointScrape](https://www.thoughtvector.io/pointscrape/).\n\n### Content\nThe dataset is a CSV, where each row is a tweet.  The different columns are described below.  Every conversation included has at least one request from a consumer and at least one response from a company.  Which user IDs are company user IDs can be calculated using the `inbound` field.\n\n#### `tweet_id`\nA unique, anonymized ID for the Tweet.  Referenced by `response_tweet_id` and `in_response_to_tweet_id`.\n\n#### `author_id`\nA unique, anonymized user ID.  @s in the dataset have been replaced with their associated anonymized user ID.\n\n#### `inbound`\nWhether the tweet is \"inbound\" to a company doing customer support on Twitter.  This feature is useful when re-organizing data for training conversational models.\n\n#### `created_at`\nDate and time when the tweet was sent.\n\n#### `text`\nTweet content.  Sensitive information like phone numbers and email addresses are replaced with mask values like `__email__`.\n\n#### `response_tweet_id`\nIDs of tweets that are responses to this tweet, comma-separated.\n\n#### `in_response_to_tweet_id`\nID of the tweet this tweet is in response to, if any.\n\n### Contributing\n\nKnow of other brands the dataset should include?  Found something that needs to be fixed?  Start a discussion, or email me directly at `$FIRSTNAME`@`$LASTNAME`.com!\n\n### Acknowledgements\nA huge thank you to my friends who helped bootstrap the list of companies that  do customer support on Twitter!  There are many rocks that would have been left un-turned were it not for your suggestions!\n\n### Relevant Resources\n\n- NLTK - [casual_tokenize for social media text tokenizing](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.casual.casual_tokenize), [vader sentiment analysis for social media text](http://www.nltk.org/howto/sentiment.html)\n- SciKit Learn - [BoW Count Vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), [Multinomial Naive Bayes Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n- [Topic Modeling via Phrase detection with gensim](https://www.thoughtvector.io/blog/topic-modeling-for-humans-with-phrase-detection/)\n- [facebook research - fastText text classifier](https://github.com/facebookresearch/fastText)\n\n### Licensing\n\nFor commercial applications and use of full dataset, please contact [stuart@thoughtvector.io](mailto:stuart@thoughtvector.io).",
  "datasetId": 4133,
  "datasetSlug": "customer-support-on-twitter",
  "hasDatasetSlug": true,
  "ownerUser": "",
  "hasOwnerUser": false,
  "usabilityRating": 0.9117647058823529,
  "hasUsabilityRating": true,
  "totalViews": 245122,
  "totalVotes": 477,
  "totalDownloads": 32467,
  "title": "Customer Support on Twitter",
  "hasTitle": true,
  "subtitle": "Over 3 million tweets and replies from the biggest brands on Twitter",
  "hasSubtitle": true,
  "description": "The Customer Support on Twitter dataset is a large, modern corpus of tweets and replies to aid innovation in natural language understanding and conversational models, and for study of modern customer support practices and impact.\n\n![Example Analysis - Inbound Volume for the Top 20 Brands](https://i.imgur.com/nTv3Iuu.png)\n\n### Context\nNatural language remains the densest encoding of human experience we have, and innovation in NLP has accelerated to power understanding of that data, but the datasets driving this innovation don't match the real language in use today.  The Customer Support on Twitter dataset offers a large corpus of modern English (mostly) conversations between consumers and customer support agents on Twitter, and has three important advantages over other conversational text datasets:\n\n- **Focused** - Consumers contact customer support to have a specific problem solved, and the manifold of problems to be discussed is relatively small, especially compared to unconstrained conversational datasets like the reddit Corpus.\n- **Natural** - Consumers in this dataset come from a much broader segment than those in the Ubuntu Dialogue Corpus and have much more natural and recent use of typed text than the Cornell Movie Dialogs Corpus.\n- **Succinct** - Twitter's brevity causes more natural responses from support agents (rather than scripted), and to-the-point descriptions of problems and solutions.  Also, its convenient in allowing for a relatively low message limit size for recurrent nets.\n\n### Inspiration\nThe size and breadth of this dataset inspires many interesting questions:\n\n- Can we predict company responses? Given the bounded set of subjects handled by each company, the answer seems like yes!\n- Do requests get stale?  How quickly do the best companies respond, compared to the worst?\n- Can we learn high quality dense embeddings or representations of similarity for topical clustering?\n- How does tone affect the customer support conversation?  Does saying sorry help?\n- Can we help companies identify new problems, or ones most affecting their customers?\n\n### Acknowledgements\n\nDataset built with [PointScrape](https://www.thoughtvector.io/pointscrape/).\n\n### Content\nThe dataset is a CSV, where each row is a tweet.  The different columns are described below.  Every conversation included has at least one request from a consumer and at least one response from a company.  Which user IDs are company user IDs can be calculated using the `inbound` field.\n\n#### `tweet_id`\nA unique, anonymized ID for the Tweet.  Referenced by `response_tweet_id` and `in_response_to_tweet_id`.\n\n#### `author_id`\nA unique, anonymized user ID.  @s in the dataset have been replaced with their associated anonymized user ID.\n\n#### `inbound`\nWhether the tweet is \"inbound\" to a company doing customer support on Twitter.  This feature is useful when re-organizing data for training conversational models.\n\n#### `created_at`\nDate and time when the tweet was sent.\n\n#### `text`\nTweet content.  Sensitive information like phone numbers and email addresses are replaced with mask values like `__email__`.\n\n#### `response_tweet_id`\nIDs of tweets that are responses to this tweet, comma-separated.\n\n#### `in_response_to_tweet_id`\nID of the tweet this tweet is in response to, if any.\n\n### Contributing\n\nKnow of other brands the dataset should include?  Found something that needs to be fixed?  Start a discussion, or email me directly at `$FIRSTNAME`@`$LASTNAME`.com!\n\n### Acknowledgements\nA huge thank you to my friends who helped bootstrap the list of companies that  do customer support on Twitter!  There are many rocks that would have been left un-turned were it not for your suggestions!\n\n### Relevant Resources\n\n- NLTK - [casual_tokenize for social media text tokenizing](http://www.nltk.org/api/nltk.tokenize.html#nltk.tokenize.casual.casual_tokenize), [vader sentiment analysis for social media text](http://www.nltk.org/howto/sentiment.html)\n- SciKit Learn - [BoW Count Vectorizer](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.CountVectorizer.html), [Multinomial Naive Bayes Classifier](http://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html)\n- [Topic Modeling via Phrase detection with gensim](https://www.thoughtvector.io/blog/topic-modeling-for-humans-with-phrase-detection/)\n- [facebook research - fastText text classifier](https://github.com/facebookresearch/fastText)\n\n### Licensing\n\nFor commercial applications and use of full dataset, please contact [stuart@thoughtvector.io](mailto:stuart@thoughtvector.io).",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "business",
    "social science",
    "linguistics",
    "computer science",
    "online communities",
    "social networks"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [
    {
      "username": "soaxelbrooke",
      "role": "writer"
    }
  ],
  "data": []
}