{
  "id": "torarnenordmo/njord-fishing-trawler-surveillance-videos",
  "id_no": 2809617,
  "datasetSlugNullable": "njord-fishing-trawler-surveillance-videos",
  "ownerUserNullable": "torarnenordmo",
  "usabilityRatingNullable": 0.75,
  "titleNullable": "Njord: Fishing Trawler Surveillance Videos",
  "subtitleNullable": "Insight into commercial fishing",
  "descriptionNullable": "The Njord dataset is described in the \"Njord: A Fishing Trawler Dataset\" paper in MMSys '22. Please cite as: \nNordmo, Tor-Arne Schmidt, Ovesen, Aril Bernhard, Juliussen, Bj\u00f8rn Aslak, Hicks, Steven, Thambawita, Vajira, Johansen, H\u00e5vard Dagenborg, Halvorsen, P\u00e5l, Riegler, Michael Alexander, & Johansen, Dag. (2022). Njord: A Fishing Trawler Dataset (1.0) [Data set]. ACM Multimedia Systems Conference (MMSys), Athlone, Ireland. \n\nThe dataset Njord contains surveillance videos from the Hermes fishing trawler that were live-streamed online in 2019 as Slow TV entertainment. The videos are from a trip from the western shores of Greenland to Norway, documenting their fishing journey. There were a total of 29 videos that are, on average, 1 hour in duration. These were downloaded from YouTube using the youtube-dl CLI tool. They were then split up into 10 minute segments to be easier to deal with both in the labeling and the benchmarking process. At the time of submission we have annotated a subset of these. This results in a dataset with 71 videos that have been annotated so far, and 127 videos which are not annotated. With 71 annotated videos, each with a frame rate of 25 fps and a duration of approximately 10-minutes, results in approximately 1,065,000 frames with annotations. The videos have a resolution 1,280x720 and run at 25 frames per second. The videos have varying lighting conditions with complex, moving backgrounds, due to the trawler being at sea. The videos consist of eight different fixed-camera scenes plus a view with a manually-operated camera for showing particularly interesting events, such as whale observations and other boats. The cameras are changed between on a fixed schedule, but can also be manually changed by the captain. This sometimes result in scenes having varying durations. There are overlays that sometimes appear on screen. These show general information about what is being caught, about the vessel in general, and statistics related to catch. They also sometimes show a map overlay with the current location of the trawler along with speed and orientation of it.\n\nFor each video we have labelled bounding boxes around people, other boats, nets, and fish. The temporal annotations consist of when scene changes occur, when overlays are turned on and off, when Events of Interest (EoI) occur, and when the intro plays. We also have labels that denote whether it is daytime or nighttime, and, due to the videos being from a live-stream, labels for parts of the videos that are before the introduction and after the end of the relevant live-stream. The bounding boxes for fish label groups of fish, due to the scenes on deck showing fish being far away from the camera. The bounding boxes for the nets both label nets in use and those lying in heaps on deck.\n\nThe labels were manually created using Labelbox. Labelbox is a platform for annotating datasets. It had a simple interface that allowed us to label bounding boxes and temporal annotations. For the bounding boxes it linearly interpolates between keyframes, allowing for faster annotating. The dataset is anticipated as continuously growing and expanding (in terms of annotations, but also amount of data), and currently it contains 71 fully annotated videos and 127 videos without annotations. The not annotated video can also be useful for unsupervised or self supervised learning experiments.",
  "datasetId": 2809617,
  "datasetSlug": "njord-fishing-trawler-surveillance-videos",
  "hasDatasetSlug": true,
  "ownerUser": "torarnenordmo",
  "hasOwnerUser": true,
  "usabilityRating": 0.75,
  "hasUsabilityRating": true,
  "totalViews": 406,
  "totalVotes": 0,
  "totalDownloads": 29,
  "title": "Njord: Fishing Trawler Surveillance Videos",
  "hasTitle": true,
  "subtitle": "Insight into commercial fishing",
  "hasSubtitle": true,
  "description": "The Njord dataset is described in the \"Njord: A Fishing Trawler Dataset\" paper in MMSys '22. Please cite as: \nNordmo, Tor-Arne Schmidt, Ovesen, Aril Bernhard, Juliussen, Bj\u00f8rn Aslak, Hicks, Steven, Thambawita, Vajira, Johansen, H\u00e5vard Dagenborg, Halvorsen, P\u00e5l, Riegler, Michael Alexander, & Johansen, Dag. (2022). Njord: A Fishing Trawler Dataset (1.0) [Data set]. ACM Multimedia Systems Conference (MMSys), Athlone, Ireland. \n\nThe dataset Njord contains surveillance videos from the Hermes fishing trawler that were live-streamed online in 2019 as Slow TV entertainment. The videos are from a trip from the western shores of Greenland to Norway, documenting their fishing journey. There were a total of 29 videos that are, on average, 1 hour in duration. These were downloaded from YouTube using the youtube-dl CLI tool. They were then split up into 10 minute segments to be easier to deal with both in the labeling and the benchmarking process. At the time of submission we have annotated a subset of these. This results in a dataset with 71 videos that have been annotated so far, and 127 videos which are not annotated. With 71 annotated videos, each with a frame rate of 25 fps and a duration of approximately 10-minutes, results in approximately 1,065,000 frames with annotations. The videos have a resolution 1,280x720 and run at 25 frames per second. The videos have varying lighting conditions with complex, moving backgrounds, due to the trawler being at sea. The videos consist of eight different fixed-camera scenes plus a view with a manually-operated camera for showing particularly interesting events, such as whale observations and other boats. The cameras are changed between on a fixed schedule, but can also be manually changed by the captain. This sometimes result in scenes having varying durations. There are overlays that sometimes appear on screen. These show general information about what is being caught, about the vessel in general, and statistics related to catch. They also sometimes show a map overlay with the current location of the trawler along with speed and orientation of it.\n\nFor each video we have labelled bounding boxes around people, other boats, nets, and fish. The temporal annotations consist of when scene changes occur, when overlays are turned on and off, when Events of Interest (EoI) occur, and when the intro plays. We also have labels that denote whether it is daytime or nighttime, and, due to the videos being from a live-stream, labels for parts of the videos that are before the introduction and after the end of the relevant live-stream. The bounding boxes for fish label groups of fish, due to the scenes on deck showing fish being far away from the camera. The bounding boxes for the nets both label nets in use and those lying in heaps on deck.\n\nThe labels were manually created using Labelbox. Labelbox is a platform for annotating datasets. It had a simple interface that allowed us to label bounding boxes and temporal annotations. For the bounding boxes it linearly interpolates between keyframes, allowing for faster annotating. The dataset is anticipated as continuously growing and expanding (in terms of annotations, but also amount of data), and currently it contains 71 fully annotated videos and 127 videos without annotations. The not annotated video can also be useful for unsupervised or self supervised learning experiments.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "video",
    "fish and aquaria",
    "object detection"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}