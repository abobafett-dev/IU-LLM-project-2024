{
  "id": "umbertogriffo/googles-trained-word2vec-model-in-python",
  "id_no": 12162,
  "datasetSlugNullable": "googles-trained-word2vec-model-in-python",
  "ownerUserNullable": "umbertogriffo",
  "usabilityRatingNullable": 0.6875,
  "titleNullable": "Google's trained Word2Vec model in Python",
  "subtitleNullable": "It includes word vectors for a vocabulary of 3 million words and phrases.",
  "descriptionNullable": "### Context\n\nGoogle\u2019s Word2Vec pre-trained [model][1].\n\n### Content\n\nIt\u2019s 1.5GB! It includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 features.\n\n  [1]: http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/",
  "datasetId": 12162,
  "datasetSlug": "googles-trained-word2vec-model-in-python",
  "hasDatasetSlug": true,
  "ownerUser": "umbertogriffo",
  "hasOwnerUser": true,
  "usabilityRating": 0.6875,
  "hasUsabilityRating": true,
  "totalViews": 30529,
  "totalVotes": 45,
  "totalDownloads": 3070,
  "title": "Google's trained Word2Vec model in Python",
  "hasTitle": true,
  "subtitle": "It includes word vectors for a vocabulary of 3 million words and phrases.",
  "hasSubtitle": true,
  "description": "### Context\n\nGoogle\u2019s Word2Vec pre-trained [model][1].\n\n### Content\n\nIt\u2019s 1.5GB! It includes word vectors for a vocabulary of 3 million words and phrases that they trained on roughly 100 billion words from a Google News dataset. The vector length is 300 features.\n\n  [1]: http://mccormickml.com/2016/04/12/googles-pretrained-word2vec-model-in-python/",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "computer science",
    "programming"
  ],
  "licenses": [
    {
      "nameNullable": "copyright-authors",
      "name": "copyright-authors",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}