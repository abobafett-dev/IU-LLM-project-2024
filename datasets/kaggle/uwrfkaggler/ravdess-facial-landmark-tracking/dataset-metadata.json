{
  "id": "uwrfkaggler/ravdess-facial-landmark-tracking",
  "id_no": 342705,
  "datasetSlugNullable": "ravdess-facial-landmark-tracking",
  "ownerUserNullable": "uwrfkaggler",
  "usabilityRatingNullable": 0.8529411764705882,
  "titleNullable": "RAVDESS Facial Landmark Tracking",
  "subtitleNullable": "Facial expression tracking dataset",
  "descriptionNullable": "RAVDESS Facial Landmark Tracking\n------------\n\nThis data set contains tracked facial landmark movements (.CSV format) from the Ryerson Audio-Visual Database of Emotional Speech and Song, available on Zenodo [[1](https://zenodo.org/record/1188976)].  Motion tracking of actors' faces was produced by OpenFace 2.1.0 [[2](https://github.com/TadasBaltrusaitis/OpenFace)].  Tracked information includes: facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.  Complete information on this dataset can be found at the Zenodo project page [[3](https://zenodo.org/record/3255102)].\n\nCheck out our related Kaggle datasets: Speech audio emotion [[4](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio)] and Song audio emotion [[5](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-song-audio)].\n\n**Files**\n\nThis data set contains tracking for all 2452 RAVDESS trials.  All tracking movement data are contained in \"FacialTracking_Actors_01-24.zip\", which contains 2452 .CSV files.  Each actor has 104 tracked trials (60 speech, 44 song).  Note, there are no song files for Actor 18.\n\nTotal Tracked Files = (24 Actors x 60 Speech trials) + (23 Actors x 44 Song trials) = 2452 files.\n\nTracking results for each trial are provided as individual comma separated value files (CSV format).  File naming convention of tracked files is identical to that of the RAVDESS.  For example, tracked file \"01-01-01-01-01-01-01.csv\" corresponds to RAVDESS audio-video file \"01-01-01-01-01-01-01.mp4\".  For a complete description of the RAVDESS file naming convention and experimental manipulations, please see the [RAVDESS Zenodo page](https://zenodo.org/record/1188976). \n\nTracking overlay videos for all trials (720p Xvid, .avi), one zip file per Actor, can be downloaded from the RAVDESS Facial Landmark Tracking project page on [Zenodo](https://zenodo.org/record/3255102).  \n\nAs the RAVDESS does not contain \"ground truth\" facial landmark locations, the overlay videos provide a visual 'sanity check' for researchers to confirm the general accuracy of the tracking results.  The file naming convention of tracking overlay videos also matches that of the RAVDESS.  For example, tracking video \"01-01-01-01-01-01-01.avi\" corresponds to RAVDESS audio-video file \"01-01-01-01-01-01-01.mp4\".\n\n**Tracking File Output Format**\n\nThis data set retained OpenFace's data output format, [described here in detail](https://github.com/TadasBaltrusaitis/OpenFace/wiki/Output-Format).  The resolution of all input videos was 1280x720.  When tracking output units are in pixels, their range of values is (0,0) (top left corner) to (1280,720) (bottom right corner). \n\n*Columns 1-3 = Timing and Detection Confidence*\n\n   1. Frame - The number of the frame (source videos 30 fps), range = 1 to n\n   2. Timestamp - Time of frame, range = 0 to m\n   3. Confidence - Tracker confidence level in current landmark detection estimate, range = 0 to 1\n\n*Columns 4-291 = Eye Gaze Detection*\n\n   4-6. gaze_0_x, gaze_0_y, gaze_0_z - Eye gaze direction vector in world coordinates for eye 0 (normalized), eye 0 is the leftmost eye in the image (think of it as a ray going from the left eye in the image in the direction of the eye gaze).\n   7-9. gaze_1_x, gaze_1_y, gaze_1_z - Eye gaze direction vector in world coordinates for eye 1 (normalized), eye 1 is the rightmost eye in the image (think of it as a ray going from the right eye in the image in the direction of the eye gaze).\n   10-11. gaze_angle_x, gaze_angle_y - Eye gaze direction in radians in world coordinates, averaged for both eyes. If a person is looking left-right this will results in the change of gaze_angle_x (from positive to negative) and, if a person is looking up-down this will result in change of gaze_angle_y (from negative to positive), if a person is looking straight ahead both of the angles will be close to 0 (within measurement error).\n   12-123. eye_lmk_x_0, ..., eye_lmk_x55, eye_lmk_y_0,..., eye_lmk_y_55 - Location of 2D eye region landmarks in pixels. A figure describing the landmark index [can be found here](https://raw.githubusercontent.com/wiki/TadasBaltrusaitis/OpenFace/images/eye_lmk_markup.png).\n   124-291. eye_lmk_X_0, ..., eye_lmk_X55, eye_lmk_Y_0,..., eye_lmk_Y_55,..., eye_lmk_Z_0,..., eye_lmk_Z_55 - Location of 3D eye region landmarks in millimeters. A figure describing the landmark index [can be found here](https://raw.githubusercontent.com/wiki/TadasBaltrusaitis/OpenFace/images/eye_lmk_markup.png).\n\n*Columns 292-297 = Head pose*\n\n   292-294. pose_Tx, pose_Ty, pose_Tz - Location of the head with respect to camera in millimeters (positive Z is away from the camera).\n   295-297. pose_Rx, pose_Ry, pose_Rz - Rotation of the head in radians around X,Y,Z axes with the convention R = Rx * Ry * Rz, left-handed positive sign. This can be seen as pitch (Rx), yaw (Ry), and roll (Rz). The rotation is in world coordinates with the camera being located at the origin.\n\n*Columns 298-433 = Facial Landmarks locations in 2D*\n\n   298-433. x_0, ..., x_67, y_0,...y_67 - Location of 2D landmarks in pixels. A figure describing the landmark index can be found here.\n\n*Columns 434-637 = Facial Landmarks locations in 3D*\n\n   434-637. X_0, ..., X_67, Y_0,..., Y_67, Z_0,..., Z_67 - Location of 3D landmarks in millimetres. A figure describing the landmark index can be found here.  For these values to be accurate, OpenFace needs to have good estimates for fx,fy,cx,cy.\n\n*Columns 638-677 = Rigid and non-rigid shape parameters*\n\nParameters of a point distribution model (PDM) that describe the rigid face shape (location, scale and rotation) and non-rigid face shape (deformation due to expression and identity). For more details, please refer to chapter 4.2 of my Tadas Baltrusaitis's PhD thesis [download link].\n\n   638-643. p_scale, p_rx, p_ry, p_rz, p_tx, p_ty - Scale, rotation, and translation terms of the PDM.\n   644-677. p_0, ..., p_33 - Non-rigid shape parameters.\n\n*Columns 687-712 = Facial Action Units*\n\nFacial Action Units (AUs) are a way to describe human facial movements (Ekman, Friesen, and Hager, 2002) [wiki link].  More information on OpenFace's implementation of AUs can be found here.\n\n   687-694. AU01_r, AU02_r, AU04_r, AU05_r, AU06_r, AU07_r, AU09_r, AU10_r, AU12_r, AU14_r, AU15_r, AU17_r, AU20_r, AU23_r, AU25_r, AU26_r, AU45_r - Intensity of AU movement, range from 0 (no muscle  contraction) to 5 (maximal muscle contraction).\n   695-712. AU01_c, AU02_c, AU04_c, AU05_c, AU06_c, AU07_c, AU09_c, AU10_c, AU12_c, AU14_c, AU15_c, AU17_c, AU20_c, AU23_c, AU25_c, AU26_c, AU28_c, AU45_c - Presence or absence of 18 AUs, range 0 (absent, not detected) to 1 (present, detected).\n\nNote, OpenFace's columns 2 and 5 (face_id and success, respectively) were not included in this data set. These values were redundant as a single face was detected in all frames, in all 2452 trials.\n\n**Camera Parameters and 3D Calibration Procedure**\n\nThis data set contains accurate estimates of actors' 3D head poses. To produce these, camera parameters at the time of recording were required (distance from camera to actor, and camera field of view).  These values were used with OpenCV's camera calibration procedure, described here, to produce estimates of the camera's focal length and optical center at the time of actor recordings.  The four values produced by the calibration procedure (fx,fy,cx,cy) were input to OpenFace as command line arguments during facial tracking, described here, to produce accurate estimates of 3D head pose.\n\n*Camera Parameters*\n\n    Distance between camera and actor = 1.4 meters\n    Camera field of view = 0.5 meters\n    Focal length in x (fx) = 6385.9\n    Focal length in y (fy) = 6339.6\n    Optical center in x (cx) = 824.241\n    Optical center in y (cy) = 1033.6\n\nThe use of OpenCV's calibration procedure was required as the video camera used in the RAVDESS recordings did not report focal length values.  Unlike SLR cameras, most video cameras do not provide this information to the user due to their dynamic focus feature.  For all RAVDESS recordings, camera distance, field of view, and focal point (manual fixed camera focus) were kept constant.",
  "datasetId": 342705,
  "datasetSlug": "ravdess-facial-landmark-tracking",
  "hasDatasetSlug": true,
  "ownerUser": "uwrfkaggler",
  "hasOwnerUser": true,
  "usabilityRating": 0.8529411764705882,
  "hasUsabilityRating": true,
  "totalViews": 12570,
  "totalVotes": 33,
  "totalDownloads": 710,
  "title": "RAVDESS Facial Landmark Tracking",
  "hasTitle": true,
  "subtitle": "Facial expression tracking dataset",
  "hasSubtitle": true,
  "description": "RAVDESS Facial Landmark Tracking\n------------\n\nThis data set contains tracked facial landmark movements (.CSV format) from the Ryerson Audio-Visual Database of Emotional Speech and Song, available on Zenodo [[1](https://zenodo.org/record/1188976)].  Motion tracking of actors' faces was produced by OpenFace 2.1.0 [[2](https://github.com/TadasBaltrusaitis/OpenFace)].  Tracked information includes: facial landmark detection, head pose estimation, facial action unit recognition, and eye-gaze estimation.  Complete information on this dataset can be found at the Zenodo project page [[3](https://zenodo.org/record/3255102)].\n\nCheck out our related Kaggle datasets: Speech audio emotion [[4](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-speech-audio)] and Song audio emotion [[5](https://www.kaggle.com/uwrfkaggler/ravdess-emotional-song-audio)].\n\n**Files**\n\nThis data set contains tracking for all 2452 RAVDESS trials.  All tracking movement data are contained in \"FacialTracking_Actors_01-24.zip\", which contains 2452 .CSV files.  Each actor has 104 tracked trials (60 speech, 44 song).  Note, there are no song files for Actor 18.\n\nTotal Tracked Files = (24 Actors x 60 Speech trials) + (23 Actors x 44 Song trials) = 2452 files.\n\nTracking results for each trial are provided as individual comma separated value files (CSV format).  File naming convention of tracked files is identical to that of the RAVDESS.  For example, tracked file \"01-01-01-01-01-01-01.csv\" corresponds to RAVDESS audio-video file \"01-01-01-01-01-01-01.mp4\".  For a complete description of the RAVDESS file naming convention and experimental manipulations, please see the [RAVDESS Zenodo page](https://zenodo.org/record/1188976). \n\nTracking overlay videos for all trials (720p Xvid, .avi), one zip file per Actor, can be downloaded from the RAVDESS Facial Landmark Tracking project page on [Zenodo](https://zenodo.org/record/3255102).  \n\nAs the RAVDESS does not contain \"ground truth\" facial landmark locations, the overlay videos provide a visual 'sanity check' for researchers to confirm the general accuracy of the tracking results.  The file naming convention of tracking overlay videos also matches that of the RAVDESS.  For example, tracking video \"01-01-01-01-01-01-01.avi\" corresponds to RAVDESS audio-video file \"01-01-01-01-01-01-01.mp4\".\n\n**Tracking File Output Format**\n\nThis data set retained OpenFace's data output format, [described here in detail](https://github.com/TadasBaltrusaitis/OpenFace/wiki/Output-Format).  The resolution of all input videos was 1280x720.  When tracking output units are in pixels, their range of values is (0,0) (top left corner) to (1280,720) (bottom right corner). \n\n*Columns 1-3 = Timing and Detection Confidence*\n\n   1. Frame - The number of the frame (source videos 30 fps), range = 1 to n\n   2. Timestamp - Time of frame, range = 0 to m\n   3. Confidence - Tracker confidence level in current landmark detection estimate, range = 0 to 1\n\n*Columns 4-291 = Eye Gaze Detection*\n\n   4-6. gaze_0_x, gaze_0_y, gaze_0_z - Eye gaze direction vector in world coordinates for eye 0 (normalized), eye 0 is the leftmost eye in the image (think of it as a ray going from the left eye in the image in the direction of the eye gaze).\n   7-9. gaze_1_x, gaze_1_y, gaze_1_z - Eye gaze direction vector in world coordinates for eye 1 (normalized), eye 1 is the rightmost eye in the image (think of it as a ray going from the right eye in the image in the direction of the eye gaze).\n   10-11. gaze_angle_x, gaze_angle_y - Eye gaze direction in radians in world coordinates, averaged for both eyes. If a person is looking left-right this will results in the change of gaze_angle_x (from positive to negative) and, if a person is looking up-down this will result in change of gaze_angle_y (from negative to positive), if a person is looking straight ahead both of the angles will be close to 0 (within measurement error).\n   12-123. eye_lmk_x_0, ..., eye_lmk_x55, eye_lmk_y_0,..., eye_lmk_y_55 - Location of 2D eye region landmarks in pixels. A figure describing the landmark index [can be found here](https://raw.githubusercontent.com/wiki/TadasBaltrusaitis/OpenFace/images/eye_lmk_markup.png).\n   124-291. eye_lmk_X_0, ..., eye_lmk_X55, eye_lmk_Y_0,..., eye_lmk_Y_55,..., eye_lmk_Z_0,..., eye_lmk_Z_55 - Location of 3D eye region landmarks in millimeters. A figure describing the landmark index [can be found here](https://raw.githubusercontent.com/wiki/TadasBaltrusaitis/OpenFace/images/eye_lmk_markup.png).\n\n*Columns 292-297 = Head pose*\n\n   292-294. pose_Tx, pose_Ty, pose_Tz - Location of the head with respect to camera in millimeters (positive Z is away from the camera).\n   295-297. pose_Rx, pose_Ry, pose_Rz - Rotation of the head in radians around X,Y,Z axes with the convention R = Rx * Ry * Rz, left-handed positive sign. This can be seen as pitch (Rx), yaw (Ry), and roll (Rz). The rotation is in world coordinates with the camera being located at the origin.\n\n*Columns 298-433 = Facial Landmarks locations in 2D*\n\n   298-433. x_0, ..., x_67, y_0,...y_67 - Location of 2D landmarks in pixels. A figure describing the landmark index can be found here.\n\n*Columns 434-637 = Facial Landmarks locations in 3D*\n\n   434-637. X_0, ..., X_67, Y_0,..., Y_67, Z_0,..., Z_67 - Location of 3D landmarks in millimetres. A figure describing the landmark index can be found here.  For these values to be accurate, OpenFace needs to have good estimates for fx,fy,cx,cy.\n\n*Columns 638-677 = Rigid and non-rigid shape parameters*\n\nParameters of a point distribution model (PDM) that describe the rigid face shape (location, scale and rotation) and non-rigid face shape (deformation due to expression and identity). For more details, please refer to chapter 4.2 of my Tadas Baltrusaitis's PhD thesis [download link].\n\n   638-643. p_scale, p_rx, p_ry, p_rz, p_tx, p_ty - Scale, rotation, and translation terms of the PDM.\n   644-677. p_0, ..., p_33 - Non-rigid shape parameters.\n\n*Columns 687-712 = Facial Action Units*\n\nFacial Action Units (AUs) are a way to describe human facial movements (Ekman, Friesen, and Hager, 2002) [wiki link].  More information on OpenFace's implementation of AUs can be found here.\n\n   687-694. AU01_r, AU02_r, AU04_r, AU05_r, AU06_r, AU07_r, AU09_r, AU10_r, AU12_r, AU14_r, AU15_r, AU17_r, AU20_r, AU23_r, AU25_r, AU26_r, AU45_r - Intensity of AU movement, range from 0 (no muscle  contraction) to 5 (maximal muscle contraction).\n   695-712. AU01_c, AU02_c, AU04_c, AU05_c, AU06_c, AU07_c, AU09_c, AU10_c, AU12_c, AU14_c, AU15_c, AU17_c, AU20_c, AU23_c, AU25_c, AU26_c, AU28_c, AU45_c - Presence or absence of 18 AUs, range 0 (absent, not detected) to 1 (present, detected).\n\nNote, OpenFace's columns 2 and 5 (face_id and success, respectively) were not included in this data set. These values were redundant as a single face was detected in all frames, in all 2452 trials.\n\n**Camera Parameters and 3D Calibration Procedure**\n\nThis data set contains accurate estimates of actors' 3D head poses. To produce these, camera parameters at the time of recording were required (distance from camera to actor, and camera field of view).  These values were used with OpenCV's camera calibration procedure, described here, to produce estimates of the camera's focal length and optical center at the time of actor recordings.  The four values produced by the calibration procedure (fx,fy,cx,cy) were input to OpenFace as command line arguments during facial tracking, described here, to produce accurate estimates of 3D head pose.\n\n*Camera Parameters*\n\n    Distance between camera and actor = 1.4 meters\n    Camera field of view = 0.5 meters\n    Focal length in x (fx) = 6385.9\n    Focal length in y (fy) = 6339.6\n    Optical center in x (cx) = 824.241\n    Optical center in y (cy) = 1033.6\n\nThe use of OpenCV's calibration procedure was required as the video camera used in the RAVDESS recordings did not report focal length values.  Unlike SLR cameras, most video cameras do not provide this information to the user due to their dynamic focus feature.  For all RAVDESS recordings, camera distance, field of view, and focal point (manual fixed camera focus) were kept constant.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "earth and nature",
    "education",
    "classification",
    "eyes and vision"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}