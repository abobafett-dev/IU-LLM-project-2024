{
  "id": "viktormodroczky/facial-affect-dataset",
  "id_no": 3068408,
  "datasetSlugNullable": "facial-affect-dataset",
  "ownerUserNullable": "viktormodroczky",
  "usabilityRatingNullable": 1.0,
  "titleNullable": "Facial Affect Dataset Balanced",
  "subtitleNullable": "Balanced dataset of facial expressions for affect recognition",
  "descriptionNullable": "This dataset is based on [Facial Expressions Training Data](https://www.kaggle.com/datasets/noamsegal/affectnet-training-data).\n\nImages remain 96x96 in size and their labels were inferred from directory names in the original dataset. The source dataset was split into two subsets - train and test - and its classes were balanced. The `train.csv` and `test.csv` files contain label to file name mappings for train and test subsets respectively.\n\nClasses are as follows: anger, contempt, disgust, fear, happy, neutral, sad, and surprise. Classes were balanced by augmentation relative to the size of the largest class using the [Albumentations](https://albumentations.ai/docs/) library for Python.\n\nThe following pipeline was used for augmentation:\n\n```py\nA.Compose(\n  [\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(\n      always_apply=True, contrast_limit=0.2, brightness_limit=0.2\n    ),\n    A.OneOf(\n      [\n        A.MotionBlur(always_apply=True),\n        A.GaussNoise(always_apply=True),\n        A.GaussianBlur(always_apply=True),\n      ],\n      p=0.5,\n    ),\n    A.PixelDropout(p=0.25),\n    A.Rotate(always_apply=True, limit=20, border_mode=cv2.BORDER_REPLICATE),\n  ]\n)\n```\n\nHorizontal flip is applied with a probability of 50%. Random brightness and contrast are always applied with a contrast limit of \u00b120% and a brightness limit of \u00b120%. One of motion blur, Gaussian noise, or Gaussian blur is applied with a probability of 50%. Pixel dropout is applied with a probability of 25%. Rotation by a random angle is always applied with a limit of \u00b120 degrees and border mode set to replicate colors at the borders of the image being rotated to avoid black borders.\n\nThree variants of the original dataset were created:\n\n- 1x the size of the original dataset + balancing (`data_balanced_1x`)\n- 2x the size of the original dataset + balancing (`data_balanced_2x`)\n- 3x the size of the original dataset + balancing (`data_balanced_3x`)",
  "datasetId": 3068408,
  "datasetSlug": "facial-affect-dataset",
  "hasDatasetSlug": true,
  "ownerUser": "viktormodroczky",
  "hasOwnerUser": true,
  "usabilityRating": 1.0,
  "hasUsabilityRating": true,
  "totalViews": 714,
  "totalVotes": 1,
  "totalDownloads": 117,
  "title": "Facial Affect Dataset Balanced",
  "hasTitle": true,
  "subtitle": "Balanced dataset of facial expressions for affect recognition",
  "hasSubtitle": true,
  "description": "This dataset is based on [Facial Expressions Training Data](https://www.kaggle.com/datasets/noamsegal/affectnet-training-data).\n\nImages remain 96x96 in size and their labels were inferred from directory names in the original dataset. The source dataset was split into two subsets - train and test - and its classes were balanced. The `train.csv` and `test.csv` files contain label to file name mappings for train and test subsets respectively.\n\nClasses are as follows: anger, contempt, disgust, fear, happy, neutral, sad, and surprise. Classes were balanced by augmentation relative to the size of the largest class using the [Albumentations](https://albumentations.ai/docs/) library for Python.\n\nThe following pipeline was used for augmentation:\n\n```py\nA.Compose(\n  [\n    A.HorizontalFlip(p=0.5),\n    A.RandomBrightnessContrast(\n      always_apply=True, contrast_limit=0.2, brightness_limit=0.2\n    ),\n    A.OneOf(\n      [\n        A.MotionBlur(always_apply=True),\n        A.GaussNoise(always_apply=True),\n        A.GaussianBlur(always_apply=True),\n      ],\n      p=0.5,\n    ),\n    A.PixelDropout(p=0.25),\n    A.Rotate(always_apply=True, limit=20, border_mode=cv2.BORDER_REPLICATE),\n  ]\n)\n```\n\nHorizontal flip is applied with a probability of 50%. Random brightness and contrast are always applied with a contrast limit of \u00b120% and a brightness limit of \u00b120%. One of motion blur, Gaussian noise, or Gaussian blur is applied with a probability of 50%. Pixel dropout is applied with a probability of 25%. Rotation by a random angle is always applied with a limit of \u00b120 degrees and border mode set to replicate colors at the borders of the image being rotated to avoid black borders.\n\nThree variants of the original dataset were created:\n\n- 1x the size of the original dataset + balancing (`data_balanced_1x`)\n- 2x the size of the original dataset + balancing (`data_balanced_2x`)\n- 3x the size of the original dataset + balancing (`data_balanced_3x`)",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "people",
    "neural networks",
    "image",
    "image classification"
  ],
  "licenses": [
    {
      "nameNullable": "Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)",
      "name": "Attribution-NonCommercial-ShareAlike 3.0 IGO (CC BY-NC-SA 3.0 IGO)",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}