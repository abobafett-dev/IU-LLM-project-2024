{
  "id": "vinayakshanawad/street-view-housing-number-digit-recognition",
  "id_no": 1460330,
  "datasetSlugNullable": "street-view-housing-number-digit-recognition",
  "ownerUserNullable": "vinayakshanawad",
  "usabilityRatingNullable": 0.9375,
  "titleNullable": "Street View Housing Number Digit Recognition",
  "subtitleNullable": "SVHN is obtained from house numbers in Google Street View images",
  "descriptionNullable": "### Description\n\nRecognizing multi-digit numbers in photographs captured at street level is an important component of modern-day map making. A classic example of a corpus of such street-level photographs is Google\u2019s Street View imagery comprised of hundreds of millions of geo-located 360-degree panoramic images. The ability to automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed\nnumber with a known street address helps pinpoint, with a high degree of accuracy, the location of the building it represents. More broadly, recognizing numbers in photographs is a problem of interest to the optical\ncharacter recognition community. While OCR on constrained domains like document processing is well studied, arbitrary multi-character text recognition in photographs is still highly challenging. This difficulty arises due to the wide variability in the visual appearance of text in the wild on account of a large range of fonts, colours, styles, orientations, and character arrangements. The recognition problem is further complicated by environmental factors such as lighting, shadows, specularities, and occlusions as well as by image acquisition factors such as resolution, motion, and focus blurs. In this project, we will use the dataset with images centred around a single digit (many of the images do contain some distractors at the sides). Although we are taking a sample of the data which is simpler, it is more complex than MNIST because of the distractors.\n\n### Dataset\n\nSVHN is a real-world image dataset for developing machine learning and object recognition algorithms with the minimal requirement on data formatting but comes from a significantly harder, unsolved, real-world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n\n###  Acknowledgement\n\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. PDF\n[http://ufldl.stanford.edu/housenumbers](http://ufldl.stanford.edu/housenumbers) as the URL for this site when necessary\n\n### Objective\n\nThe objective of the project is to learn how to implement a simple image classification pipeline based on a deep neural network and understand the basics of Image Classification.",
  "datasetId": 1460330,
  "datasetSlug": "street-view-housing-number-digit-recognition",
  "hasDatasetSlug": true,
  "ownerUser": "vinayakshanawad",
  "hasOwnerUser": true,
  "usabilityRating": 0.9375,
  "hasUsabilityRating": true,
  "totalViews": 4067,
  "totalVotes": 9,
  "totalDownloads": 176,
  "title": "Street View Housing Number Digit Recognition",
  "hasTitle": true,
  "subtitle": "SVHN is obtained from house numbers in Google Street View images",
  "hasSubtitle": true,
  "description": "### Description\n\nRecognizing multi-digit numbers in photographs captured at street level is an important component of modern-day map making. A classic example of a corpus of such street-level photographs is Google\u2019s Street View imagery comprised of hundreds of millions of geo-located 360-degree panoramic images. The ability to automatically transcribe an address number from a geo-located patch of pixels and associate the transcribed\nnumber with a known street address helps pinpoint, with a high degree of accuracy, the location of the building it represents. More broadly, recognizing numbers in photographs is a problem of interest to the optical\ncharacter recognition community. While OCR on constrained domains like document processing is well studied, arbitrary multi-character text recognition in photographs is still highly challenging. This difficulty arises due to the wide variability in the visual appearance of text in the wild on account of a large range of fonts, colours, styles, orientations, and character arrangements. The recognition problem is further complicated by environmental factors such as lighting, shadows, specularities, and occlusions as well as by image acquisition factors such as resolution, motion, and focus blurs. In this project, we will use the dataset with images centred around a single digit (many of the images do contain some distractors at the sides). Although we are taking a sample of the data which is simpler, it is more complex than MNIST because of the distractors.\n\n### Dataset\n\nSVHN is a real-world image dataset for developing machine learning and object recognition algorithms with the minimal requirement on data formatting but comes from a significantly harder, unsolved, real-world problem (recognizing digits and numbers in natural scene images). SVHN is obtained from house numbers in Google Street View images.\n\n###  Acknowledgement\n\nYuval Netzer, Tao Wang, Adam Coates, Alessandro Bissacco, Bo Wu, Andrew Y. Ng Reading Digits in Natural Images with Unsupervised Feature Learning NIPS Workshop on Deep Learning and Unsupervised Feature Learning 2011. PDF\n[http://ufldl.stanford.edu/housenumbers](http://ufldl.stanford.edu/housenumbers) as the URL for this site when necessary\n\n### Objective\n\nThe objective of the project is to learn how to implement a simple image classification pipeline based on a deep neural network and understand the basics of Image Classification.",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "earth and nature",
    "computer vision",
    "classification",
    "image"
  ],
  "licenses": [
    {
      "nameNullable": "CC0-1.0",
      "name": "CC0-1.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}