{
  "id": "yewtsing/pretty-face",
  "id_no": 1086951,
  "datasetSlugNullable": "pretty-face",
  "ownerUserNullable": "yewtsing",
  "usabilityRatingNullable": 0.8125,
  "titleNullable": "Pretty Face",
  "subtitleNullable": "Images creates from StyleGAN2, faceParser and Sketch Simplification",
  "descriptionNullable": "(Adapted from my [Blog](https://kiyoshimu.github.io))\n### Context\n\nA generative adversarial network (GAN) is a class of machine learning frameworks that generate new *fake* data deceptively from real data. It was invented in just 2014, but its applications have increased rapidly. It has also been used successfully in lots of areas, including fashion, art, advertising, and science.\n\nGANs can be used to achieve image-to-image translation, where the generation of the output image is **conditional** on an input. I think it would be interesting to use segmentation layouts or sketches as inputs to let the model generate **pretty** faces. Right, pretty or not is a matter of taste). Fortunately, I found one paper, [*Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation*](https://arxiv.org/abs/2008.00951)(*Encoding in Style*), which published recently has paved the road to this imaginary transformation\n\n### Content\n\n#### Use a GAN to create a dataset for another GAN\nThe benefit of GANs is that it can provide unlimited data. If I want to create a dataset with pretty-face, why not use a GAN pre-trained on celebrities. Why celebrities? Because it's heuristic that there are more good-looking people in the group of stars than in the group of ordinary people. Since a GAN learn the distribution of its training data, it masks sense to select stars as training data. Luckily, when I was searching for a proper dataset, I found [someone](https://github.com/a312863063/) has already trained a [StyleGAN2](https://arxiv.org/abs/1912.04958) on an ideal dataset that has 95600 512*512 faces from 500 Chinese stars.\n\nSince not all the stars in the training dataset have beautiful faces, the GAN images are not all pretty. **A model's problem can be solved using another model.** Here, I used the model to generate about 3000 pictures and *manually* selected those that look *not bad*. Using *not bad* images and the same number of other images, I prepared a dataset to train a binary classifier using [MixNet-S](https://arxiv.org/abs/1907.09595?source=techstories.org) as the backbone. This model can filter qualified faces from the GANs' products. Next, StyleGAN2 generated another 30,000 images, and the classifier selected 3318 not-bad from them. Finally, these images are collected as the dataset for the following training.\n\n#### Generate Sketch Data\n\nMany studies mentioned how to generate sketch data from original data, especially in the community of GANs for line art coloration. Common methods include using [sketchKeras](https://github.com/lllyasviel/sketchKeras), [Sketch Simplification](https://esslab.jp/~ess/en/research/sketch_master/) etc. Here, I applied the sketchGAN from Sketch Simplification as the authors of *Encoding in Style* did to make sketches from the selected faces.\n\n#### Plus: Segmentation Layout\n\nI also tried to use segmentation layouts as inputs to generate images. Here another model is created to create images from segmentation maps (also just following their instruction). The faces' segmentation layouts are created by using [face-parsing](https://github.com/zllrunning/face-parsing.PyTorch)\n\n### Acknowledgements\n\nThanks for the pre-trained StyleGAN2 model shared by [a312863063](https://github.com/a312863063/). [StyleGAN2](https://arxiv.org/abs/1912.04958) and  [MixNet-S](https://arxiv.org/abs/1907.09595?source=techstories.org),  also are the foundation of this dataset.\n\n### Inspiration\n\nCould a smaller model (&lt;512 MB) be trained to achieve the same functions as the [*Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation*](https://arxiv.org/abs/2008.00951)?",
  "datasetId": 1086951,
  "datasetSlug": "pretty-face",
  "hasDatasetSlug": true,
  "ownerUser": "yewtsing",
  "hasOwnerUser": true,
  "usabilityRating": 0.8125,
  "hasUsabilityRating": true,
  "totalViews": 9770,
  "totalVotes": 19,
  "totalDownloads": 916,
  "title": "Pretty Face",
  "hasTitle": true,
  "subtitle": "Images creates from StyleGAN2, faceParser and Sketch Simplification",
  "hasSubtitle": true,
  "description": "(Adapted from my [Blog](https://kiyoshimu.github.io))\n### Context\n\nA generative adversarial network (GAN) is a class of machine learning frameworks that generate new *fake* data deceptively from real data. It was invented in just 2014, but its applications have increased rapidly. It has also been used successfully in lots of areas, including fashion, art, advertising, and science.\n\nGANs can be used to achieve image-to-image translation, where the generation of the output image is **conditional** on an input. I think it would be interesting to use segmentation layouts or sketches as inputs to let the model generate **pretty** faces. Right, pretty or not is a matter of taste). Fortunately, I found one paper, [*Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation*](https://arxiv.org/abs/2008.00951)(*Encoding in Style*), which published recently has paved the road to this imaginary transformation\n\n### Content\n\n#### Use a GAN to create a dataset for another GAN\nThe benefit of GANs is that it can provide unlimited data. If I want to create a dataset with pretty-face, why not use a GAN pre-trained on celebrities. Why celebrities? Because it's heuristic that there are more good-looking people in the group of stars than in the group of ordinary people. Since a GAN learn the distribution of its training data, it masks sense to select stars as training data. Luckily, when I was searching for a proper dataset, I found [someone](https://github.com/a312863063/) has already trained a [StyleGAN2](https://arxiv.org/abs/1912.04958) on an ideal dataset that has 95600 512*512 faces from 500 Chinese stars.\n\nSince not all the stars in the training dataset have beautiful faces, the GAN images are not all pretty. **A model's problem can be solved using another model.** Here, I used the model to generate about 3000 pictures and *manually* selected those that look *not bad*. Using *not bad* images and the same number of other images, I prepared a dataset to train a binary classifier using [MixNet-S](https://arxiv.org/abs/1907.09595?source=techstories.org) as the backbone. This model can filter qualified faces from the GANs' products. Next, StyleGAN2 generated another 30,000 images, and the classifier selected 3318 not-bad from them. Finally, these images are collected as the dataset for the following training.\n\n#### Generate Sketch Data\n\nMany studies mentioned how to generate sketch data from original data, especially in the community of GANs for line art coloration. Common methods include using [sketchKeras](https://github.com/lllyasviel/sketchKeras), [Sketch Simplification](https://esslab.jp/~ess/en/research/sketch_master/) etc. Here, I applied the sketchGAN from Sketch Simplification as the authors of *Encoding in Style* did to make sketches from the selected faces.\n\n#### Plus: Segmentation Layout\n\nI also tried to use segmentation layouts as inputs to generate images. Here another model is created to create images from segmentation maps (also just following their instruction). The faces' segmentation layouts are created by using [face-parsing](https://github.com/zllrunning/face-parsing.PyTorch)\n\n### Acknowledgements\n\nThanks for the pre-trained StyleGAN2 model shared by [a312863063](https://github.com/a312863063/). [StyleGAN2](https://arxiv.org/abs/1912.04958) and  [MixNet-S](https://arxiv.org/abs/1907.09595?source=techstories.org),  also are the foundation of this dataset.\n\n### Inspiration\n\nCould a smaller model (&lt;512 MB) be trained to achieve the same functions as the [*Encoding in Style: a StyleGAN Encoder for Image-to-Image Translation*](https://arxiv.org/abs/2008.00951)?",
  "hasDescription": true,
  "isPrivate": false,
  "keywords": [
    "arts and entertainment",
    "computer science",
    "online communities"
  ],
  "licenses": [
    {
      "nameNullable": "CC-BY-NC-SA-4.0",
      "name": "CC-BY-NC-SA-4.0",
      "hasName": true
    }
  ],
  "collaborators": [],
  "data": []
}